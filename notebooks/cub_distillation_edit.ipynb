{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 11:38:43.756117: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-03 11:38:44.823020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 503.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment varied these params: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No group keys passed!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m r \u001b[38;5;241m=\u001b[39m imodelsx\u001b[38;5;241m.\u001b[39mprocess_results\u001b[38;5;241m.\u001b[39mfill_missing_args_with_default(\n\u001b[1;32m     38\u001b[0m     r, experiment_filename)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# get the breakdown of data in these groups\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols_varied\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msize()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:8399\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8397\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8402\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8405\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8407\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:959\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 959\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:916\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    913\u001b[0m     groupings\u001b[38;5;241m.\u001b[39mappend(ping)\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(groupings) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj):\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo group keys passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(groupings) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    918\u001b[0m     groupings\u001b[38;5;241m.\u001b[39mappend(Grouping(Index([], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m), np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)))\n",
      "\u001b[0;31mValueError\u001b[0m: No group keys passed!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import imodelsx.process_results\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# def load_csvs(path):\n",
    "\n",
    "#     X_train = pd.read_csv(f'{path}/X_trainval.csv', index_col=0)\n",
    "#     X_train_hat = pd.read_csv(f'{path}/X_trainval_hat.csv', index_col=0)\n",
    "#     X_test = pd.read_csv(f'{path}/X_test.csv', index_col=0)\n",
    "#     X_test_hat = pd.read_csv(f'{path}/X_test_hat.csv', index_col=0)\n",
    "#     y_train = pd.read_csv(f'{path}/y_trainval.csv', index_col=0)\n",
    "#     y_train_hat = pd.read_csv(f'{path}/y_trainval_hat.csv', index_col=0)\n",
    "#     y_test = pd.read_csv(f'{path}/y_test.csv', index_col=0)\n",
    "#     y_test_hat = pd.read_csv(f'{path}/y_test_hat.csv', index_col=0)\n",
    "\n",
    "#     return X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat\n",
    "\n",
    "sys.path.append('../experiments/')\n",
    "results = []\n",
    "\n",
    "results_dir = f'../results/cub_distillation_edit'\n",
    "experiment_filename = '../experiments/cub_distillation_edit.py'\n",
    "\n",
    "# load the results in to a pandas dataframe\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "cols_varied = imodelsx.process_results.get_experiment_keys(\n",
    "    r, experiment_filename)\n",
    "print('experiment varied these params:', cols_varied)\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(\n",
    "    r, experiment_filename)\n",
    "\n",
    "# get the breakdown of data in these groups\n",
    "r.groupby(cols_varied).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>X_type</th>\n",
       "      <th>thresh</th>\n",
       "      <th>Y_type</th>\n",
       "      <th>save_dir</th>\n",
       "      <th>max_rules</th>\n",
       "      <th>max_trees</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>pre_interaction</th>\n",
       "      <th>...</th>\n",
       "      <th>%_correct_seed3_overlap_trainval</th>\n",
       "      <th>%_correct_seed3_overlap_test</th>\n",
       "      <th>edited_cbm_true_seed3_accuracy_trainval</th>\n",
       "      <th>edited_cbm_true_seed3_accuracy_test</th>\n",
       "      <th>edited_distiller_true_seed3_accuracy_trainval</th>\n",
       "      <th>edited_distiller_true_seed3_accuracy_test</th>\n",
       "      <th>edited_distiller_cbm_seed3_accuracy_trainval</th>\n",
       "      <th>edited_distiller_cbm_seed3_accuracy_test</th>\n",
       "      <th>edited_%_correct_seed3_overlap_trainval</th>\n",
       "      <th>edited_%_correct_seed3_overlap_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regression</td>\n",
       "      <td>FIGSRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.25</td>\n",
       "      <td>logits</td>\n",
       "      <td>/home/mattyshen/DistillationEdit/results/cub_d...</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983289</td>\n",
       "      <td>0.935278</td>\n",
       "      <td>0.983623</td>\n",
       "      <td>0.783569</td>\n",
       "      <td>0.976103</td>\n",
       "      <td>0.762858</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>0.891785</td>\n",
       "      <td>0.98379</td>\n",
       "      <td>0.935105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_type     model_name  X_type  thresh  Y_type  \\\n",
       "0  regression  FIGSRegressor  binary    0.25  logits   \n",
       "\n",
       "                                            save_dir  max_rules  max_trees  \\\n",
       "0  /home/mattyshen/DistillationEdit/results/cub_d...         60         30   \n",
       "\n",
       "   max_depth pre_interaction  ...  %_correct_seed3_overlap_trainval  \\\n",
       "0          3            l0l2  ...                          0.983289   \n",
       "\n",
       "  %_correct_seed3_overlap_test  edited_cbm_true_seed3_accuracy_trainval  \\\n",
       "0                     0.935278                                 0.983623   \n",
       "\n",
       "   edited_cbm_true_seed3_accuracy_test  \\\n",
       "0                             0.783569   \n",
       "\n",
       "  edited_distiller_true_seed3_accuracy_trainval  \\\n",
       "0                                      0.976103   \n",
       "\n",
       "  edited_distiller_true_seed3_accuracy_test  \\\n",
       "0                                  0.762858   \n",
       "\n",
       "   edited_distiller_cbm_seed3_accuracy_trainval  \\\n",
       "0                                      0.983456   \n",
       "\n",
       "  edited_distiller_cbm_seed3_accuracy_test  \\\n",
       "0                                 0.891785   \n",
       "\n",
       "   edited_%_correct_seed3_overlap_trainval  \\\n",
       "0                                  0.98379   \n",
       "\n",
       "   edited_%_correct_seed3_overlap_test  \n",
       "0                             0.935105  \n",
       "\n",
       "[1 rows x 66 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: clean below when results are logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['cbm_mean_accuracy_val'] = np.mean([r[f'cbm_seed{seed}_accuracy_val'] for seed in range(1, 4)], axis = 0)\n",
    "r['cbm_std_accuracy_val'] = np.std([r[f'cbm_seed{seed}_accuracy_val'] for seed in range(1, 4)], axis = 0)\n",
    "r['cbm_mean_accuracy_train'] = np.mean([r[f'cbm_seed{seed}_accuracy_train'] for seed in range(1, 4)], axis = 0)\n",
    "r['cbm_std_accuracy_train'] = np.std([r[f'cbm_seed{seed}_accuracy_train'] for seed in range(1, 4)], axis = 0)\n",
    "\n",
    "r['true_mean_accuracy_val'] = np.mean([r[f'true_seed{seed}_accuracy_val'] for seed in range(1, 4)], axis = 0)\n",
    "r['true_std_accuracy_val'] = np.std([r[f'true_seed{seed}_accuracy_val'] for seed in range(1, 4)], axis = 0)\n",
    "r['true_mean_accuracy_train'] = np.mean([r[f'true_seed{seed}_accuracy_train'] for seed in range(1, 4)], axis = 0)\n",
    "r['true_std_accuracy_train'] = np.std([r[f'true_seed{seed}_accuracy_train'] for seed in range(1, 4)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['thresh'] = r['thresh'].fillna(0) + r['half'].fillna(0)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r.drop(columns  = ['save_dir', 'save_dir_unique', 'use_cache', 'half']\n",
    "      +[f'true_seed{seed}_accuracy_val' for seed in range(1, 4)]+\n",
    "       [f'true_seed{seed}_accuracy_train' for seed in range(1, 4)]+\n",
    "       [f'cbm_seed{seed}_accuracy_val' for seed in range(1, 4)]+\n",
    "       [f'cbm_seed{seed}_accuracy_train' for seed in range(1, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>X_type</th>\n",
       "      <th>Y_type</th>\n",
       "      <th>max_trees</th>\n",
       "      <th>pre_interaction</th>\n",
       "      <th>post_interaction</th>\n",
       "      <th>post_max_features</th>\n",
       "      <th>thresh</th>\n",
       "      <th>mo</th>\n",
       "      <th>cbm_mean_accuracy_val</th>\n",
       "      <th>cbm_std_accuracy_val</th>\n",
       "      <th>cbm_mean_accuracy_train</th>\n",
       "      <th>cbm_std_accuracy_train</th>\n",
       "      <th>true_mean_accuracy_val</th>\n",
       "      <th>true_std_accuracy_val</th>\n",
       "      <th>true_mean_accuracy_train</th>\n",
       "      <th>true_std_accuracy_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>elastic_net</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>30</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.797607</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.984347</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.704925</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.972315</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>elastic_net</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>30</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.858647</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.992647</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.742147</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.988581</td>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>elastic_net</td>\n",
       "      <td>probs</td>\n",
       "      <td>logits</td>\n",
       "      <td>30</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995858</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.999499</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.776953</td>\n",
       "      <td>0.002638</td>\n",
       "      <td>0.984737</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>elastic_net</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>30</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.936083</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.988692</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.772408</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>0.974933</td>\n",
       "      <td>0.001774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  X_type  Y_type  max_trees pre_interaction post_interaction  \\\n",
       "49   elastic_net  binary   probs         30            l0l2             l0l2   \n",
       "69   elastic_net  binary  logits         30            l0l2             l0l2   \n",
       "117  elastic_net   probs  logits         30            l0l2             l0l2   \n",
       "166  elastic_net   probs   probs         30            l0l2             l0l2   \n",
       "\n",
       "     post_max_features thresh     mo  cbm_mean_accuracy_val  \\\n",
       "49                30.0    0.0  False               0.797607   \n",
       "69                30.0    0.0  False               0.858647   \n",
       "117               30.0    0.0  False               0.995858   \n",
       "166               30.0    0.0  False               0.936083   \n",
       "\n",
       "     cbm_std_accuracy_val  cbm_mean_accuracy_train  cbm_std_accuracy_train  \\\n",
       "49               0.004439                 0.984347                0.002682   \n",
       "69               0.006432                 0.992647                0.002367   \n",
       "117              0.000508                 0.999499                0.000361   \n",
       "166              0.005144                 0.988692                0.003415   \n",
       "\n",
       "     true_mean_accuracy_val  true_std_accuracy_val  true_mean_accuracy_train  \\\n",
       "49                 0.704925               0.003870                  0.972315   \n",
       "69                 0.742147               0.003612                  0.988581   \n",
       "117                0.776953               0.002638                  0.984737   \n",
       "166                0.772408               0.005568                  0.974933   \n",
       "\n",
       "     true_std_accuracy_train  \n",
       "49                  0.000284  \n",
       "69                  0.001570  \n",
       "117                 0.001817  \n",
       "166                 0.001774  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[r['model_name'] == 'elastic_net'].drop(columns=['task_type', 'max_depth', 'pre_max_features', 'max_rules', 'reg_depth','shrink_depth', 'reg_shrink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.loc[(r['model_name'] == 'ft_distill') & (r['task_type'] == 'classification'), 'model_name'] = 'FTDistillClassifier'\n",
    "r.loc[(r['model_name'] == 'ft_distill') & (r['task_type'] == 'regression'), 'model_name'] = 'FTDistillHydraRegressor'\n",
    "r.loc[(r['model_name'] == 'FTDistillHydraRegressor') & (r['max_depth'] == 1), 'model_name'] = 'FTDistillHydraRegressor (No Interactions)'\n",
    "r.loc[(r['model_name'] == 'decision_tree') & (r['task_type'] == 'regression'), 'model_name'] = 'DTRegressor'\n",
    "r.loc[(r['model_name'] == 'decision_tree') & (r['task_type'] == 'classification'), 'model_name'] = 'DTClassifier'\n",
    "r.loc[(r['model_name'] == 'random_forest') & (r['task_type'] == 'regression'), 'model_name'] = 'RFRegressor'\n",
    "r.loc[(r['model_name'] == 'random_forest') & (r['task_type'] == 'classification'), 'model_name'] = 'RFClassifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r[r.model_name != 'elastic_net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting = r.groupby(['model_name', 'task_type']).apply(lambda sdf: sdf.sort_values(by='cbm_mean_accuracy_val', ascending=False).iloc[0,:]).drop(columns=['model_name', 'task_type']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>X_type</th>\n",
       "      <th>Y_type</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>pre_max_features</th>\n",
       "      <th>post_interaction</th>\n",
       "      <th>post_max_features</th>\n",
       "      <th>thresh</th>\n",
       "      <th>...</th>\n",
       "      <th>shrink_depth</th>\n",
       "      <th>mo</th>\n",
       "      <th>cbm_mean_accuracy_val</th>\n",
       "      <th>cbm_std_accuracy_val</th>\n",
       "      <th>cbm_mean_accuracy_train</th>\n",
       "      <th>cbm_std_accuracy_train</th>\n",
       "      <th>true_mean_accuracy_val</th>\n",
       "      <th>true_std_accuracy_val</th>\n",
       "      <th>true_mean_accuracy_train</th>\n",
       "      <th>true_std_accuracy_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DTClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>binary</td>\n",
       "      <td>classes</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.194684</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.265319</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.167702</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.252117</td>\n",
       "      <td>0.008919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DTRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>probs</td>\n",
       "      <td>logits</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.493326</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>0.679757</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.439938</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.671234</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FIGSClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>probs</td>\n",
       "      <td>classes</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.582269</td>\n",
       "      <td>0.170401</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>0.188379</td>\n",
       "      <td>0.514268</td>\n",
       "      <td>0.143457</td>\n",
       "      <td>0.719753</td>\n",
       "      <td>0.187564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FIGSHydraRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.713036</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.923240</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>0.649005</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.923908</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FIGSRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.927914</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.994374</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.765102</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>0.004886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>FTDistillClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>probs</td>\n",
       "      <td>classes</td>\n",
       "      <td>1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.954033</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.999276</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.774709</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.984626</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.870958</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.981228</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.743470</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.972037</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>FTDistillHydraRegressor (No Interactions)</td>\n",
       "      <td>regression</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.783684</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>0.855002</td>\n",
       "      <td>0.017749</td>\n",
       "      <td>0.675526</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.845978</td>\n",
       "      <td>0.013120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>RFClassifier</td>\n",
       "      <td>classification</td>\n",
       "      <td>probs</td>\n",
       "      <td>classes</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903118</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.759004</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.981339</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>RFRegressor</td>\n",
       "      <td>regression</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.562939</td>\n",
       "      <td>0.010285</td>\n",
       "      <td>0.632242</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.499425</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.625334</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>regression</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.926188</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.993928</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.762053</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                 model_name       task_type  X_type  \\\n",
       "0       0                               DTClassifier  classification  binary   \n",
       "1       1                                DTRegressor      regression   probs   \n",
       "2       2                             FIGSClassifier  classification   probs   \n",
       "3       3                         FIGSHydraRegressor      regression  binary   \n",
       "4       4                              FIGSRegressor      regression  binary   \n",
       "5       5                        FTDistillClassifier  classification   probs   \n",
       "6       6                    FTDistillHydraRegressor      regression   probs   \n",
       "7       7  FTDistillHydraRegressor (No Interactions)      regression   probs   \n",
       "8       8                               RFClassifier  classification   probs   \n",
       "9       9                                RFRegressor      regression   probs   \n",
       "10     10                                    xgboost      regression  binary   \n",
       "\n",
       "     Y_type  max_depth  pre_max_features post_interaction  post_max_features  \\\n",
       "0   classes          8               1.0             l0l2               30.0   \n",
       "1    logits          8               1.0             l0l2               30.0   \n",
       "2   classes          3               1.0             l0l2               30.0   \n",
       "3    logits          4               1.0             l0l2               30.0   \n",
       "4    logits          4               1.0             l0l2               30.0   \n",
       "5   classes          1             112.0             l0l2              112.0   \n",
       "6     probs          2               1.0             l0l2                7.0   \n",
       "7     probs          1               1.0             l0l2                7.0   \n",
       "8   classes          8               1.0             l0l2               30.0   \n",
       "9     probs          4               1.0             l0l2               30.0   \n",
       "10   logits          3               1.0             l0l2               30.0   \n",
       "\n",
       "    thresh  ...  shrink_depth     mo  cbm_mean_accuracy_val  \\\n",
       "0      0.0  ...           0.0  False               0.194684   \n",
       "1      0.0  ...           0.0  False               0.493326   \n",
       "2      0.0  ...           0.0  False               0.582269   \n",
       "3      0.0  ...           0.0  False               0.713036   \n",
       "4      0.5  ...           0.0  False               0.927914   \n",
       "5      0.0  ...           0.0  False               0.954033   \n",
       "6      0.0  ...           0.0   True               0.870958   \n",
       "7      0.0  ...           0.0   True               0.783684   \n",
       "8      0.0  ...           0.0  False               0.903118   \n",
       "9      0.0  ...           0.0  False               0.562939   \n",
       "10     0.5  ...           0.0  False               0.926188   \n",
       "\n",
       "    cbm_std_accuracy_val  cbm_mean_accuracy_train  cbm_std_accuracy_train  \\\n",
       "0               0.000924                 0.265319                0.007489   \n",
       "1               0.028981                 0.679757                0.021957   \n",
       "2               0.170401                 0.732620                0.188379   \n",
       "3               0.013265                 0.923240                0.008356   \n",
       "4               0.002185                 0.994374                0.002633   \n",
       "5               0.004138                 0.999276                0.000343   \n",
       "6               0.014137                 0.981228                0.005957   \n",
       "7               0.015644                 0.855002                0.017749   \n",
       "8               0.013839                 0.996156                0.002363   \n",
       "9               0.010285                 0.632242                0.004884   \n",
       "10              0.005709                 0.993928                0.003256   \n",
       "\n",
       "    true_mean_accuracy_val  true_std_accuracy_val  true_mean_accuracy_train  \\\n",
       "0                 0.167702               0.001681                  0.252117   \n",
       "1                 0.439938               0.017237                  0.671234   \n",
       "2                 0.514268               0.143457                  0.719753   \n",
       "3                 0.649005               0.003624                  0.923908   \n",
       "4                 0.765102               0.002912                  0.981061   \n",
       "5                 0.774709               0.002053                  0.984626   \n",
       "6                 0.743470               0.005416                  0.972037   \n",
       "7                 0.675526               0.010141                  0.845978   \n",
       "8                 0.759004               0.006117                  0.981339   \n",
       "9                 0.499425               0.004951                  0.625334   \n",
       "10                0.762053               0.003092                  0.981061   \n",
       "\n",
       "    true_std_accuracy_train  \n",
       "0                  0.008919  \n",
       "1                  0.016667  \n",
       "2                  0.187564  \n",
       "3                  0.006993  \n",
       "4                  0.004886  \n",
       "5                  0.001910  \n",
       "6                  0.001853  \n",
       "7                  0.013120  \n",
       "8                  0.000776  \n",
       "9                  0.002131  \n",
       "10                 0.002325  \n",
       "\n",
       "[11 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting.reset_index().drop(columns=['reg_shrink', 'max_rules', 'max_trees', 'pre_interaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>X_type</th>\n",
       "      <th>Y_type</th>\n",
       "      <th>max_rules</th>\n",
       "      <th>max_trees</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>pre_interaction</th>\n",
       "      <th>pre_max_features</th>\n",
       "      <th>post_interaction</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_shrink</th>\n",
       "      <th>mo</th>\n",
       "      <th>cbm_mean_accuracy_val</th>\n",
       "      <th>cbm_std_accuracy_val</th>\n",
       "      <th>cbm_mean_accuracy_train</th>\n",
       "      <th>cbm_std_accuracy_train</th>\n",
       "      <th>true_mean_accuracy_val</th>\n",
       "      <th>true_std_accuracy_val</th>\n",
       "      <th>true_mean_accuracy_train</th>\n",
       "      <th>true_std_accuracy_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.870958</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.981228</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>0.743470</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.972037</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.858129</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.980559</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.734265</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.976771</td>\n",
       "      <td>0.002482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.857726</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.736912</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.966355</td>\n",
       "      <td>0.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.853584</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.981729</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.739673</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.976660</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.852951</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.977997</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.726556</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.968471</td>\n",
       "      <td>0.009077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.851168</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>0.735473</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.006124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.830687</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>0.927362</td>\n",
       "      <td>0.016961</td>\n",
       "      <td>0.720746</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.927418</td>\n",
       "      <td>0.017584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.805086</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.911096</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.705960</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.913603</td>\n",
       "      <td>0.026958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>probs</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751467</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.922906</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.664423</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.917502</td>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704695</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>0.780916</td>\n",
       "      <td>0.027015</td>\n",
       "      <td>0.619722</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.783701</td>\n",
       "      <td>0.028518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.700610</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.977718</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.629502</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.968639</td>\n",
       "      <td>0.003112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.697158</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.972315</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.630422</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.970087</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691117</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>0.899677</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.630652</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>0.011794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.675009</td>\n",
       "      <td>0.043845</td>\n",
       "      <td>0.768215</td>\n",
       "      <td>0.052884</td>\n",
       "      <td>0.605914</td>\n",
       "      <td>0.036087</td>\n",
       "      <td>0.768438</td>\n",
       "      <td>0.052972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>probs</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.645668</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>0.800524</td>\n",
       "      <td>0.026436</td>\n",
       "      <td>0.577609</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>0.799855</td>\n",
       "      <td>0.021979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>regression</td>\n",
       "      <td>FTDistillHydraRegressor</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l0l2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620872</td>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.807877</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>0.564665</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.804980</td>\n",
       "      <td>0.019336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      task_type               model_name  X_type  Y_type  max_rules  \\\n",
       "68   regression  FTDistillHydraRegressor   probs   probs         60   \n",
       "56   regression  FTDistillHydraRegressor  binary   probs         60   \n",
       "170  regression  FTDistillHydraRegressor   probs   probs         60   \n",
       "266  regression  FTDistillHydraRegressor  binary   probs         60   \n",
       "284  regression  FTDistillHydraRegressor  binary   probs         60   \n",
       "203  regression  FTDistillHydraRegressor  binary   probs         60   \n",
       "47   regression  FTDistillHydraRegressor  binary  logits         60   \n",
       "44   regression  FTDistillHydraRegressor  binary  logits         60   \n",
       "248  regression  FTDistillHydraRegressor   probs  logits         60   \n",
       "115  regression  FTDistillHydraRegressor  binary  logits         60   \n",
       "120  regression  FTDistillHydraRegressor  binary   probs         60   \n",
       "5    regression  FTDistillHydraRegressor  binary   probs         60   \n",
       "267  regression  FTDistillHydraRegressor  binary  logits         60   \n",
       "102  regression  FTDistillHydraRegressor  binary  logits         60   \n",
       "21   regression  FTDistillHydraRegressor   probs  logits         60   \n",
       "196  regression  FTDistillHydraRegressor  binary  logits         60   \n",
       "\n",
       "     max_trees  max_depth pre_interaction  pre_max_features post_interaction  \\\n",
       "68          30          2            None               1.0             l0l2   \n",
       "56          30          2            None               1.0             l0l2   \n",
       "170         30          2            None               1.0             l0l2   \n",
       "266         30          2            None               1.0             l0l2   \n",
       "284         30          2            None               1.0             l0l2   \n",
       "203         30          2            None               1.0             l0l2   \n",
       "47          30          2            None               1.0             l0l2   \n",
       "44          30          2            None               1.0             l0l2   \n",
       "248         30          2            None               1.0             l0l2   \n",
       "115         30          2            None               1.0             l0l2   \n",
       "120         30          2            None               1.0             l0l2   \n",
       "5           30          2            None               1.0             l0l2   \n",
       "267         30          2            None               1.0             l0l2   \n",
       "102         30          2            None               1.0             l0l2   \n",
       "21          30          2            None               1.0             l0l2   \n",
       "196         30          2            None               1.0             l0l2   \n",
       "\n",
       "     ...  reg_shrink    mo  cbm_mean_accuracy_val  cbm_std_accuracy_val  \\\n",
       "68   ...         0.0  True               0.870958              0.014137   \n",
       "56   ...         0.0  True               0.858129              0.002188   \n",
       "170  ...         0.0  True               0.857726              0.012074   \n",
       "266  ...         0.0  True               0.853584              0.003354   \n",
       "284  ...         0.0  True               0.852951              0.004474   \n",
       "203  ...         0.0  True               0.851168              0.002690   \n",
       "47   ...         0.0  True               0.830687              0.015461   \n",
       "44   ...         0.0  True               0.805086              0.023392   \n",
       "248  ...         0.0  True               0.751467              0.006668   \n",
       "115  ...         0.0  True               0.704695              0.023933   \n",
       "120  ...         0.0  True               0.700610              0.008788   \n",
       "5    ...         0.0  True               0.697158              0.007182   \n",
       "267  ...         0.0  True               0.691117              0.011062   \n",
       "102  ...         0.0  True               0.675009              0.043845   \n",
       "21   ...         0.0  True               0.645668              0.029073   \n",
       "196  ...         0.0  True               0.620872              0.016176   \n",
       "\n",
       "     cbm_mean_accuracy_train  cbm_std_accuracy_train  true_mean_accuracy_val  \\\n",
       "68                  0.981228                0.005957                0.743470   \n",
       "56                  0.980559                0.007118                0.734265   \n",
       "170                 0.977941                0.003320                0.736912   \n",
       "266                 0.981729                0.005494                0.739673   \n",
       "284                 0.977997                0.010040                0.726556   \n",
       "203                 0.976883                0.006315                0.735473   \n",
       "47                  0.927362                0.016961                0.720746   \n",
       "44                  0.911096                0.031481                0.705960   \n",
       "248                 0.922906                0.017556                0.664423   \n",
       "115                 0.780916                0.027015                0.619722   \n",
       "120                 0.977718                0.004051                0.629502   \n",
       "5                   0.972315                0.002176                0.630422   \n",
       "267                 0.899677                0.013359                0.630652   \n",
       "102                 0.768215                0.052884                0.605914   \n",
       "21                  0.800524                0.026436                0.577609   \n",
       "196                 0.807877                0.018252                0.564665   \n",
       "\n",
       "     true_std_accuracy_val  true_mean_accuracy_train  true_std_accuracy_train  \n",
       "68                0.005416                  0.972037                 0.001853  \n",
       "56                0.004109                  0.976771                 0.002482  \n",
       "170               0.004769                  0.966355                 0.003052  \n",
       "266               0.001279                  0.976660                 0.002597  \n",
       "284               0.003324                  0.968471                 0.009077  \n",
       "203               0.000215                  0.967525                 0.006124  \n",
       "47                0.012448                  0.927418                 0.017584  \n",
       "44                0.018109                  0.913603                 0.026958  \n",
       "248               0.006794                  0.917502                 0.012928  \n",
       "115               0.015847                  0.783701                 0.028518  \n",
       "120               0.003383                  0.968639                 0.003112  \n",
       "5                 0.005333                  0.970087                 0.001550  \n",
       "267               0.008125                  0.902574                 0.011794  \n",
       "102               0.036087                  0.768438                 0.052972  \n",
       "21                0.026133                  0.799855                 0.021979  \n",
       "196               0.009877                  0.804980                 0.019336  \n",
       "\n",
       "[16 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[r.model_name == 'FTDistillHydraRegressor'].sort_values('cbm_mean_accuracy_val', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_plot = plotting[['model_name', 'cbm_mean_accuracy_train', 'cbm_mean_accuracy_val']].set_index('model_name').round(2).rename(columns = {'cbm_mean_accuracy_val':'test accuracy', 'cbm_mean_accuracy_train':'train accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_plot = plotting[['model_name', 'true_mean_accuracy_train', 'true_mean_accuracy_val']].set_index('model_name').round(2).rename(columns = {'true_mean_accuracy_val':'test accuracy', 'true_mean_accuracy_train':'train accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true = plotting[['model_name', 'true_mean_accuracy_train', 'true_mean_accuracy_val']].set_index('model_name').round(2).rename(columns = {'true_mean_accuracy_val':'test accuracy', 'true_mean_accuracy_train':'train accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98468137, 0.77712576])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbm_scores = np.zeros((3, 2))\n",
    "\n",
    "for seed in range(1, 4):\n",
    "    X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat = load_csvs(f'/home/mattyshen/interpretableDistillation/interpretDistill/data/cbm_datasets/seed0_Joint0.01SigmoidModel__Seed{seed}')\n",
    "    cbm_scores[seed-1, 0] = accuracy_score(y_train_hat.idxmax(axis=1).astype(int), y_train)\n",
    "    cbm_scores[seed-1, 1] = accuracy_score(y_test_hat.idxmax(axis=1).astype(int), y_test)\n",
    "\n",
    "cbm_scores.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_plot.loc['CBM'] = cbm_scores.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_plot = true_plot.sort_values('test accuracy', ascending=False)\n",
    "cbm_plot = cbm_plot.sort_values('test accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FTDistillClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGSRegressor</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTDistillHydraRegressor</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTDistillHydraRegressor (No Interactions)</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGSHydraRegressor</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIGSClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFRegressor</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTRegressor</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTClassifier</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train accuracy  test accuracy\n",
       "model_name                                                              \n",
       "FTDistillClassifier                                  1.00           0.95\n",
       "FIGSRegressor                                        0.99           0.93\n",
       "xgboost                                              0.99           0.93\n",
       "RFClassifier                                         1.00           0.90\n",
       "FTDistillHydraRegressor                              0.98           0.87\n",
       "FTDistillHydraRegressor (No Interactions)            0.86           0.78\n",
       "FIGSHydraRegressor                                   0.92           0.71\n",
       "FIGSClassifier                                       0.73           0.58\n",
       "RFRegressor                                          0.63           0.56\n",
       "DTRegressor                                          0.68           0.49\n",
       "DTClassifier                                         0.27           0.19"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbm_plot.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>X_type</th>\n",
       "      <th>Y_type</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>cbm_mean_accuracy_val</th>\n",
       "      <th>cbm_std_accuracy_val</th>\n",
       "      <th>cbm_mean_accuracy_train</th>\n",
       "      <th>cbm_std_accuracy_train</th>\n",
       "      <th>true_mean_accuracy_val</th>\n",
       "      <th>true_std_accuracy_val</th>\n",
       "      <th>true_mean_accuracy_train</th>\n",
       "      <th>true_std_accuracy_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>8</td>\n",
       "      <td>0.766310</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.997270</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.681279</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.984514</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926188</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.993928</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.762053</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.981061</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>probs</td>\n",
       "      <td>logits</td>\n",
       "      <td>3</td>\n",
       "      <td>0.811299</td>\n",
       "      <td>0.011422</td>\n",
       "      <td>0.989862</td>\n",
       "      <td>0.001268</td>\n",
       "      <td>0.710850</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.983456</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>3</td>\n",
       "      <td>0.912611</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.994931</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.762916</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.981228</td>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900587</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.995766</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.750834</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.001616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>8</td>\n",
       "      <td>0.893223</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>0.997828</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.755897</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.002399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>8</td>\n",
       "      <td>0.902658</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.997716</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.752733</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.985684</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>8</td>\n",
       "      <td>0.598550</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.999610</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.546888</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.984514</td>\n",
       "      <td>0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>probs</td>\n",
       "      <td>probs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.607237</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>0.998830</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.553504</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>0.984793</td>\n",
       "      <td>0.001660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.756472</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.994652</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.671039</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.983512</td>\n",
       "      <td>0.003752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>logits</td>\n",
       "      <td>3</td>\n",
       "      <td>0.806294</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.993984</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.711138</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.983679</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>regression</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>binary</td>\n",
       "      <td>probs</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891037</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.996101</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.753941</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.982342</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      task_type model_name  X_type  Y_type  max_depth  cbm_mean_accuracy_val  \\\n",
       "39   regression    xgboost  binary   probs          8               0.766310   \n",
       "51   regression    xgboost  binary  logits          3               0.926188   \n",
       "70   regression    xgboost   probs  logits          3               0.811299   \n",
       "73   regression    xgboost  binary  logits          3               0.912611   \n",
       "97   regression    xgboost  binary   probs          3               0.900587   \n",
       "132  regression    xgboost  binary   probs          8               0.893223   \n",
       "150  regression    xgboost  binary   probs          8               0.902658   \n",
       "180  regression    xgboost   probs   probs          8               0.598550   \n",
       "187  regression    xgboost   probs   probs          3               0.607237   \n",
       "219  regression    xgboost  binary   probs          3               0.756472   \n",
       "225  regression    xgboost  binary  logits          3               0.806294   \n",
       "291  regression    xgboost  binary   probs          3               0.891037   \n",
       "\n",
       "     cbm_std_accuracy_val  cbm_mean_accuracy_train  cbm_std_accuracy_train  \\\n",
       "39               0.004516                 0.997270                0.000877   \n",
       "51               0.005709                 0.993928                0.003256   \n",
       "70               0.011422                 0.989862                0.001268   \n",
       "73               0.005422                 0.994931                0.002480   \n",
       "97               0.007519                 0.995766                0.001111   \n",
       "132              0.006315                 0.997828                0.001117   \n",
       "150              0.006014                 0.997716                0.000834   \n",
       "180              0.018708                 0.999610                0.000079   \n",
       "187              0.014322                 0.998830                0.000546   \n",
       "219              0.005771                 0.994652                0.000955   \n",
       "225              0.004771                 0.993984                0.000984   \n",
       "291              0.006956                 0.996101                0.000929   \n",
       "\n",
       "     true_mean_accuracy_val  true_std_accuracy_val  true_mean_accuracy_train  \\\n",
       "39                 0.681279               0.004935                  0.984514   \n",
       "51                 0.762053               0.003092                  0.981061   \n",
       "70                 0.710850               0.009915                  0.983456   \n",
       "73                 0.762916               0.004070                  0.981228   \n",
       "97                 0.750834               0.004314                  0.982063   \n",
       "132                0.755897               0.005330                  0.983957   \n",
       "150                0.752733               0.004221                  0.985684   \n",
       "180                0.546888               0.017172                  0.984514   \n",
       "187                0.553504               0.011315                  0.984793   \n",
       "219                0.671039               0.008428                  0.983512   \n",
       "225                0.711138               0.003870                  0.983679   \n",
       "291                0.753941               0.005498                  0.982342   \n",
       "\n",
       "     true_std_accuracy_train  \n",
       "39                  0.002442  \n",
       "51                  0.002325  \n",
       "70                  0.001438  \n",
       "73                  0.004058  \n",
       "97                  0.001616  \n",
       "132                 0.002399  \n",
       "150                 0.001853  \n",
       "180                 0.001969  \n",
       "187                 0.001660  \n",
       "219                 0.003752  \n",
       "225                 0.004600  \n",
       "291                 0.000417  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[r.model_name=='xgboost'].drop(columns=['max_rules', 'max_trees', 'pre_interaction', 'pre_max_features', 'post_interaction', 'post_max_features', 'thresh', 'reg_depth','shrink_depth','reg_shrink','mo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy(df, title, mean_val_col, std_val_col, mean_train_col, std_train_col):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Bar positions\n",
    "    indices = np.arange(len(df['model_name']))\n",
    "\n",
    "    # Bar widths\n",
    "    bar_width = 0.35\n",
    "\n",
    "    # Plot bars for validation accuracy\n",
    "    ax.bar(indices, df[mean_val_col], bar_width, yerr=df[std_val_col], label='Test Accuracy', capsize=5)\n",
    "\n",
    "    # Plot bars for training accuracy\n",
    "    ax.bar(indices + bar_width, df[mean_train_col], bar_width, yerr=df[std_train_col], label='Training/Validation Accuracy', capsize=5)\n",
    "\n",
    "    # Add some text for labels, title, and axes ticks\n",
    "    ax.set_xticklabels(indices, rotation=45, fontsize=7)\n",
    "    ax.set_xlabel('Model Name')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(indices + bar_width / 2)\n",
    "    ax.set_xticklabels(df['model_name'])\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cbm_distillation_accuracy.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot for CBM accuracies\n",
    "plot_accuracy(plotting.sort_values('cbm_mean_accuracy_val', ascending=False), 'CBM Distillation Accuracy', 'cbm_mean_accuracy_val', 'cbm_std_accuracy_val', 'cbm_mean_accuracy_train', 'cbm_std_accuracy_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_with_hlines(df, title, mean_val_col, std_val_col, mean_train_col, std_train_col, cbm_scores):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Bar positions\n",
    "    indices = np.arange(len(df['model_name']))\n",
    "\n",
    "    # Bar widths\n",
    "    bar_width = 0.35\n",
    "\n",
    "    # Plot bars for validation accuracy\n",
    "    ax.bar(indices, df[mean_val_col], bar_width, yerr=df[std_val_col], label='Test Accuracy', capsize=5)\n",
    "\n",
    "    # Plot bars for training accuracy\n",
    "    ax.bar(indices + bar_width, df[mean_train_col], bar_width, yerr=df[std_train_col], label='Training/Validation Accuracy', capsize=5)\n",
    "\n",
    "    # Add horizontal lines for train and test scores with std from cbm_scores\n",
    "    train_mean = cbm_scores[:, 0].mean()\n",
    "    train_std = cbm_scores[:, 0].std()\n",
    "    test_mean = cbm_scores[:, 1].mean()\n",
    "    test_std = cbm_scores[:, 1].std()\n",
    "\n",
    "    ax.axhline(y=train_mean, color='orange', linestyle='--', label=f'CBM Train/Val Accuracy: {train_mean:.2f}')\n",
    "    ax.fill_between([indices[0] - bar_width, indices[-1] + bar_width * 2], \n",
    "                    train_mean - train_std, train_mean + train_std, color='orange', alpha=0.2)\n",
    "\n",
    "    # Horizontal line for test scores with std\n",
    "    ax.axhline(y=test_mean, color='blue', linestyle='--', label=f'CBM Test Accuracy: {test_mean:.2f}')\n",
    "    ax.fill_between([indices[0] - bar_width, indices[-1] + bar_width * 2], \n",
    "                    test_mean - test_std, test_mean + test_std, color='blue', alpha=0.2)\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xticklabels(indices, rotation=45, fontsize=7)\n",
    "    ax.set_xlabel('Model Name')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(indices + bar_width / 2)\n",
    "    ax.set_xticklabels(df['model_name'])\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cbm_true_accuracy.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot for True accuracies with horizontal lines\n",
    "plot_accuracy_with_hlines(plotting.sort_values('cbm_mean_accuracy_val', ascending=False), 'True Accuracy with CBM Accuracy', \n",
    "                          'true_mean_accuracy_val', 'true_std_accuracy_val', \n",
    "                          'true_mean_accuracy_train', 'true_std_accuracy_train', cbm_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r[\"model_name\"]==\"FIGSRegressor\"].sort_values('cbm_mean_accuracy_val', ascending=False).drop(columns=['task_type', 'model_name','save_dir', \n",
    "                                                                                                     'save_dir_unique', 'use_cache']+\n",
    "                                                                                           [f'true_seed{seed}_accuracy_val' for seed in range(1, 4)]+\n",
    "                                                                                           [f'true_seed{seed}_accuracy_train' for seed in range(1, 4)]+\n",
    "                                                                                           [f'cbm_seed{seed}_accuracy_val' for seed in range(1, 4)]+\n",
    "                                                                                           [f'cbm_seed{seed}_accuracy_train' for seed in range(1, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r[\"model_name\"]==\"ft_distill\"].sort_values('cbm_mean_accuracy_val', ascending=False).drop(columns=['task_type', 'model_name', \n",
    "                                                                                                     'X_type', 'Y_type', 'save_dir', \n",
    "                                                                                                     'save_dir_unique', 'use_cache',\n",
    "                                                                                                    'max_rules', 'max_trees']+\n",
    "                                                                                           [f'true_seed{seed}_accuracy_val' for seed in range(1, 4)]+\n",
    "                                                                                           [f'true_seed{seed}_accuracy_train' for seed in range(1, 4)]+\n",
    "                                                                                           [f'cbm_seed{seed}_accuracy_val' for seed in range(1, 4)]+\n",
    "                                                                                           [f'cbm_seed{seed}_accuracy_train' for seed in range(1, 4)]) #[['pre_interaction', 'pre_max_features', 'post_interaction', 'post_max_features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['figs_training_time'].mean(), r['ftd_training_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_histogram_for_dataset(df, dataset_name, train=False):\n",
    "    # Set the aesthetics for the plots\n",
    "    sns.set_context(\"talk\", font_scale=5)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    train_str = 'train' if train else 'val'\n",
    "\n",
    "    # Create a catplot for model_name and distiller_name\n",
    "    sns.set(font_scale=1.25)\n",
    "    g = sns.catplot(\n",
    "        data=df,\n",
    "        x='dataset_name',\n",
    "        y=f'{train_str}_r2',\n",
    "        hue='model_name',\n",
    "        kind='bar',\n",
    "        height=6,\n",
    "        aspect=2,\n",
    "    )\n",
    "    \n",
    "    # Set the title and labels\n",
    "    if train:\n",
    "        g.fig.suptitle(f'Best Train R2 Scores for FIGS, FT Distill, Ridge', fontsize=25)\n",
    "        g.set_axis_labels(\"Model Name\", \"Train R2 Score\", fontsize=25)\n",
    "    else:\n",
    "        g.fig.suptitle(f'Best Val R2 Scores for FIGS, FT Distill, Ridge', fontsize=25)\n",
    "        g.set_axis_labels(\"Model Name\", \"Val R2 Score\", fontsize=25)\n",
    "    #g._legend.set_title('Distiller Name')\n",
    "    sns.move_legend(g, bbox_to_anchor=(1,0.5), loc=\"center left\", markerscale=5, title=\"model\")\n",
    "    \n",
    "    # Adjust the layout\n",
    "    plt.yticks(ticks=np.arange(0, 1.09, 0.1))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    g.savefig(f'plots/{dataset_name}_{train_str}_r2.png', bbox_inches='tight')\n",
    "#hue=df[['distiller_name', 'binary_mapper_name']].apply(tuple, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['max_rules'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(r['ftd_r2_score_val']/r['figs_r2_score_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.iloc[73, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((r[r['max_rules'] == 20]['ftd_r2_score_val']/r[r['max_rules'] == 20]['figs_r2_score_val'])*100 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((r[r['max_rules'] == 30]['ftd_r2_score_val']/r[r['max_rules'] == 30]['figs_r2_score_val'])*100-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((r['ftd_r2_score_val']/r['figs_r2_score_val'])*100-100, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ftd_r2_score_val', ascending=False).iloc[0,:])[['figs_max_interaction_size', 'ftd_max_interaction_size', 'num_common_interactions', 'figs_training_time' , 'ftd_training_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(metrics, id_vars='dataset_name', value_vars=['figs_max_interaction_size', 'ftd_max_interaction_size'],\n",
    "                    var_name='model_name', value_name='max_interaction_size')\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "# Create a categorical plot\n",
    "g = sns.catplot(\n",
    "    data=df_melted, \n",
    "    x='dataset_name', \n",
    "    y='max_interaction_size', \n",
    "    hue='model_name', \n",
    "    kind='bar', \n",
    "    height=5, \n",
    "    aspect=2\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Max Interaction Size by Dataset for Best Val R2 Model')\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel('Max Interaction Size')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "g.savefig(f'plots/interaction_size.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = r.groupby(['dataset_name'])[['figs_max_interaction_size', 'ftd_max_interaction_size']].mean().reset_index().rename(columns={'figs_max_interaction_size':'figs', 'ftd_max_interaction_size':'ftd'})\n",
    "df_melted = pd.melt(int_df, id_vars='dataset_name', value_vars=['figs', 'ftd'],\n",
    "                    var_name='model_name', value_name='max_interaction_size')\n",
    "\n",
    "# Create a categorical plot\n",
    "g = sns.catplot(\n",
    "    data=df_melted, \n",
    "    x='dataset_name', \n",
    "    y='max_interaction_size', \n",
    "    hue='model_name', \n",
    "    kind='bar', \n",
    "    height=5, \n",
    "    aspect=2\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Mean Max Interaction Size by Dataset')\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel('Mean Max Interaction Size')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "g.savefig(f'plots/interaction_size.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ftd_r2_score_val', ascending=False).iloc[0,:])[['ftd_r2_score_train', 'ftd_r2_score_val']]\n",
    "figs = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='figs_r2_score_val', ascending=False).iloc[0,:])[['figs_r2_score_train', 'figs_r2_score_val']]\n",
    "ridge_decoup = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_figs_decoup_r2_score_val', ascending=False).iloc[0,:])[['ridge_figs_decoup_r2_score_train', 'ridge_figs_decoup_r2_score_val']]\n",
    "ridge_inter = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_figs_inter_r2_score_val', ascending=False).iloc[0,:])[['ridge_figs_inter_r2_score_train', 'ridge_figs_inter_r2_score_val']]\n",
    "xgb = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='xgboost_r2_score_val', ascending=False).iloc[0,:])[['xgboost_r2_score_train', 'xgboost_r2_score_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd['model_name'] = 'ft_distill'\n",
    "figs['model_name'] = 'figs'\n",
    "ridge_decoup['model_name'] = 'ridge_decoup'\n",
    "ridge_inter['model_name'] = 'ridge_inter'\n",
    "xgb['model_name'] = 'xgboost'\n",
    "ftd = ftd.rename(columns = {'ftd_r2_score_train':'train_r2', 'ftd_r2_score_val':'val_r2'})\n",
    "figs= figs.rename(columns = {'figs_r2_score_train':'train_r2', 'figs_r2_score_val':'val_r2'})\n",
    "ridge_decoup= ridge_decoup.rename(columns = {'ridge_figs_decoup_r2_score_train':'train_r2', 'ridge_figs_decoup_r2_score_val':'val_r2'})\n",
    "ridge_inter= ridge_inter.rename(columns = {'ridge_figs_inter_r2_score_train':'train_r2', 'ridge_figs_inter_r2_score_val':'val_r2'})\n",
    "xgb= xgb.rename(columns = {'xgboost_r2_score_train':'train_r2', 'xgboost_r2_score_val':'val_r2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.concat([ftd, figs, ridge_decoup, ridge_inter, xgb], axis = 0)\n",
    "models.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_p_improve(base, comp, round_degree = 2):\n",
    "    core = np.round((comp.drop(columns = {'model_name'}).values/base.drop(columns = {'model_name'}).values), round_degree)*100-100\n",
    "    return pd.DataFrame(core, columns = comp.columns[:-1]).set_index([comp.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_p_improve(figs, ftd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_p_improve(figs, ridge_decoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_p_improve(figs, ridge_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_dataset(models, 'figs_sim', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['num_common_interactions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = r.groupby(['dataset_name'])[['figs_max_interaction_size', 'ftd_max_interaction_size']].mean().reset_index().rename(columns={'figs_max_interaction_size':'figs', 'ftd_max_interaction_size':'ftd'})\n",
    "df_melted = pd.melt(int_df, id_vars='dataset_name', value_vars=['figs', 'ftd'],\n",
    "                    var_name='model_name', value_name='max_interaction_size')\n",
    "\n",
    "# Create a categorical plot\n",
    "g = sns.catplot(\n",
    "    data=df_melted, \n",
    "    x='dataset_name', \n",
    "    y='max_interaction_size', \n",
    "    hue='model_name', \n",
    "    kind='bar', \n",
    "    height=5, \n",
    "    aspect=2\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Mean Max Interaction Size by Dataset')\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel('Mean Max Interaction Size')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "g.savefig(f'plots/interaction_size.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['num_common_interactions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['ftd_max_interaction_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ftd_r2_score_val', ascending=False).iloc[0,:])[['ftd_r2_score_train', 'ftd_r2_score_val']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='figs_r2_score_val', ascending=False).iloc[0,:])[['figs_r2_score_train', 'figs_r2_score_val']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_r2_score_val', ascending=False).iloc[0,:])[['ridge_r2_score_train', 'ridge_r2_score_val']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd['model_name'] = 'ft_distill'\n",
    "figs['model_name'] = 'figs'\n",
    "ridge['model_name'] = 'ridge'\n",
    "ftd = ftd.rename(columns = {'ftd_r2_score_train':'train_r2', 'ftd_r2_score_val':'val_r2'})\n",
    "figs= figs.rename(columns = {'figs_r2_score_train':'train_r2', 'figs_r2_score_val':'val_r2'})\n",
    "ridge= ridge.rename(columns = {'ridge_r2_score_train':'train_r2', 'ridge_r2_score_val':'val_r2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.concat([ftd, figs, ridge], axis = 0)\n",
    "models.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_dataset(models, 'figs_sim', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_r2_score_val', ascending=False).iloc[0,:])[['dataset_name', 'binary_mapper_frac', 'ridge_r2_score_train', 'ridge_r2_score_val', 'max_features']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = r.groupby(['model_name', 'distiller_name', 'binary_mapper_name'])['val_r2'].mean().reset_index() #.apply(lambda sdf: sdf.sort_values(by='val_r2', ascending=False).iloc[0,:])\n",
    "df.loc[:, 'distiller+binary_mapper'] = df['distiller_name'] + ' + '+ df['binary_mapper_name'] #(df['distiller_name'] == 'None').map(lambda x: 'original_model' if x else '') + (df['distiller_name'] + \" + \" + df['binary_mapper_name'])*(df['distiller_name'] != 'None').to_numpy()\n",
    "plot_histogram_for_dataset(df, 'all datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['n_epochs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r['model_name'] == 'ft_distill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = r['dataset_name'].unique()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.groupby(['dataset_name', 'binary_mapper_name'])[['teacher_r2_score_train_true', 'distiller_r2_score_train_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[(r['distiller_name']=='ft_distill') & (r['max_depth']==5) & (r['max_features']==0.75)] #['max_features'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF params: max_depth, max_features\n",
    "random_forest= r[r['model_name'] == 'random_forest'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "random_forest_g = random_forest.groupby(['dataset_name','model_name', 'max_depth', 'max_features', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.groupby(['max_depth', 'max_features', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_best_hyp = {}\n",
    "# for d in datasets:\n",
    "#     queried = random_forest_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth', 'max_features'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     random_forest_best_hyp[d] = d_best_hyp\n",
    "# random_forest_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF+ params: max_depth, max_features\n",
    "rf_plus = r[r['model_name'] == 'rf_plus'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "rf_plus_g = rf_plus.groupby(['dataset_name','model_name', 'max_depth', 'max_features', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()\n",
    "rf_plus_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus.groupby(['max_depth', 'max_features', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_plus_best_hyp = {}\n",
    "# for d in datasets:\n",
    "#     queried = rf_plus_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth', 'max_features'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     rf_plus_best_hyp[d] = d_best_hyp\n",
    "# rf_plus_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGS params: max_rules, max_trees, max_features\n",
    "figs = r[r['model_name'] == 'figs'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_depth','pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "figs_g = figs.groupby(['dataset_name','model_name', 'max_rules','max_trees', 'max_features', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean().round(2)\n",
    "figs_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs.groupby(['max_rules', 'max_trees', 'max_features', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF+ params: max_depth, max_features\n",
    "xgboost = r[r['model_name'] == 'xgboost'].drop(columns=['subsample_frac', 'save_dir','use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features'])\n",
    "xgboost_g = xgboost.groupby(['dataset_name','model_name', 'max_depth', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean().round(2)\n",
    "xgboost_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.groupby(['max_depth', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_best_hyp = {}\n",
    "# for d in datasets:\n",
    "#     queried = xgboost_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     xgboost_best_hyp[d] = d_best_hyp\n",
    "# xgboost_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet params: n_epochs\n",
    "resnet = r[r['model_name'] == 'resnet'].drop(columns=['subsample_frac', 'save_dir','use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features', 'max_depth'])\n",
    "resnet_g = resnet.groupby(['dataset_name','model_name', 'n_epochs', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()\n",
    "resnet_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.groupby(['n_epochs', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_best_hyp = {}\n",
    "# for d in resnet['dataset_name'].unique():\n",
    "#     queried = resnet_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name','n_epochs'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     resnet_best_hyp[d] = d_best_hyp\n",
    "# resnet_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FT Transformer params: n_epochs\n",
    "ft_transformer = r[r['model_name'] == 'ft_transformer'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features', 'max_depth'])\n",
    "ft_transformer_g = ft_transformer.groupby(['dataset_name','model_name', 'n_epochs', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()\n",
    "ft_transformer_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_transformer.groupby(['n_epochs', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_transformer_best_hyp = {}\n",
    "# for d in ft_transformer['dataset_name'].unique():\n",
    "#     queried = ft_transformer_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name','n_epochs'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     ft_transformer_best_hyp[d] = d_best_hyp\n",
    "# ft_transformer_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp = {}\n",
    "for m in ['random_forest', 'rf_plus', 'figs', 'xgboost', 'resnet', 'ft_transformer']:\n",
    "    best_hyp[m] = eval(f'{m}_best_hyp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "with open('/home/mattyshen/interpretableDistillation/scripts/best_hyperparams/original_hyperparams.json', \"w\") as outfile: \n",
    "    json.dump(best_hyp, outfile, cls =NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
