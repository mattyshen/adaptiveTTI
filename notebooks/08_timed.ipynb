{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import imodelsx.process_results\n",
    "import sys\n",
    "sys.path.append('../experiments/')\n",
    "results = []\n",
    "\n",
    "results_dir = f'../results/08_timed'\n",
    "experiment_filename = '../experiments/08_figs_restructure.py'\n",
    "\n",
    "# load the results in to a pandas dataframe\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "cols_varied = imodelsx.process_results.get_experiment_keys(\n",
    "    r, experiment_filename)\n",
    "print('experiment varied these params:', cols_varied)\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(\n",
    "    r, experiment_filename)\n",
    "\n",
    "# get the breakdown of data in these groups\n",
    "r.groupby(cols_varied).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['figs_training_time'].mean(), r['ftd_training_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_histogram_for_dataset(df, dataset_name, train=False):\n",
    "    # Set the aesthetics for the plots\n",
    "    sns.set_context(\"talk\", font_scale=5)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    train_str = 'train' if train else 'val'\n",
    "\n",
    "    # Create a catplot for model_name and distiller_name\n",
    "    sns.set(font_scale=1.25)\n",
    "    g = sns.catplot(\n",
    "        data=df,\n",
    "        x='dataset_name',\n",
    "        y=f'{train_str}_r2',\n",
    "        hue='model_name',\n",
    "        kind='bar',\n",
    "        height=6,\n",
    "        aspect=2,\n",
    "    )\n",
    "    \n",
    "    # Set the title and labels\n",
    "    if train:\n",
    "        g.fig.suptitle(f'Best Train R2 Scores for FIGS, FT Distill, Ridge', fontsize=25)\n",
    "        g.set_axis_labels(\"Model Name\", \"Train R2 Score\", fontsize=25)\n",
    "    else:\n",
    "        g.fig.suptitle(f'Best Val R2 Scores for FIGS, FT Distill, Ridge', fontsize=25)\n",
    "        g.set_axis_labels(\"Model Name\", \"Val R2 Score\", fontsize=25)\n",
    "    #g._legend.set_title('Distiller Name')\n",
    "    sns.move_legend(g, bbox_to_anchor=(1,0.5), loc=\"center left\", markerscale=5, title=\"model\")\n",
    "    \n",
    "    # Adjust the layout\n",
    "    plt.yticks(ticks=np.arange(0, 1.09, 0.1))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    g.savefig(f'plots/{dataset_name}_{train_str}_r2.png', bbox_inches='tight')\n",
    "#hue=df[['distiller_name', 'binary_mapper_name']].apply(tuple, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['max_rules'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(r['ftd_r2_score_val']/r['figs_r2_score_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.iloc[73, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((r[r['max_rules'] == 20]['ftd_r2_score_val']/r[r['max_rules'] == 20]['figs_r2_score_val'])*100 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((r[r['max_rules'] == 30]['ftd_r2_score_val']/r[r['max_rules'] == 30]['figs_r2_score_val'])*100-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((r['ftd_r2_score_val']/r['figs_r2_score_val'])*100-100, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ftd_r2_score_val', ascending=False).iloc[0,:])[['figs_max_interaction_size', 'ftd_max_interaction_size', 'num_common_interactions', 'figs_training_time' , 'ftd_training_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(metrics, id_vars='dataset_name', value_vars=['figs_max_interaction_size', 'ftd_max_interaction_size'],\n",
    "                    var_name='model_name', value_name='max_interaction_size')\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "# Create a categorical plot\n",
    "g = sns.catplot(\n",
    "    data=df_melted, \n",
    "    x='dataset_name', \n",
    "    y='max_interaction_size', \n",
    "    hue='model_name', \n",
    "    kind='bar', \n",
    "    height=5, \n",
    "    aspect=2\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Max Interaction Size by Dataset for Best Val R2 Model')\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel('Max Interaction Size')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "g.savefig(f'plots/interaction_size.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = r.groupby(['dataset_name'])[['figs_max_interaction_size', 'ftd_max_interaction_size']].mean().reset_index().rename(columns={'figs_max_interaction_size':'figs', 'ftd_max_interaction_size':'ftd'})\n",
    "df_melted = pd.melt(int_df, id_vars='dataset_name', value_vars=['figs', 'ftd'],\n",
    "                    var_name='model_name', value_name='max_interaction_size')\n",
    "\n",
    "# Create a categorical plot\n",
    "g = sns.catplot(\n",
    "    data=df_melted, \n",
    "    x='dataset_name', \n",
    "    y='max_interaction_size', \n",
    "    hue='model_name', \n",
    "    kind='bar', \n",
    "    height=5, \n",
    "    aspect=2\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Mean Max Interaction Size by Dataset')\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel('Mean Max Interaction Size')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "g.savefig(f'plots/interaction_size.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ftd_r2_score_val', ascending=False).iloc[0,:])[['ftd_r2_score_train', 'ftd_r2_score_val']]\n",
    "figs = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='figs_r2_score_val', ascending=False).iloc[0,:])[['figs_r2_score_train', 'figs_r2_score_val']]\n",
    "ridge_decoup = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_figs_decoup_r2_score_val', ascending=False).iloc[0,:])[['ridge_figs_decoup_r2_score_train', 'ridge_figs_decoup_r2_score_val']]\n",
    "ridge_inter = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_figs_inter_r2_score_val', ascending=False).iloc[0,:])[['ridge_figs_inter_r2_score_train', 'ridge_figs_inter_r2_score_val']]\n",
    "xgb = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='xgboost_r2_score_val', ascending=False).iloc[0,:])[['xgboost_r2_score_train', 'xgboost_r2_score_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd['model_name'] = 'ft_distill'\n",
    "figs['model_name'] = 'figs'\n",
    "ridge_decoup['model_name'] = 'ridge_decoup'\n",
    "ridge_inter['model_name'] = 'ridge_inter'\n",
    "xgb['model_name'] = 'xgboost'\n",
    "ftd = ftd.rename(columns = {'ftd_r2_score_train':'train_r2', 'ftd_r2_score_val':'val_r2'})\n",
    "figs= figs.rename(columns = {'figs_r2_score_train':'train_r2', 'figs_r2_score_val':'val_r2'})\n",
    "ridge_decoup= ridge_decoup.rename(columns = {'ridge_figs_decoup_r2_score_train':'train_r2', 'ridge_figs_decoup_r2_score_val':'val_r2'})\n",
    "ridge_inter= ridge_inter.rename(columns = {'ridge_figs_inter_r2_score_train':'train_r2', 'ridge_figs_inter_r2_score_val':'val_r2'})\n",
    "xgb= xgb.rename(columns = {'xgboost_r2_score_train':'train_r2', 'xgboost_r2_score_val':'val_r2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.concat([ftd, figs, ridge_decoup, ridge_inter, xgb], axis = 0)\n",
    "models.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_p_improve(base, comp, round_degree = 2):\n",
    "    core = np.round((comp.drop(columns = {'model_name'}).values/base.drop(columns = {'model_name'}).values), round_degree)*100-100\n",
    "    return pd.DataFrame(core, columns = comp.columns[:-1]).set_index([comp.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_p_improve(figs, ftd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_p_improve(figs, ridge_decoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_p_improve(figs, ridge_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_dataset(models, 'figs_sim', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['num_common_interactions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_df = r.groupby(['dataset_name'])[['figs_max_interaction_size', 'ftd_max_interaction_size']].mean().reset_index().rename(columns={'figs_max_interaction_size':'figs', 'ftd_max_interaction_size':'ftd'})\n",
    "df_melted = pd.melt(int_df, id_vars='dataset_name', value_vars=['figs', 'ftd'],\n",
    "                    var_name='model_name', value_name='max_interaction_size')\n",
    "\n",
    "# Create a categorical plot\n",
    "g = sns.catplot(\n",
    "    data=df_melted, \n",
    "    x='dataset_name', \n",
    "    y='max_interaction_size', \n",
    "    hue='model_name', \n",
    "    kind='bar', \n",
    "    height=5, \n",
    "    aspect=2\n",
    ")\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Mean Max Interaction Size by Dataset')\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel('Mean Max Interaction Size')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "g.savefig(f'plots/interaction_size.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['num_common_interactions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['ftd_max_interaction_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ftd_r2_score_val', ascending=False).iloc[0,:])[['ftd_r2_score_train', 'ftd_r2_score_val']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='figs_r2_score_val', ascending=False).iloc[0,:])[['figs_r2_score_train', 'figs_r2_score_val']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_r2_score_val', ascending=False).iloc[0,:])[['ridge_r2_score_train', 'ridge_r2_score_val']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd['model_name'] = 'ft_distill'\n",
    "figs['model_name'] = 'figs'\n",
    "ridge['model_name'] = 'ridge'\n",
    "ftd = ftd.rename(columns = {'ftd_r2_score_train':'train_r2', 'ftd_r2_score_val':'val_r2'})\n",
    "figs= figs.rename(columns = {'figs_r2_score_train':'train_r2', 'figs_r2_score_val':'val_r2'})\n",
    "ridge= ridge.rename(columns = {'ridge_r2_score_train':'train_r2', 'ridge_r2_score_val':'val_r2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.concat([ftd, figs, ridge], axis = 0)\n",
    "models.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_dataset(models, 'figs_sim', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.groupby(['dataset_name']).apply(lambda sdf: sdf.sort_values(by='ridge_r2_score_val', ascending=False).iloc[0,:])[['dataset_name', 'binary_mapper_frac', 'ridge_r2_score_train', 'ridge_r2_score_val', 'max_features']] #[['ftd_r2_score_train', 'ftd_r2_score_val', 'figs_r2_score_train', 'figs_r2_score_val']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = r.groupby(['model_name', 'distiller_name', 'binary_mapper_name'])['val_r2'].mean().reset_index() #.apply(lambda sdf: sdf.sort_values(by='val_r2', ascending=False).iloc[0,:])\n",
    "df.loc[:, 'distiller+binary_mapper'] = df['distiller_name'] + ' + '+ df['binary_mapper_name'] #(df['distiller_name'] == 'None').map(lambda x: 'original_model' if x else '') + (df['distiller_name'] + \" + \" + df['binary_mapper_name'])*(df['distiller_name'] != 'None').to_numpy()\n",
    "plot_histogram_for_dataset(df, 'all datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['n_epochs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[r['model_name'] == 'ft_distill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = r['dataset_name'].unique()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.groupby(['dataset_name', 'binary_mapper_name'])[['teacher_r2_score_train_true', 'distiller_r2_score_train_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[(r['distiller_name']=='ft_distill') & (r['max_depth']==5) & (r['max_features']==0.75)] #['max_features'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF params: max_depth, max_features\n",
    "random_forest= r[r['model_name'] == 'random_forest'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "random_forest_g = random_forest.groupby(['dataset_name','model_name', 'max_depth', 'max_features', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.groupby(['max_depth', 'max_features', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_best_hyp = {}\n",
    "# for d in datasets:\n",
    "#     queried = random_forest_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth', 'max_features'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     random_forest_best_hyp[d] = d_best_hyp\n",
    "# random_forest_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF+ params: max_depth, max_features\n",
    "rf_plus = r[r['model_name'] == 'rf_plus'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "rf_plus_g = rf_plus.groupby(['dataset_name','model_name', 'max_depth', 'max_features', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()\n",
    "rf_plus_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus.groupby(['max_depth', 'max_features', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_plus_best_hyp = {}\n",
    "# for d in datasets:\n",
    "#     queried = rf_plus_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth', 'max_features'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     rf_plus_best_hyp[d] = d_best_hyp\n",
    "# rf_plus_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGS params: max_rules, max_trees, max_features\n",
    "figs = r[r['model_name'] == 'figs'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_depth','pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "figs_g = figs.groupby(['dataset_name','model_name', 'max_rules','max_trees', 'max_features', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean().round(2)\n",
    "figs_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs.groupby(['max_rules', 'max_trees', 'max_features', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF+ params: max_depth, max_features\n",
    "xgboost = r[r['model_name'] == 'xgboost'].drop(columns=['subsample_frac', 'save_dir','use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features'])\n",
    "xgboost_g = xgboost.groupby(['dataset_name','model_name', 'max_depth', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean().round(2)\n",
    "xgboost_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.groupby(['max_depth', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_best_hyp = {}\n",
    "# for d in datasets:\n",
    "#     queried = xgboost_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     xgboost_best_hyp[d] = d_best_hyp\n",
    "# xgboost_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet params: n_epochs\n",
    "resnet = r[r['model_name'] == 'resnet'].drop(columns=['subsample_frac', 'save_dir','use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features', 'max_depth'])\n",
    "resnet_g = resnet.groupby(['dataset_name','model_name', 'n_epochs', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()\n",
    "resnet_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.groupby(['n_epochs', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_best_hyp = {}\n",
    "# for d in resnet['dataset_name'].unique():\n",
    "#     queried = resnet_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name','n_epochs'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     resnet_best_hyp[d] = d_best_hyp\n",
    "# resnet_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FT Transformer params: n_epochs\n",
    "ft_transformer = r[r['model_name'] == 'ft_transformer'].drop(columns=['subsample_frac', 'save_dir', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features', 'max_depth'])\n",
    "ft_transformer_g = ft_transformer.groupby(['dataset_name','model_name', 'n_epochs', 'bit', 'depth'])[['teacher_r2_score_train_true', 'teacher_r2_score_val_true']].mean()\n",
    "ft_transformer_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_transformer.groupby(['n_epochs', 'seed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_transformer_best_hyp = {}\n",
    "# for d in ft_transformer['dataset_name'].unique():\n",
    "#     queried = ft_transformer_g.query(f\"dataset_name == '{d}'\")\n",
    "#     d_best_hyp = dict(zip(['dataset_name','model_name','n_epochs'], list(queried['r2_score_val_true'].idxmax())))\n",
    "#     d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "#     del d_best_hyp['dataset_name']\n",
    "#     del d_best_hyp['model_name']\n",
    "#     ft_transformer_best_hyp[d] = d_best_hyp\n",
    "# ft_transformer_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp = {}\n",
    "for m in ['random_forest', 'rf_plus', 'figs', 'xgboost', 'resnet', 'ft_transformer']:\n",
    "    best_hyp[m] = eval(f'{m}_best_hyp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "with open('/home/mattyshen/interpretableDistillation/scripts/best_hyperparams/original_hyperparams.json', \"w\") as outfile: \n",
    "    json.dump(best_hyp, outfile, cls =NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
