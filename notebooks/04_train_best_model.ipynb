{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 17:48:51.664895: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-28 17:48:52.742843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1823/1823 [00:31<00:00, 57.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment varied these params: ['dataset_name', 'seed', 'model_name', 'max_depth', 'max_features', 'max_trees', 'n_epochs']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset_name  seed  model_name  max_depth  max_features  max_trees  n_epochs\n",
       "abalone       0     figs        4          0.50          20         100         1\n",
       "                                                         30         100         1\n",
       "                                           0.75          20         100         1\n",
       "                                                         30         100         1\n",
       "                                           1.00          20         100         1\n",
       "                                                                               ..\n",
       "transaction   4     rf_plus     4          1.00          30         100         1\n",
       "                                5          1.00          30         100         1\n",
       "                    xgboost     4          1.00          30         100         1\n",
       "                                5          1.00          30         100         1\n",
       "                                6          1.00          30         100         1\n",
       "Length: 1823, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import imodelsx.process_results\n",
    "import sys\n",
    "sys.path.append('../experiments/')\n",
    "results_dir = '../results/04_train_best_model'\n",
    "experiment_filename = '../experiments/01_train_model.py'\n",
    "\n",
    "# load the results in to a pandas dataframe\n",
    "r = imodelsx.process_results.get_results_df(results_dir)\n",
    "cols_varied = imodelsx.process_results.get_experiment_keys(\n",
    "    r, experiment_filename)\n",
    "print('experiment varied these params:', cols_varied)\n",
    "r = imodelsx.process_results.fill_missing_args_with_default(\n",
    "    r, experiment_filename)\n",
    "\n",
    "# get the breakdown of data in these groups\n",
    "r.groupby(cols_varied).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = r['dataset_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF params: max_depth, max_features\n",
    "random_forest= r[r['model_name'] == 'random_forest'].drop(columns=['subsample_frac', 'save_dir', 'featurizer_name', 'featurizer_frac', 'featurizer_overlap',\n",
    "                                                        'depth', 'bit', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "random_forest_g = random_forest.groupby(['dataset_name','model_name', 'max_depth', 'max_features'])[['r2_score_train_true', 'r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allstate': {'max_depth': 6,\n",
       "  'max_features': 0.5,\n",
       "  'r2_val': 0.4622840715830795},\n",
       " 'parkinsons': {'max_depth': 6,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.7524213096993081},\n",
       " 'powerplant': {'max_depth': 6,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.9438282121672575},\n",
       " 'miami_housing': {'max_depth': 6,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.8556671426021527},\n",
       " 'cpu_act': {'max_depth': 6,\n",
       "  'max_features': 0.5,\n",
       "  'r2_val': 0.9730567587088202},\n",
       " 'transaction': {'max_depth': 6,\n",
       "  'max_features': 0.5,\n",
       "  'r2_val': 0.21572899530353756},\n",
       " 'ca_housing': {'max_depth': 6,\n",
       "  'max_features': 0.5,\n",
       "  'r2_val': 0.7030792389320804},\n",
       " 'insurance': {'max_depth': 4,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.8571740981122209},\n",
       " 'mercedes': {'max_depth': 4,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.5878040706284025},\n",
       " 'abalone': {'max_depth': 6,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.5437160079110199},\n",
       " 'airfoil': {'max_depth': 6, 'max_features': 1.0, 'r2_val': 0.78256972006629},\n",
       " 'concrete': {'max_depth': 6,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.8492022821680688},\n",
       " 'qsar': {'max_depth': 6, 'max_features': 1.0, 'r2_val': 0.39048867278188115}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_best_hyp = {}\n",
    "for d in datasets:\n",
    "    queried = random_forest_g.query(f\"dataset_name == '{d}'\")\n",
    "    d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth', 'max_features'], list(queried['r2_score_val_true'].idxmax())))\n",
    "    d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "    del d_best_hyp['dataset_name']\n",
    "    del d_best_hyp['model_name']\n",
    "    random_forest_best_hyp[d] = d_best_hyp\n",
    "random_forest_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF+ params: max_depth, max_features\n",
    "rf_plus = r[r['model_name'] == 'rf_plus'].drop(columns=['subsample_frac', 'save_dir', 'featurizer_name', 'featurizer_frac', 'featurizer_overlap',\n",
    "                                                        'depth', 'bit', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "rf_plus_g = rf_plus.groupby(['dataset_name','model_name', 'max_depth', 'max_features'])[['r2_score_train_true', 'r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allstate': {'max_depth': 5,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.4857347448456884},\n",
       " 'parkinsons': {'max_depth': 6,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.7542152631148996},\n",
       " 'powerplant': {'max_depth': 6,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.9446751731190283},\n",
       " 'miami_housing': {'max_depth': 6,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.8712473379484337},\n",
       " 'cpu_act': {'max_depth': 6,\n",
       "  'max_features': 0.5,\n",
       "  'r2_val': 0.9783737223170819},\n",
       " 'transaction': {'max_depth': 5,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.20406457989161803},\n",
       " 'ca_housing': {'max_depth': 6,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.7221553430142867},\n",
       " 'insurance': {'max_depth': 4,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.860206251420065},\n",
       " 'mercedes': {'max_depth': 4,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.5894047942318578},\n",
       " 'abalone': {'max_depth': 6,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.5668616306295201},\n",
       " 'airfoil': {'max_depth': 6,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.7887936365206617},\n",
       " 'concrete': {'max_depth': 6,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.8784921130490341},\n",
       " 'qsar': {'max_depth': 5, 'max_features': 1.0, 'r2_val': 0.3631886371350036}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_plus_best_hyp = {}\n",
    "for d in datasets:\n",
    "    queried = rf_plus_g.query(f\"dataset_name == '{d}'\")\n",
    "    d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth', 'max_features'], list(queried['r2_score_val_true'].idxmax())))\n",
    "    d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "    del d_best_hyp['dataset_name']\n",
    "    del d_best_hyp['model_name']\n",
    "    rf_plus_best_hyp[d] = d_best_hyp\n",
    "rf_plus_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGS params: max_rules, max_trees, max_features\n",
    "figs = r[r['model_name'] == 'figs'].drop(columns=['subsample_frac', 'save_dir', 'featurizer_name', 'featurizer_frac', 'featurizer_overlap',\n",
    "                                                        'depth', 'bit', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_depth','pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions'])\n",
    "figs_g = figs.groupby(['dataset_name','model_name', 'max_rules','max_trees', 'max_features'])[['r2_score_train_true', 'r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allstate': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.5069910874821875},\n",
       " 'parkinsons': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.8825121344810796},\n",
       " 'powerplant': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 0.5,\n",
       "  'r2_val': 0.9374676393991448},\n",
       " 'miami_housing': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.8621672423479977},\n",
       " 'cpu_act': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.9773946580799491},\n",
       " 'transaction': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': -0.09348332723359438},\n",
       " 'ca_housing': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.7815641252184437},\n",
       " 'insurance': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 0.5,\n",
       "  'r2_val': 0.7879054740134631},\n",
       " 'mercedes': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.4982606945129011},\n",
       " 'abalone': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 0.75,\n",
       "  'r2_val': 0.4310555732638309},\n",
       " 'airfoil': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.8418877912337767},\n",
       " 'concrete': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.8820219424565234},\n",
       " 'qsar': {'max_rules': 60,\n",
       "  'max_trees': 20,\n",
       "  'max_features': 1.0,\n",
       "  'r2_val': 0.21637869968198498}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figs_best_hyp = {}\n",
    "for d in datasets:\n",
    "    queried = figs_g.query(f\"dataset_name == '{d}'\")\n",
    "    d_best_hyp = dict(zip(['dataset_name','model_name', 'max_rules', 'max_trees', 'max_features'], list(queried['r2_score_val_true'].idxmax())))\n",
    "    d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "    del d_best_hyp['dataset_name']\n",
    "    del d_best_hyp['model_name']\n",
    "    figs_best_hyp[d] = d_best_hyp\n",
    "figs_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF+ params: max_depth, max_features\n",
    "xgboost = r[r['model_name'] == 'xgboost'].drop(columns=['subsample_frac', 'save_dir', 'featurizer_name', 'featurizer_frac', 'featurizer_overlap',\n",
    "                                                        'depth', 'bit', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'n_epochs', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features'])\n",
    "xgboost_g = xgboost.groupby(['dataset_name','model_name', 'max_depth'])[['r2_score_train_true', 'r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allstate': {'max_depth': 5, 'r2_val': 0.56880074550301},\n",
       " 'parkinsons': {'max_depth': 6, 'r2_val': 0.8943154947685432},\n",
       " 'powerplant': {'max_depth': 6, 'r2_val': 0.9619338164422656},\n",
       " 'miami_housing': {'max_depth': 5, 'r2_val': 0.9154602004150789},\n",
       " 'cpu_act': {'max_depth': 4, 'r2_val': 0.9833557963371277},\n",
       " 'transaction': {'max_depth': 4, 'r2_val': 0.12749623951140837},\n",
       " 'ca_housing': {'max_depth': 6, 'r2_val': 0.8258611965361391},\n",
       " 'insurance': {'max_depth': 4, 'r2_val': 0.814687698692056},\n",
       " 'mercedes': {'max_depth': 4, 'r2_val': 0.5457945775010881},\n",
       " 'abalone': {'max_depth': 4, 'r2_val': 0.5052047848701477},\n",
       " 'airfoil': {'max_depth': 6, 'r2_val': 0.9363278907330399},\n",
       " 'concrete': {'max_depth': 4, 'r2_val': 0.9152923336616308},\n",
       " 'qsar': {'max_depth': 4, 'r2_val': 0.40006738901138306}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_best_hyp = {}\n",
    "for d in datasets:\n",
    "    queried = xgboost_g.query(f\"dataset_name == '{d}'\")\n",
    "    d_best_hyp = dict(zip(['dataset_name','model_name', 'max_depth'], list(queried['r2_score_val_true'].idxmax())))\n",
    "    d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "    del d_best_hyp['dataset_name']\n",
    "    del d_best_hyp['model_name']\n",
    "    xgboost_best_hyp[d] = d_best_hyp\n",
    "xgboost_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet params: n_epochs\n",
    "resnet = r[r['model_name'] == 'resnet'].drop(columns=['subsample_frac', 'save_dir', 'featurizer_name', 'featurizer_frac', 'featurizer_overlap',\n",
    "                                                        'depth', 'bit', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features', 'max_depth'])\n",
    "resnet_g = resnet.groupby(['dataset_name','model_name', 'n_epochs'])[['r2_score_train_true', 'r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'miami_housing': {'n_epochs': 200, 'r2_val': 0.8335230025572364},\n",
       " 'ca_housing': {'n_epochs': 200, 'r2_val': 0.7108938926826326},\n",
       " 'concrete': {'n_epochs': 100, 'r2_val': 0.5756088074295108},\n",
       " 'powerplant': {'n_epochs': 200, 'r2_val': 0.9291184240041794},\n",
       " 'parkinsons': {'n_epochs': 100, 'r2_val': 0.8453877042791884},\n",
       " 'insurance': {'n_epochs': 100, 'r2_val': 0.6193256156088197},\n",
       " 'abalone': {'n_epochs': 200, 'r2_val': 0.39101495742797854},\n",
       " 'airfoil': {'n_epochs': 100, 'r2_val': 0.35768165935684787},\n",
       " 'qsar': {'n_epochs': 200, 'r2_val': 0.1023605465888977},\n",
       " 'cpu_act': {'n_epochs': 100, 'r2_val': 0.9514864563941956}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_best_hyp = {}\n",
    "for d in resnet['dataset_name'].unique():\n",
    "    queried = resnet_g.query(f\"dataset_name == '{d}'\")\n",
    "    d_best_hyp = dict(zip(['dataset_name','model_name','n_epochs'], list(queried['r2_score_val_true'].idxmax())))\n",
    "    d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "    del d_best_hyp['dataset_name']\n",
    "    del d_best_hyp['model_name']\n",
    "    resnet_best_hyp[d] = d_best_hyp\n",
    "resnet_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FT Transformer params: n_epochs\n",
    "ft_transformer = r[r['model_name'] == 'ft_transformer'].drop(columns=['subsample_frac', 'save_dir', 'featurizer_name', 'featurizer_frac', 'featurizer_overlap',\n",
    "                                                        'depth', 'bit', 'use_cache', 'cat_mappings', 'task_type', 'save_dir_unique',\n",
    "                                                        'gpu', 'max_rules', 'max_trees', 'pre_interaction', 'post_interaction',\n",
    "                                                        'pre_max_features', 'post_max_features', 'size_interactions', 'max_features', 'max_depth'])\n",
    "ft_transformer_g = ft_transformer.groupby(['dataset_name','model_name', 'n_epochs'])[['r2_score_train_true', 'r2_score_val_true']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'powerplant': {'n_epochs': 200, 'r2_val': 0.9336203155525509},\n",
       " 'miami_housing': {'n_epochs': 100, 'r2_val': 0.8532076207192454},\n",
       " 'insurance': {'n_epochs': 200, 'r2_val': 0.6814996945201638},\n",
       " 'abalone': {'n_epochs': 100, 'r2_val': 0.44565123319625854},\n",
       " 'parkinsons': {'n_epochs': 100, 'r2_val': 0.8442809764311544},\n",
       " 'cpu_act': {'n_epochs': 200, 'r2_val': 0.9749787211418152},\n",
       " 'ca_housing': {'n_epochs': 200, 'r2_val': 0.7175731868584732},\n",
       " 'concrete': {'n_epochs': 200, 'r2_val': 0.6545138020010774},\n",
       " 'airfoil': {'n_epochs': 200, 'r2_val': 0.38982354812794223}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_transformer_best_hyp = {}\n",
    "for d in ft_transformer['dataset_name'].unique():\n",
    "    queried = ft_transformer_g.query(f\"dataset_name == '{d}'\")\n",
    "    d_best_hyp = dict(zip(['dataset_name','model_name','n_epochs'], list(queried['r2_score_val_true'].idxmax())))\n",
    "    d_best_hyp['r2_val'] = queried['r2_score_val_true'].max()\n",
    "    del d_best_hyp['dataset_name']\n",
    "    del d_best_hyp['model_name']\n",
    "    ft_transformer_best_hyp[d] = d_best_hyp\n",
    "ft_transformer_best_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp = {}\n",
    "for m in ['random_forest', 'rf_plus', 'figs', 'xgboost', 'resnet', 'ft_transformer']:\n",
    "    best_hyp[m] = eval(f'{m}_best_hyp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/mattyshen/interpretableDistillation/scripts/best_hyperparams\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile: \n\u001b[0;32m----> 4\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_hyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json \n",
    "   \n",
    "with open('/home/mattyshen/interpretableDistillation/scripts/best_hyperparams', \"w\") as outfile: \n",
    "    json.dump(best_hyp, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
