{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fd21a6-7051-4e34-a5b5-17401a775bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/aiohttp/helpers.py:107: DeprecationWarning: \"@coroutine\" decorator is deprecated since Python 3.8, use \"async def\" instead\n",
      "  def noop(*args, **kwargs):  # type: ignore\n",
      "2025-02-10 19:12:12.930469: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 19:12:14.817355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/botocore/httpsession.py:34: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\n",
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, f1_score\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import imodels\n",
    "import inspect\n",
    "import os.path\n",
    "import sys\n",
    "import psutil\n",
    "import imodelsx.cache_save_utils\n",
    "import time\n",
    "import torch\n",
    "\n",
    "### TODO: fill in import statements and correct path###\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import idistill.model\n",
    "import idistill.data\n",
    "from idistill.whitebox_figs import FIGSRegressorCV\n",
    "\n",
    "def distill_model(student, X_train_teacher, y_train_teacher, r, feature_names = None):\n",
    "    \"\"\"Distill the teacher model using the student model\n",
    "    \n",
    "        Paramaters: \n",
    "            student: student model\n",
    "            X_train_teacher (n_train, n_concepts): teacher model's predicted concept outputs (logits, probabilties, etc) for training data\n",
    "            y_train_teacher (n_train, n_outputs): teacher model's predicted task outputs (logits, probabilities, etc) for training data\n",
    "            r: default dictionary to log experiment metrics\n",
    "            feature_names: feature names of X_train_teacher\n",
    "            \n",
    "        Returns:\n",
    "            r: default dictionary to log experiment metrics\n",
    "            student: trained/distilled student model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    fit_parameters = inspect.signature(student.fit).parameters.keys()\n",
    "    if \"feature_names\" in fit_parameters and feature_names is not None:\n",
    "        student.fit(X_train_teacher, y_train_teacher, feature_names=feature_names)\n",
    "    else:\n",
    "        student.fit(X_train_teacher, y_train_teacher)\n",
    "\n",
    "    return r, student\n",
    "\n",
    "def evaluate_student(student, X_train, X_test, y_train, y_test, metric, task, r):\n",
    "    \"\"\"Evaluate student performance on each split\n",
    "    \n",
    "        Paramaters: \n",
    "            student: student model\n",
    "            X_train (n_train, n_concepts): teacher model's predicted concept outputs (logits, probabilties, etc) for training data\n",
    "            X_test (n_test, n_concepts): teacher model's predicted concept outputs (logits, probabilties, etc) for test data\n",
    "            y_train (n_train, 1): teacher model's predicted task outputs in evaluation form (i.e. if classification task, y_train_teacher must be class predictions, not class logits) OR true outputs for train data\n",
    "            y_test (n_test, 1): teacher model's predicted task outputs in evaluation form OR true outputs for test data\n",
    "            metric: metric to log \n",
    "            task: task to log (i.e. if evaluating distillation performance, task would be `distillation`)\n",
    "            r: default dictionary to log experiment metrics\n",
    "            \n",
    "        Returns:\n",
    "            r: default dictionary to log experiment metrics\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"mse\": mean_squared_error,\n",
    "            \"r2\": r2_score,\n",
    "            \"f1\": f1_score,\n",
    "        \n",
    "        }\n",
    "    \n",
    "    metric_fn = metrics[metric]\n",
    "    \n",
    "    for split_name, (X_, y_) in zip(\n",
    "        [\"train\", \"test\"], [(X_train, y_train), (X_test, y_test)]\n",
    "    ):\n",
    "        y_pred_ = process_student_eval(student.predict(X_))\n",
    "        r[f\"student_{task}_{split_name}_{metric}\"] = metric_fn(y_, y_pred_)\n",
    "\n",
    "    return r\n",
    "\n",
    "def evaluate_teacher(y_train_teacher, y_test_teacher, y_train, y_test, metric, task, r):\n",
    "    \"\"\"Evaluate teacher performance on each split\n",
    "    \n",
    "        Paramaters: \n",
    "            y_train_teacher (n_train, n_outputs): teacher model's predicted task outputs in evaluation form (i.e. if classification task, y_train_teacher must be class predictions, not class logits) for train data\n",
    "            y_test_teacher (n_test, n_outputs): teacher model's predicted task outputs in evaluation form for test data\n",
    "            y_train (n_train, 1): true outputs for train data\n",
    "            y_test (n_test, 1): true outputs for test data\n",
    "            metric: metric to log \n",
    "            task: type of distillation task (likely regression)\n",
    "            r: default dictionary to log experiment metrics\n",
    "            \n",
    "        Returns:\n",
    "            r: default dictionary to log experiment metrics\n",
    "            \n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"mse\": mean_squared_error,\n",
    "            \"r2\": r2_score,\n",
    "            \"f1\": f1_score,\n",
    "        \n",
    "        }\n",
    "    \n",
    "    metric_fn = metrics[metric]\n",
    "    \n",
    "    for split_name, (y_teacher_, y_) in zip(\n",
    "        [\"train\", \"test\"], [(y_train_teacher, y_train), (y_test_teacher, y_test)]\n",
    "    ):\n",
    "        r[f\"teacher_{task}_{split_name}_{metric}\"] = metric_fn(y_teacher_, y_)\n",
    "    \n",
    "    return r\n",
    "\n",
    "def evaluate_test_student(student, X_test, y_test, metric, task, r):\n",
    "    \"\"\"Evaluate student performance on each split\"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"mse\": mean_squared_error,\n",
    "            \"r2\": r2_score,\n",
    "            \"f1\": f1_score,\n",
    "        \n",
    "        }\n",
    "    \n",
    "    metric_fn = metrics[metric]\n",
    "    \n",
    "    y_pred_ = process_student_eval(student.predict(X_test))\n",
    "    r[f\"student_{task}_test_{metric}\"] = metric_fn(y_test, y_pred_)\n",
    "\n",
    "    return r\n",
    "\n",
    "def evaluate_test_teacher(y_test_teacher, y_test, metric, task, r):\n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"mse\": mean_squared_error,\n",
    "            \"r2\": r2_score,\n",
    "            \"f1\": f1_score,\n",
    "        \n",
    "        }\n",
    "    \n",
    "    metric_fn = metrics[metric]\n",
    "    \n",
    "    r[f\"teacher_{task}_test_{metric}\"] = metric_fn(y_test_teacher, y_test)\n",
    "    \n",
    "    return r\n",
    "\n",
    "def predict_teacher(teacher, X, gpu=0):\n",
    "    \"\"\"Make prediction from concepts to outputs with teacher model\n",
    "    \n",
    "        Paramaters: \n",
    "            teacher: teacher model\n",
    "            X (n, n_concepts): concept data\n",
    "            gpu: gpu cuda device if applicable\n",
    "            \n",
    "        Returns:\n",
    "            y_pred: teacher model predictions for X \n",
    "            \n",
    "    \"\"\"\n",
    "    ### TODO: handle teacher prediction outputs (X is intended to be concept design matrix)###\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def load_teacher_model(teacher_path, gpu=0):\n",
    "    \"\"\"Load in teacher model\n",
    "    \n",
    "        Paramaters: \n",
    "            teacher_path: path where teacher model is stored\n",
    "            gpu: gpu cuda device if applicable\n",
    "            \n",
    "        Returns:\n",
    "            model: teacher model\n",
    "            \n",
    "    \"\"\"\n",
    "    ### TODO: load in teacher model using teacher_path ###\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_tabular_distillation_data(teacher, train_path, test_path, gpu=0):\n",
    "    \"\"\"Generate tabular concept and output data using teacher model for distillation and evaluation\n",
    "    \n",
    "        Paramaters: \n",
    "            teacher: teacher model\n",
    "            train_path: path where training data is stored\n",
    "            test_path: path where test data is stored\n",
    "            gpu: gpu cuda device if applicable\n",
    "            \n",
    "        Returns:\n",
    "            X_train_teacher (n_train, n_concepts): predicted concepts by teacher model for training data\n",
    "            X_test_teacher (n_test, n_concepts): predicted concepts by teacher model for test data\n",
    "            X_train (n_train, n_concepts): true concept training data (likely 0, 1)\n",
    "            X_test (n_test, n_concepts): true concept test data (likely 0, 1)\n",
    "            y_train_teacher (n_train, n_outputs): teacher model's predicted task outputs for train data\n",
    "            y_test_teacher (n_test, n_outputs): teacher model's predicted task outputs for test data\n",
    "            y_train (n_train, 1): true outputs for train data\n",
    "            y_test (n_test, 1): true outputs for test data\n",
    "            \n",
    "    \"\"\"\n",
    "    ### TODO: generate teacher train and test data using model, train_path, and test_path ###\n",
    "    \n",
    "    return X_train_teacher, X_test_teacher, X_train, X_test, y_train_teacher, y_test_teacher, y_train, y_test\n",
    "    \n",
    "def process_distillation_data(X_train_teacher, X_test_teacher, X_train, X_test, y_train_teacher, y_test_teacher):\n",
    "    \"\"\"Process teacher data for distillation (likely binarizing the data)\n",
    "    \n",
    "        Paramaters: \n",
    "            X_train_teacher (n_train, n_concepts): predicted concepts by teacher model for training data\n",
    "            X_test_teacher (n_test, n_concepts): predicted concepts by teacher model for test data\n",
    "            X_train (n_train, n_concepts): true concept training data (likely 0, 1)\n",
    "            X_test (n_test, n_concepts): true concept test data (likely 0, 1)\n",
    "            y_train_teacher (n_train, n_outputs): teacher model's predicted task outputs in evaluation form (i.e. if classification task, y_train_teacher must be class predictions, not class logits) for train data\n",
    "            y_test_teacher (n_test, n_outputs): teacher model's predicted task outputs in evaluation form for test data\n",
    "            \n",
    "        Returns:\n",
    "            X_train_teacher (n_train, n_concepts): processed predicted concepts by teacher model for distillation/student train data (likely 0, 1)\n",
    "            X_test_teacher (n_test, n_concepts): processed predicted concepts by teacher model for student test data (likely 0, 1)\n",
    "            y_train_teacher (n_train, n_outputs): teacher model's predicted task outputs for train data\n",
    "            y_test_teacher (n_test, n_outputs): teacher model's predicted task outputs for test data\n",
    "            \n",
    "    \"\"\"\n",
    "    ### TODO: process (i.e. binarize) data for distillation ###\n",
    "    \n",
    "    return X_train_teacher, X_test_teacher, y_train_teacher, y_test_teacher\n",
    "\n",
    "def process_student_eval(y_student):\n",
    "    \"\"\"Process student data outputs for evaluation (i.e. if we're using a regressor for distilling a classification model, need to argmax for evaluation)\n",
    "    \n",
    "        Paramaters: \n",
    "            y_student (n, n_outputs): student model predictions\n",
    "            \n",
    "        Returns:\n",
    "            y_pred (n, ...): student model predictions in evaluation form (if regression, then perhaps y_pred = y_student)\n",
    "            \n",
    "    \"\"\"\n",
    "    ### TODO: handle student prediction outputs to match metrics ###\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def process_teacher_eval(y_teacher):\n",
    "    \"\"\"Process teacher data outputs for evaluation (i.e. if process teacher logits into classes)\n",
    "    \n",
    "        Paramaters: \n",
    "            y_student (n, n_outputs): teacher model predictions\n",
    "            \n",
    "        Returns:\n",
    "            y_pred (n, ...): teacher model predictions in evaluation form (if regression, then perhaps y_pred = y_teacher)\n",
    "            \n",
    "    \"\"\"\n",
    "    ### TODO: process teacher model predictions for evaluations (sometimes we distill a teacher model using a regressor, but want to evaluate class prediction accuracy) ###\n",
    "    \n",
    "    return y_teacher_eval\n",
    "\n",
    "def extract_interactions(student):\n",
    "\n",
    "    interactions = []\n",
    "\n",
    "    def traverse_tree(node, current_features, current_depth):\n",
    "\n",
    "        if node.left is None and node.right is None:\n",
    "            tree_interactions.append((current_features, np.var(np.abs(node.value))))\n",
    "            return\n",
    "        if node.left is not None:\n",
    "            current_features_l = current_features.copy()\n",
    "            current_features_l.append('c' + str(node.feature+1))\n",
    "            traverse_tree(node.left, current_features_l.copy(), current_depth=current_depth+1)\n",
    "        if node.right is not None:\n",
    "            current_features_r = current_features.copy()\n",
    "            current_features_r.append('!c' + str(node.feature+1))\n",
    "            traverse_tree(node.right, current_features_r.copy(), current_depth=current_depth+1)\n",
    "            \n",
    "    try:\n",
    "        trees = student.trees_\n",
    "    except:\n",
    "        trees = student.figs.trees_\n",
    "\n",
    "    for tree in trees:\n",
    "        tree_interactions = []\n",
    "        traverse_tree(tree, [], current_depth=0)\n",
    "        interactions.append(tree_interactions)\n",
    "        \n",
    "    return interactions\n",
    "\n",
    "def split_list_by_sizes(list1, list2):\n",
    "    result = []\n",
    "    for row1, row2 in zip(list1, list2):\n",
    "        sizes = [len(sublist) for sublist in row1]\n",
    "        row_result = []\n",
    "        start = 0\n",
    "        for size in sizes:\n",
    "            end = start + size\n",
    "            row_result.append(list(row2[start:end]))\n",
    "            start = end\n",
    "        result.append(row_result)\n",
    "    return result\n",
    "\n",
    "def find_closest_keys_vectorized(dictionary, targets):\n",
    "    keys = np.array(list(dictionary.keys()))\n",
    "    targets = np.array(targets)\n",
    "    diffs = np.abs(keys[:, None] - targets)\n",
    "    closest_key_indices = np.argmin(diffs, axis=0)\n",
    "    closest_keys = keys[closest_key_indices]\n",
    "\n",
    "    return closest_keys\n",
    "\n",
    "def extract_adaptive_intervention(student, X, interactions, number_of_top_paths=0):\n",
    "    \n",
    "    figs_dict = {}\n",
    "    for i, tree in enumerate(interactions):\n",
    "        tree_dict = {}\n",
    "        for path, var in tree:\n",
    "            tree_dict[var] = path\n",
    "        figs_dict[i] = tree_dict\n",
    "\n",
    "    test_pred_intervention = student.predict(X, by_tree = True)\n",
    "\n",
    "    concepts_to_edit = [[] for _ in range(X.shape[0])]\n",
    "    variances = np.var(np.abs(test_pred_intervention), axis = 1)\n",
    "\n",
    "    concepts = np.array([find_closest_keys_vectorized(figs_dict[i], variances[:, i]) for i in range(variances.shape[1])])\n",
    "    orderings_of_interventions = np.argsort(concepts.T, axis = 1)[:, ::-1]\n",
    "    variances_of_orderings_of_interventions = np.sort(concepts.T, axis = 1)[:, ::-1]\n",
    "    \n",
    "    if number_of_top_paths == 0:\n",
    "        r = range(orderings_of_interventions.shape[1])\n",
    "    else:\n",
    "        r = range(number_of_top_paths)\n",
    "\n",
    "    for t in r:\n",
    "        for i, l in enumerate(orderings_of_interventions[:, t]):\n",
    "            new_list = []\n",
    "            for c in figs_dict[l][variances_of_orderings_of_interventions[i, t]]:\n",
    "                new_list.append(int(c[1:])-1 if c[0] != '!' else int(c[2:])-1)\n",
    "            concepts_to_edit[i].append(new_list)\n",
    "    return concepts_to_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4871b111-fed0-4821-9031-10ca8c2afb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    def __init__(self, a_dict):\n",
    "        for k in a_dict.keys():\n",
    "            exec(f'self.{k} = a_dict[\"{k}\"]')\n",
    "        \n",
    "args = {}\n",
    "#args['save_dir'] = join(path_to_repo, \"results\")  # The default value\n",
    "args['teacher_path'] = '' \n",
    "args['train_path'] = ''\n",
    "args['test_path'] = ''\n",
    "args['task_type'] = \"regression\"\n",
    "args['student_name'] = \"FIGSRegressor\"\n",
    "\n",
    "args['max_rules'] = 250\n",
    "args['max_trees'] = 40\n",
    "args['max_depth'] = 4\n",
    "\n",
    "args['metric'] = \"accuracy\" \n",
    "args['num_interactions_intervention'] = 0\n",
    "args['gpu'] = 0\n",
    "\n",
    "args = ARGS(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d395e-d1ad-4ccc-81c2-c59b054811e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c1843-4221-41f1-b24b-11568776f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = load_teacher_model(args.teacher_path, args.gpu)\n",
    "    \n",
    "X_train_t, X_test_t, X_train, X_test, y_train_t, y_test_t, y_train, y_test = generate_tabular_distillation_data(teacher, args.train_path, args.test_path, args.gpu)\n",
    "\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = process_distillation_data(X_train_t, X_test_t, X_train, X_test, y_train_t, y_test_t)\n",
    "\n",
    "y_train_t_eval = process_teacher_eval(y_train_t)\n",
    "y_test_t_eval = process_teacher_eval(y_test_t)\n",
    "\n",
    "figs_student = idistill.model.get_model(args.task_type, args.student_name, args)\n",
    "\n",
    "r, figs_student = distill_model(figs_student, X_train_d, y_train_d, r)\n",
    "\n",
    "r['max_trees'] = figs_student.max_trees\n",
    "r['max_rules'] = figs_student.max_rules\n",
    "r['max_depth'] = figs_student.max_depth\n",
    "try:\n",
    "    r['n_trees'] = len(figs_student.figs.trees_)\n",
    "    r['n_rules'] = figs_student.figs.complexity_\n",
    "except:\n",
    "    r['n_trees'] = len(figs_student.trees_)\n",
    "    r['n_rules'] = figs_student.complexity_\n",
    "\n",
    "r = evaluate_student(figs_student, X_train_d, X_test_d, y_train_t_eval, y_test_t_eval, args.metric, \"distillation\", r)\n",
    "r = evaluate_student(figs_student, X_train_d, X_test_d, y_train, y_test, args.metric, \"prediction\", r)\n",
    "\n",
    "r = evaluate_teacher(y_train_t_eval, y_test_t_eval, y_train, y_test, args.metric, \"prediction\", r)\n",
    "\n",
    "### adaptive FIGS concept editing ###\n",
    "\n",
    "figs_interactions = extract_interactions(figs_student)\n",
    "\n",
    "r['depth'] = max([max([len(i[0]) for i in t]) for t in figs_interactions])\n",
    "\n",
    "train_q5 = np.quantile(X_train_t, 0.05, axis = 0)\n",
    "train_q95 = np.quantile(X_train_t, 0.95, axis = 0)\n",
    "\n",
    "X_test_d_a_edit = X_test_d.copy()\n",
    "X_test_d_r_edit = X_test_d.copy()\n",
    "\n",
    "X_test_t_a_edit = X_test_t.copy()\n",
    "X_test_t_r_edit = X_test_t.copy()\n",
    "\n",
    "\n",
    "cti_adap_test = extract_adaptive_intervention(figs_student, X_test_d, figs_interactions, args.num_interactions_intervention)\n",
    "\n",
    "cti_rand_test = [np.random.choice(np.arange(X_test_d.shape[1]), X_test_d.shape[1], replace=False) for i in range(X_test_d.shape[0])]\n",
    "cti_rand_test = split_list_by_sizes(cti_adap_test, cti_rand_test)\n",
    "\n",
    "\n",
    "if 'linear' in args.teacher_path or 'Linear' in args.teacher_path:\n",
    "    X_test_d_l_edit = X_test_d.copy()\n",
    "    X_test_t_l_edit = X_test_t.copy()\n",
    "\n",
    "    test_l_edit = np.einsum('nc, yc -> nyc', X_test_t.values, teacher.sec_model.linear.weight.cpu().detach().numpy())\n",
    "\n",
    "    cti_l_test_arr = np.argsort(np.var(np.abs(test_l_edit), axis = 1), axis = 1)[:, ::-1]\n",
    "    cti_l_test = [row for row in cti_l_test_arr]\n",
    "    cti_l_test = split_list_by_sizes(cti_adap_test, cti_l_test)\n",
    "\n",
    "if args.num_interactions_intervention == 0:\n",
    "    num_iters = len(figs_student.trees_)\n",
    "else:\n",
    "    num_iters = args.num_interactions_intervention\n",
    "\n",
    "for i in range(num_iters):\n",
    "    for n in range(X_test_d.shape[0]):\n",
    "\n",
    "        X_test_d_a_edit.iloc[n, cti_adap_test[n][i]] = X_test.iloc[n, cti_adap_test[n][i]]\n",
    "        X_test_d_r_edit.iloc[n, cti_rand_test[n][i]] = X_test.iloc[n, cti_rand_test[n][i]]\n",
    "\n",
    "        X_test_t_a_edit.iloc[n, cti_adap_test[n][i]] = train_q5[cti_adap_test[n][i]]*(X_test.iloc[n, cti_adap_test[n][i]] == 0) + train_q95[cti_adap_test[n][i]]*(X_test.iloc[n, cti_adap_test[n][i]])\n",
    "        X_test_t_r_edit.iloc[n, cti_rand_test[n][i]] = train_q5[cti_rand_test[n][i]]*(X_test.iloc[n, cti_rand_test[n][i]] == 0) + train_q95[cti_rand_test[n][i]]*(X_test.iloc[n, cti_rand_test[n][i]])\n",
    "\n",
    "        if 'linear' in args.teacher_path or 'Linear' in args.teacher_path:\n",
    "            X_test_d_l_edit.iloc[n, cti_l_test[n][i]] = X_test.iloc[n, cti_l_test[n][i]]\n",
    "            X_test_t_l_edit.iloc[n, cti_l_test[n][i]] = train_q5[cti_l_test[n][i]]*(X_test.iloc[n, cti_l_test[n][i]] == 0) + train_q95[cti_l_test[n][i]]*(X_test.iloc[n, cti_l_test[n][i]])\n",
    "\n",
    "    y_test_t_eval_a_interv = process_teacher_eval(predict_teacher(teacher, X_test_t_a_edit, args.gpu))\n",
    "    y_test_t_eval_r_interv = process_teacher_eval(predict_teacher(teacher, X_test_t_r_edit, args.gpu))\n",
    "\n",
    "    r = evaluate_test_student(figs_student, X_test_d_a_edit, y_test_t_eval_a_interv, args.metric, f\"distill_adap_interv_iter{i}\", r)\n",
    "    r = evaluate_test_student(figs_student, X_test_d_r_edit, y_test_t_eval_r_interv, args.metric, f\"distill_rand_interv_iter{i}\", r)\n",
    "\n",
    "    r = evaluate_test_student(figs_student, X_test_d_a_edit, y_test, args.metric, f\"pred_adap_interv_iter{i}\", r)\n",
    "    r = evaluate_test_student(figs_student, X_test_d_r_edit, y_test, args.metric, f\"pred_rand_interv_iter{i}\", r)\n",
    "\n",
    "    r = evaluate_test_teacher(y_test_t_eval_a_interv, y_test, args.metric, f\"pred_adap_interv_iter{i}\", r)\n",
    "    r = evaluate_test_teacher(y_test_t_eval_r_interv, y_test, args.metric, f\"pred_rand_interv_iter{i}\", r)\n",
    "\n",
    "    if 'linear' in args.teacher_path or 'Linear' in args.teacher_path:\n",
    "        y_test_t_eval_l_interv = process_teacher_eval(predict_teacher(teacher, X_test_t_l_edit, args.gpu))\n",
    "\n",
    "        r = evaluate_test_student(figs_student, X_test_d_l_edit, y_test_t_eval_l_interv, args.metric, f\"distill_lin_interv_iter{i}\", r)\n",
    "        r = evaluate_test_student(figs_student, X_test_d_l_edit, y_test, args.metric, f\"pred_lin_interv_iter{i}\", r)\n",
    "        r = evaluate_test_teacher(y_test_t_eval_l_interv, y_test, args.metric, f\"pred_lin_interv_iter{i}\", r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
