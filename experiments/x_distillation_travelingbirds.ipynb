{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6384ecca-7f1c-4e61-8cef-416c6edf9d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/aiohttp/helpers.py:107: DeprecationWarning: \"@coroutine\" decorator is deprecated since Python 3.8, use \"async def\" instead\n",
      "  def noop(*args, **kwargs):  # type: ignore\n",
      "2025-02-06 19:14:11.019346: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-06 19:14:11.977613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/botocore/httpsession.py:34: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\n",
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, f1_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import imodels\n",
    "import inspect\n",
    "import os.path\n",
    "import imodelsx.cache_save_utils\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "#path_to_repo = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "#os.chdir(path_to_repo)\n",
    "#os.chdir('/home/mattyshen/interpretableDistillation')\n",
    "sys.path.append('..')\n",
    "\n",
    "import idistill.model\n",
    "import idistill.data\n",
    "\n",
    "def distill_model(student, X_train_teacher, y_train_teacher, r, feature_names = None):\n",
    "    \"\"\"Distill the teacher model using the student model\"\"\"\n",
    "    \n",
    "    fit_parameters = inspect.signature(student.fit).parameters.keys()\n",
    "    if \"feature_names\" in fit_parameters and feature_names is not None:\n",
    "        student.fit(X_train_teacher, y_train_teacher, feature_names=feature_names)\n",
    "    else:\n",
    "        student.fit(X_train_teacher, y_train_teacher)\n",
    "\n",
    "    return r, student\n",
    "\n",
    "def evaluate_student(student, X_train, X_test, y_train, y_test, metric, task, r):\n",
    "    \"\"\"Evaluate student performance on each split\"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"mse\": mean_squared_error,\n",
    "            \"r2\": r2_score,\n",
    "            \"f1\": f1_score,\n",
    "        \n",
    "        }\n",
    "    \n",
    "    metric_fn = metrics[metric]\n",
    "    \n",
    "    for split_name, (X_, y_) in zip(\n",
    "        [\"train\", \"test\"], [(X_train, y_train), (X_test, y_test)]\n",
    "    ):\n",
    "        y_pred_ = process_student_eval(student.predict(X_))\n",
    "        r[f\"student_{task}_{split_name}_{metric}\"] = metric_fn(y_, y_pred_)\n",
    "\n",
    "    return r\n",
    "\n",
    "def evaluate_teacher(y_train_teacher, y_test_teacher, y_train, y_test, metric, task, r):\n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "            \"mse\": mean_squared_error,\n",
    "            \"r2\": r2_score,\n",
    "            \"f1\": f1_score,\n",
    "        \n",
    "        }\n",
    "    \n",
    "    metric_fn = metrics[metric]\n",
    "    \n",
    "    for split_name, (y_teacher_, y_) in zip(\n",
    "        [\"train\", \"test\"], [(y_train_teacher, y_train), (y_test_teacher, y_test)]\n",
    "    ):\n",
    "        r[f\"teacher_{task}_{split_name}_{metric}\"] = metric_fn(y_teacher_, y_)\n",
    "    \n",
    "    return r\n",
    "\n",
    "def predict_teacher(teacher, X):\n",
    "    ### TODO: handle teacher prediction outputs (X is intended to be concept design matrix, output is intended to be logits)###\n",
    "\n",
    "    y_pred_torch = teacher.sec_model(torch.tensor(X.values, dtype=torch.float32).to('cuda:0'))\n",
    "    y_pred = pd.DataFrame(y_pred_torch.detach().cpu().numpy())\n",
    "        \n",
    "    return y_pred\n",
    "\n",
    "def load_teacher_model(teacher_path):\n",
    "    ### TODO: load in teacher model using model_path ###\n",
    "    \n",
    "    sys.path.append('/home/mattyshen/ConceptBottleneck')\n",
    "    teacher = torch.load(teacher_path, weights_only=False)\n",
    "    teacher.to('cuda:0')\n",
    "    teacher.eval()\n",
    "    sys.path.append('/home/mattyshen/DistillationEdit')\n",
    "    \n",
    "    return teacher\n",
    "\n",
    "def generate_tabular_distillation_data(teacher, train_path, test_path):\n",
    "    ### TODO: generate teacher train and test data using model, train_path, and test_path ###\n",
    "    \n",
    "    sys.path.append('/home/mattyshen/ConceptBottleneck/CUB')\n",
    "    from dataset import load_data\n",
    "    from config import BASE_DIR\n",
    "    \n",
    "    def get_cub_data(teacher, path, data = 'train', override_train = True, batch_size = 32):\n",
    "        with torch.no_grad():\n",
    "            if data == 'test':\n",
    "                test_dir = path\n",
    "                #print(test_dir)\n",
    "                # loader = load_data([test_dir], True, False, batch_size, image_dir='images',\n",
    "                #                    n_class_attr=2, override_train=override_train)\n",
    "                loader = load_data([test_dir], True, False, batch_size, image_dir='AdversarialData/CUB_fixed/test',\n",
    "                                   n_class_attr=2)\n",
    "            else:\n",
    "                train_dir = path\n",
    "                val_dir = '/home/mattyshen/ConceptBottleneck/CUB_processed/class_attr_data_10/val.pkl'\n",
    "                #print(train_dir, val_dir)\n",
    "                # loader = load_data([train_dir, val_dir], True, False, batch_size, image_dir='images',\n",
    "                #                    n_class_attr=2, override_train=override_train)\n",
    "                loader = load_data([train_dir, val_dir], True, False, batch_size, image_dir='AdversarialData/CUB_fixed/train',\n",
    "                                    n_class_attr=2)\n",
    "                \n",
    "            torch.manual_seed(0)\n",
    "            \n",
    "            attrs_true = []\n",
    "            attrs_hat = []\n",
    "            labels_true = []\n",
    "            labels_hat = []\n",
    "            for data_idx, data in enumerate(loader):\n",
    "                inputs, labels, attr_labels = data\n",
    "                attr_labels = torch.stack(attr_labels).t()\n",
    "\n",
    "                inputs_var = torch.autograd.Variable(inputs).to('cuda:0')\n",
    "                labels_var = torch.autograd.Variable(labels).to('cuda:0')\n",
    "                outputs = teacher(inputs_var)\n",
    "                class_outputs = outputs[0]\n",
    "\n",
    "                attr_outputs = outputs[1:] #[torch.nn.Sigmoid()(o) for o in outputs[1:]]\n",
    "                attr_outputs_sigmoid = attr_outputs\n",
    "\n",
    "                attrs_hat.append(torch.stack(attr_outputs).squeeze(2).detach().cpu().numpy())\n",
    "                attrs_true.append(attr_labels.T)\n",
    "                labels_hat.append(class_outputs.detach().cpu().numpy())\n",
    "                labels_true.append(labels)\n",
    "\n",
    "            X_hat = pd.DataFrame(np.concatenate(attrs_hat, axis=1).T, columns = [f'c{i}' for i in range(1, 113)])\n",
    "            X = pd.DataFrame(np.concatenate(attrs_true, axis = 1).T, columns = [f'c{i}' for i in range(1, 113)])\n",
    "\n",
    "            y = pd.Series(np.concatenate([l.numpy().reshape(-1, ) for l in labels_true]))\n",
    "            y_hat = pd.DataFrame(np.concatenate(labels_hat, axis = 0))\n",
    "\n",
    "            del attrs_hat\n",
    "            del labels\n",
    "            del labels_hat\n",
    "            del loader\n",
    "            del data\n",
    "            del inputs\n",
    "            del outputs\n",
    "            del class_outputs\n",
    "            del attr_outputs\n",
    "            del attr_outputs_sigmoid\n",
    "            del inputs_var\n",
    "            del labels_var\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            return X_hat, X, y_hat, y\n",
    "\n",
    "    X_train_teacher, X_train, y_train_teacher, y_train = get_cub_data(teacher, train_path)\n",
    "    X_test_teacher, X_test, y_test_teacher, y_test = get_cub_data(teacher, test_path, data = 'test')\n",
    "    \n",
    "    sys.path.append('/home/mattyshen/DistillationEdit')\n",
    "    \n",
    "    return X_train_teacher, X_test_teacher, X_train, X_test, y_train_teacher, y_test_teacher, y_train, y_test\n",
    "\n",
    "def process_distillation_data(X_train_teacher, X_test_teacher, X_train, X_test, y_train_teacher, y_test_teacher, y_train, y_test):\n",
    "    ### TODO: process (i.e. binarize, F1-max binarize) data for distillation ###\n",
    "    \n",
    "    def find_optimal_threshold(y_true, y_probs):\n",
    "        \n",
    "#         threshs = np.arange(0, 1.01, 0.01)\n",
    "#         prop_correct = [accuracy_score(y_true, y_probs > t) for t in threshs]\n",
    "        \n",
    "#         return threshs[np.argmax(prop_correct)]\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        return optimal_threshold\n",
    "    def sigmoid(x):\n",
    "        return 1/ (1+np.exp(-x))\n",
    "\n",
    "#     optimal_thresholds = []\n",
    "#     for class_idx in range(X_train_teacher.shape[1]):\n",
    "#         y_true_class = X_train.iloc[:, class_idx]\n",
    "#         y_probs_class = X_train_teacher.iloc[:, class_idx]\n",
    "#         optimal_thresholds.append(find_optimal_threshold(y_true_class, y_probs_class))\n",
    "        \n",
    "#     optimal_thresholds = np.array(optimal_thresholds)\n",
    "\n",
    "    # return X_train_teacher.applymap(sigmoid), X_test_teacher.applymap(sigmoid), y_train_teacher, y_test_teacher\n",
    "    # optimal_thresholds = find_optimal_threshold(X_train.values.reshape(-1, ), X_train_teacher.values.reshape(-1, ))\n",
    "    # print(np.unique(optimal_thresholds))\n",
    "    # return (X_train_teacher > optimal_thresholds).astype(int), (X_test_teacher > optimal_thresholds).astype(int), y_train_teacher, y_test_teacher\n",
    "    # best_t = np.argmin([np.mean(((X_train_teacher.values > t).astype(int) - X_train.values)**2) for t in np.arange(0, 1, 0.01)])\n",
    "    # thresh = np.arange(0, 1, 0.01)[best_t]\n",
    "    # print(thresh)\n",
    "    thresh = 0\n",
    "    \n",
    "    return (X_train_teacher > thresh).astype(int), (X_test_teacher > thresh).astype(int), y_train_teacher, y_test_teacher\n",
    "\n",
    "def process_student_eval(y_student):\n",
    "    ### TODO: handle student prediction outputs to match metrics ###\n",
    "    \n",
    "    y_pred = np.argmax(y_student, axis = 1)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def process_teacher_eval(y_teacher):\n",
    "    ### TODO: process teacher model predictions for evaluations (sometimes we distill a teacher model using a regressor, but want to evaluate class prediction accuracy) ###\n",
    "    \n",
    "    y_teacher_eval = y_teacher.idxmax(axis = 1).astype(int).values\n",
    "    \n",
    "    return y_teacher_eval\n",
    "\n",
    "def extract_interactions(student):\n",
    "\n",
    "    interactions = []\n",
    "\n",
    "    def traverse_tree(node, current_features, current_depth):\n",
    "\n",
    "        if node.left is None and node.right is None:\n",
    "            tree_interactions.append((current_features, np.var(np.abs(node.value))))\n",
    "            return\n",
    "        if node.left is not None:\n",
    "            current_features_l = current_features.copy()\n",
    "            current_features_l.append('c' + str(node.feature+1))\n",
    "            traverse_tree(node.left, current_features_l.copy(), current_depth=current_depth+1)\n",
    "        if node.right is not None:\n",
    "            current_features_r = current_features.copy()\n",
    "            current_features_r.append('!c' + str(node.feature+1))\n",
    "            traverse_tree(node.right, current_features_r.copy(), current_depth=current_depth+1)\n",
    "\n",
    "    for tree in student.trees_:\n",
    "        tree_interactions = []\n",
    "        traverse_tree(tree, [], current_depth=0)\n",
    "        interactions.append(tree_interactions)\n",
    "        \n",
    "    return interactions\n",
    "\n",
    "def get_argmax_max(vals, index):\n",
    "    \n",
    "    maxes = np.partition(vals, -2, axis=1)[:, -index]\n",
    "    argmaxes = np.argsort(vals, axis=1)[:, -index]\n",
    "    return maxes, argmaxes\n",
    "\n",
    "def extract_adaptive_intervention(student, X, interactions, number_of_top_paths, tol = 0.0001):\n",
    "    \n",
    "    test_pred_intervention = student.predict(X, by_tree = True)\n",
    "\n",
    "    concepts_to_edit = [[] for _ in range(X.shape[0])]\n",
    "    variances = np.var(np.abs(test_pred_intervention), axis = 1)\n",
    "\n",
    "    for idx in range(number_of_top_paths):\n",
    "        maxes, argmaxes = get_argmax_max(variances, idx+1)\n",
    "        for i, (tree_idx, var) in enumerate(zip(argmaxes, maxes)):\n",
    "            for paths in interactions[tree_idx]:\n",
    "                if abs(paths[1] - var) < tol:\n",
    "                    concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in paths[0]]\n",
    "                    concepts_to_edit[i].append(concept_indexes)\n",
    "                    \n",
    "    concepts_to_edit = [sum(element, []) for element in concepts_to_edit]\n",
    "    concepts_to_edit = [list(set(c)) for c in concepts_to_edit]\n",
    "    \n",
    "    return concepts_to_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc63f80-8ae9-4d82-85a1-47c098f68505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    def __init__(self, a_dict):\n",
    "        for k in a_dict.keys():\n",
    "            exec(f'self.{k} = a_dict[\"{k}\"]')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab59e0b-d63f-4167-8747-9e940e32e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "#args['save_dir'] = join(path_to_repo, \"results\")  # The default value\n",
    "args['teacher_path'] = '/home/mattyshen/DistillationEdit/models/travelingbirds/outputs/best_Joint0.01_Transformer_model_1.pth'  # The default value\n",
    "args['train_path'] = '/home/mattyshen/ConceptBottleneck/CUB_processed/class_attr_data_10/train.pkl'  # The default value\n",
    "args['test_path'] = '/home/mattyshen/ConceptBottleneck/CUB_processed/class_attr_data_10/test.pkl'  # The default value\n",
    "args['task_type'] = \"regression\"  # The default value\n",
    "args['student_name'] = \"FIGSRegressor\"  # The default value\n",
    "args['max_rules'] = 250  # The default value\n",
    "args['max_trees'] = 40  # The default value\n",
    "args['max_depth'] = 4  # The default value\n",
    "args['metric'] = \"accuracy\"  # The default value\n",
    "args['num_interactions_intervention'] = 3  # The default value\n",
    "args = ARGS(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a78d1a-2cc5-4d73-ac60-3bde31e1efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc01b16-02bd-4e90-a1d0-13bb4d411a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = load_teacher_model(args.teacher_path)\n",
    "    \n",
    "X_train_t, X_test_t, X_train, X_test, y_train_t, y_test_t, y_train, y_test = generate_tabular_distillation_data(teacher, args.train_path, args.test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3702b63c-bac9-4805-921e-6e45ff190e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d, X_test_d, y_train_d, y_test_d = process_distillation_data(X_train_t, X_test_t, X_train, X_test, y_train_t, y_test_t, y_train, y_test)\n",
    "\n",
    "y_train_t_eval = process_teacher_eval(y_train_t)\n",
    "y_test_t_eval = process_teacher_eval(y_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f71760-f154-4110-bd28-22ca97f7506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idistill.whitebox_figs import FIGSRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a007e9-11a1-4406-9b05-a63f6406af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_student = FIGSRegressor(max_rules=args.max_rules, max_trees=args.max_trees, max_depth=args.max_depth) #idistill.model.get_model(args.task_type, args.student_name, args)\n",
    "\n",
    "r, figs_student = distill_model(figs_student, X_train_d, y_train_d, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8403a6-2349-48b2-8e18-2313d3e59015",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = evaluate_student(figs_student, X_train_d, X_test_d, y_train_t_eval, y_test_t_eval, args.metric, \"distillation\", r)\n",
    "r = evaluate_student(figs_student, X_train_d, X_test_d, y_train, y_test, args.metric, \"prediction\", r)\n",
    "\n",
    "r = evaluate_teacher(y_train_t_eval, y_test_t_eval, y_train, y_test, args.metric, \"prediction\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "066b4c55-4450-4cf4-8e97-28d2ef6282cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'student_distillation_train_accuracy': 0.7227606951871658,\n",
       "             'student_distillation_test_accuracy': 0.6926130479806697,\n",
       "             'student_prediction_train_accuracy': 0.6497326203208557,\n",
       "             'student_prediction_test_accuracy': 0.5474628926475664,\n",
       "             'teacher_prediction_train_accuracy': 0.6911764705882353,\n",
       "             'teacher_prediction_test_accuracy': 0.5902657921988264})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288a61c-1301-43af-80c0-164a68b95c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_interactions = extract_interactions(figs_student)\n",
    "\n",
    "X_train_d_edit = X_train_d.copy()\n",
    "X_train_t_edit = X_train_t.copy()\n",
    "\n",
    "train_q5 = np.quantile(X_train_t, 0.05, axis = 0)\n",
    "train_q95 = np.quantile(X_train_t, 0.95, axis = 0)\n",
    "\n",
    "# train_q5d = np.quantile(X_train_d, 0.05, axis = 0)\n",
    "# train_q95d = np.quantile(X_train_d, 0.95, axis = 0)\n",
    "\n",
    "cti_train = extract_adaptive_intervention(figs_student, X_train_d, figs_interactions, args.num_interactions_intervention)\n",
    "\n",
    "for i in range(len(cti_train)):\n",
    "    X_train_d_edit.iloc[i, cti_train[i]] = X_train.iloc[i, cti_train[i]] #train_q5d[cti_train[i]]*(X_train.iloc[i, cti_train[i]] == 0) + train_q95d[cti_train[i]]*(X_train.iloc[i, cti_train[i]])\n",
    "    X_train_t_edit.iloc[i, cti_train[i]] = train_q5[cti_train[i]]*(X_train.iloc[i, cti_train[i]] == 0) + train_q95[cti_train[i]]*(X_train.iloc[i, cti_train[i]])\n",
    "\n",
    "cti_test = extract_adaptive_intervention(figs_student, X_test_d, figs_interactions, args.num_interactions_intervention)\n",
    "\n",
    "X_test_d_edit = X_test_d.copy()\n",
    "X_test_t_edit = X_test_t.copy()\n",
    "\n",
    "for i in range(len(cti_test)):\n",
    "    X_test_d_edit.iloc[i, cti_test[i]] = X_test.iloc[i, cti_test[i]] #train_q5d[cti_test[i]]*(X_test.iloc[i, cti_test[i]] == 0) + train_q95d[cti_test[i]]*(X_test.iloc[i, cti_test[i]])\n",
    "    X_test_t_edit.iloc[i, cti_test[i]] = train_q5[cti_test[i]]*(X_test.iloc[i, cti_test[i]] == 0) + train_q95[cti_test[i]]*(X_test.iloc[i, cti_test[i]])\n",
    "\n",
    "y_train_t_eval_interv = process_teacher_eval(predict_teacher(teacher, X_train_t_edit))\n",
    "y_test_t_eval_interv = process_teacher_eval(predict_teacher(teacher, X_test_t_edit))\n",
    "\n",
    "r = evaluate_student(figs_student, X_train_d_edit, X_test_d_edit, y_train_t_eval_interv, y_test_t_eval_interv, args.metric, \"distillation_adap_interv\", r)\n",
    "r = evaluate_student(figs_student, X_train_d_edit, X_test_d_edit, y_train, y_test, args.metric, \"prediction_adap_interv\", r)\n",
    "\n",
    "r = evaluate_teacher(y_train_t_eval_interv, y_test_t_eval_interv, y_train, y_test, args.metric, \"prediction_adap_interv\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84667e-1aab-4d89-8ba3-91b74067fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_interactions_intervention * args.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a78109-a716-4372-8e4e-004322c71c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in cti_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a263587-feb4-48de-b6a1-287a731ac4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in cti_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e75c85-14c4-4cbe-be7d-d96065b4d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cti_r_train = [np.random.choice(np.arange(0, 112), size=len(c), replace=False) for c in cti_train]\n",
    "cti_r_test = [np.random.choice(np.arange(0, 112), size=len(c), replace=False) for c in cti_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1935fe5-c2a0-4ed4-b6a6-854794d4f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in cti_r_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d852b34-1527-4c85-bdfb-cfe5d7c42587",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in cti_r_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c815dc6b-f4fe-40cc-bf87-e8da8fb9eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e40009-f83a-4418-bfb1-5f20486e5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d_r_edit = X_train_d.copy()\n",
    "X_train_t_r_edit = X_train_t.copy()\n",
    "\n",
    "for i in range(len(cti_r_train)):\n",
    "    X_train_d_r_edit.iloc[i, cti_r_train[i]] = X_train.iloc[i, cti_r_train[i]] #train_q5d[cti_r_train[i]]*(X_train.iloc[i, cti_r_train[i]] == 0) + train_q95d[cti_r_train[i]]*(X_train.iloc[i, cti_r_train[i]])\n",
    "    X_train_t_r_edit.iloc[i, cti_r_train[i]] = train_q5[cti_r_train[i]]*(X_train.iloc[i, cti_r_train[i]] == 0) + train_q95[cti_r_train[i]]*(X_train.iloc[i, cti_r_train[i]])\n",
    "\n",
    "X_test_d_r_edit = X_test_d.copy()\n",
    "X_test_t_r_edit = X_test_t.copy()\n",
    "\n",
    "for i in range(len(cti_r_test)):\n",
    "    X_test_d_r_edit.iloc[i, cti_r_test[i]] = X_test.iloc[i, cti_r_test[i]] #train_q5d[cti_r_test[i]]*(X_test.iloc[i, cti_r_test[i]] == 0) + train_q95d[cti_r_test[i]]*(X_test.iloc[i, cti_r_test[i]])\n",
    "    X_test_t_r_edit.iloc[i, cti_r_test[i]] = train_q5[cti_r_test[i]]*(X_test.iloc[i, cti_r_test[i]] == 0) + train_q95[cti_r_test[i]]*(X_test.iloc[i, cti_r_test[i]])\n",
    "\n",
    "y_train_t_eval_r_interv = process_teacher_eval(predict_teacher(teacher, X_train_t_r_edit))\n",
    "y_test_t_eval_r_interv = process_teacher_eval(predict_teacher(teacher, X_test_t_r_edit))\n",
    "\n",
    "r = evaluate_student(figs_student, X_train_d_r_edit, X_test_d_r_edit, y_train_t_eval_r_interv, y_test_t_eval_r_interv, args.metric, \"distillation_rand_interv\", r)\n",
    "r = evaluate_student(figs_student, X_train_d_r_edit, X_test_d_r_edit, y_train, y_test, args.metric, \"prediction_rand_interv\", r)\n",
    "\n",
    "r = evaluate_teacher(y_train_t_eval_r_interv, y_test_t_eval_r_interv, y_train, y_test, args.metric, \"prediction_rand_interv\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adadd1c-1d59-436e-82b3-079268b21e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_interactions_intervention * args.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c24828-5ec2-4cbe-b368-9a28f5d7edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r MLP2\n",
    "\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25cc32-ee52-4fb0-a15c-f6fd5e3a8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09dec1f-1010-48ca-a7b7-6cdecc93fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r MLP1\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c558451-6c3f-49a6-99ee-deb2cbb51d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresh = median of training values\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77998efb-fd4a-43bd-9201-562fc4c7d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresh = 0\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cbcbd-a4a2-473b-9466-20c76aa62d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(figs_student.trees_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d0908-563a-436c-a8ba-1155c3d96f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
