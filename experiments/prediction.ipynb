{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6384ecca-7f1c-4e61-8cef-416c6edf9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import joblib\n",
    "import imodels\n",
    "import inspect\n",
    "import os.path\n",
    "import imodelsx.cache_save_utils\n",
    "import sys\n",
    "import torch\n",
    "#path_to_repo = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "#os.chdir(path_to_repo)\n",
    "#os.chdir('/home/mattyshen/interpretableDistillation')\n",
    "sys.path.append('..')\n",
    "\n",
    "import idistill.model\n",
    "import idistill.data\n",
    "from idistill.ftd import FTDistillRegressorCV\n",
    "from idistill.whitebox_figs import FIGSRegressor, FIGSClassifier\n",
    "from idistill.subset_predictors import L0L2RegressorCV\n",
    "\n",
    "sys.path.append('/home/mattyshen/iCBM')\n",
    "\n",
    "from CUB.template_model import End2EndModel, Inception3, MLP\n",
    "\n",
    "class ARGS:\n",
    "    def __init__(self, a_dict):\n",
    "        for k in a_dict.keys():\n",
    "            exec(f'self.{k} = a_dict[\"{k}\"]')\n",
    "            \n",
    "def fit_model(model, X_train, y_train, feature_names, r):\n",
    "    # fit the model\n",
    "    fit_parameters = inspect.signature(model.fit).parameters.keys()\n",
    "    if \"feature_names\" in fit_parameters and feature_names is not None:\n",
    "        model.fit(X_train, y_train, feature_names=feature_names)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return r, model\n",
    "\n",
    "def evaluate_model(model, X_train, X_val, y_train, y_val, comp, seed, r):\n",
    "    \"\"\"Evaluate model performance on each split\"\"\"\n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "        }\n",
    "    for split_name, (X_, y_) in zip(\n",
    "        [\"trainval\", \"test\"], [(X_train, y_train), (X_val, y_val)]\n",
    "    ):\n",
    "        y_pred_ = model.predict(X_)\n",
    "        if len(y_pred_.shape) > 1 and y_pred_.shape[1] > 1:\n",
    "            #handle regressors\n",
    "            y_pred_ = np.argmax(y_pred_, axis=1)\n",
    "        for i, (metric_name, metric_fn) in enumerate(metrics.items()):\n",
    "            print(metric_fn(y_, y_pred_))\n",
    "            r[f\"{comp}_seed{seed}_{metric_name}_{split_name}\"] = metric_fn(y_, y_pred_)\n",
    "\n",
    "    return r\n",
    "\n",
    "def load_csvs(path):\n",
    "\n",
    "    X_train = pd.read_csv(f'{path}/X_trainval.csv', index_col=0)\n",
    "    X_train_hat = pd.read_csv(f'{path}/X_trainval_hat.csv', index_col=0)\n",
    "    X_test = pd.read_csv(f'{path}/X_test.csv', index_col=0)\n",
    "    X_test_hat = pd.read_csv(f'{path}/X_test_hat.csv', index_col=0)\n",
    "    y_train = pd.read_csv(f'{path}/y_trainval.csv', index_col=0)\n",
    "    y_train_hat = pd.read_csv(f'{path}/y_trainval_hat.csv', index_col=0)\n",
    "    y_test = pd.read_csv(f'{path}/y_test.csv', index_col=0)\n",
    "    y_test_hat = pd.read_csv(f'{path}/y_test_hat.csv', index_col=0)\n",
    "\n",
    "    return X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat\n",
    "\n",
    "def find_optimal_threshold(y_true, y_probs):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "def find_thresh(linkage_matrix, min_clusters=10, max_clusters=15, step=0.1, count = 0):\n",
    "    if count > 3:\n",
    "        print(max_clusters)\n",
    "        return find_thresh(linkage_matrix, min_clusters=min_clusters, max_clusters=(max_clusters-5*4)-1, step=step, count = 0)\n",
    "    threshold = 4.9\n",
    "    while threshold < 10:\n",
    "        clusters = fcluster(linkage_matrix, t=threshold, criterion='distance')\n",
    "        num_clusters = len(set(clusters))\n",
    "        if min_clusters <= num_clusters <= max_clusters:\n",
    "            return threshold, num_clusters\n",
    "        threshold += step\n",
    "    print('find_thresh recursive call beginning')\n",
    "    return find_thresh(linkage_matrix, min_clusters=min_clusters, max_clusters=max_clusters+5, step=0.1, count = count+1)\n",
    "    #return None, 0\n",
    "\n",
    "def cluster_concepts(X, num_clusters):\n",
    "    distance_matrix = 1 - X_train_hat.corr().abs()\n",
    "    linkage_matrix = linkage(squareform(distance_matrix), method='ward')\n",
    "    \n",
    "    threshold, _ = find_thresh(linkage_matrix, min_clusters=num_clusters-5, max_clusters=num_clusters, step=0.1)\n",
    "        \n",
    "    clusters = fcluster(linkage_matrix, t=threshold, criterion='distance')\n",
    "    \n",
    "    feature_groups = {}\n",
    "    for i, cluster_id in enumerate(clusters):\n",
    "        feature_groups.setdefault(cluster_id, []).append(distance_matrix.columns[i])\n",
    "    \n",
    "    return feature_groups\n",
    "\n",
    "def process_X(X_train, X_train_hat, X_test, X_test_hat, prepro, num_clusters, thresh=0):\n",
    "    if prepro == \"probs\":\n",
    "        return X_train_hat, X_test_hat, None\n",
    "    elif prepro == 'cluster':\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    elif prepro == 'global':\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        opt_thresh = find_optimal_threshold(X_train.values.reshape(-1, ), X_train_hat.values.reshape(-1, ))\n",
    "        \n",
    "        return (X_train_hat > opt_thresh).astype(int), (X_test_hat > opt_thresh).astype(int), f_gs\n",
    "    elif prepro == 'gpt1':\n",
    "        f_gs = {1:['c'+str(i) for i in range(1, 5)]+['c'+str(i) for i in range(53, 55)]+['c'+str(i) for i in range(100, 104)],\n",
    "                2:['c'+str(i) for i in range(5, 11)]+['c'+str(i) for i in range(110, 113)]+['c78'],\n",
    "                3:['c'+str(i) for i in range(11, 17)]+['c'+str(i) for i in range(26, 32)]+['c'+str(i) for i in range(85, 88)]+['c'+str(i) for i in range(65, 71)]+['c'+str(i) for i in range(104, 110)],\n",
    "                4:['c'+str(i) for i in range(17, 24)]+['c'+str(i) for i in range(40, 51)]+['c'+str(i) for i in range(24, 26)]+['c'+str(i) for i in range(71, 78)]+['c'+str(i) for i in range(60, 65)],\n",
    "                5:['c'+str(i) for i in range(32, 38)]+['c'+str(i) for i in range(88, 91)],\n",
    "                6:['c38', 'c39', 'c51','c52']+['c'+str(i) for i in range(55, 60)],\n",
    "                7:['c'+str(i) for i in range(97, 100)],\n",
    "                8:['c'+str(i) for i in range(91, 97)]+['c'+str(i) for i in range(79, 85)]\n",
    "        }\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    elif prepro == 'gpt2':\n",
    "        f_gs = {1:['c'+str(i) for i in range(1, 5)]+['c'+str(i) for i in range(53, 55)]+['c32']+['c'+str(i) for i in range(78, 85)],\n",
    "                2:['c'+str(i) for i in range(5, 11)]+['c'+str(i) for i in range(110, 113)]+['c'+str(i) for i in range(33, 38)]+['c'+str(i) for i in range(88, 91)],\n",
    "                3:['c'+str(i) for i in range(91, 97)]+['c'+str(i) for i in range(11, 17)]+['c'+str(i) for i in range(26, 32)]+['c'+str(i) for i in range(85, 88)]+['c'+str(i) for i in range(17, 24)]+['c'+str(i) for i in range(60, 65)],\n",
    "                4:['c'+str(i) for i in range(40, 51)]+['c24', 'c25']+['c'+str(i) for i in range(104, 110)]+['c'+str(i) for i in range(55, 60)]+['c'+str(i) for i in range(65, 78)],\n",
    "                5:['c38', 'c39', 'c51','c52'],\n",
    "                6:['c'+str(i) for i in range(100, 104)]+['c'+str(i) for i in range(97, 100)]\n",
    "        }\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    elif prepro == 'gpt3':\n",
    "        f_gs = {1:['c'+str(i) for i in range(1, 5)]+['c53', 'c54']+['c'+str(i) for i in range(100, 104)],\n",
    "                2:['c78', 'c32']+['c'+str(i) for i in range(5, 11)]+['c'+str(i) for i in range(110, 113)]+['c'+str(i) for i in range(88, 91)]+['c'+str(i) for i in range(33, 38)],\n",
    "                3:['c'+str(i) for i in range(91, 97)]+['c'+str(i) for i in range(11, 24)]+['c'+str(i) for i in range(26, 32)]+['c'+str(i) for i in range(85, 88)]+['c'+str(i) for i in range(55, 78)]+['c'+str(i) for i in range(104, 110)],\n",
    "                4:['c'+str(i) for i in range(40, 51)]+['c24', 'c25', 'c38', 'c39', 'c51', 'c52'],\n",
    "                5:['c'+str(i) for i in range(79, 85)],\n",
    "                6:['c'+str(i) for i in range(97, 100)]\n",
    "        }\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    \n",
    "    elif prepro == 'gpt4':\n",
    "        f_gs = {1:[1,3,5,7,8,11,12,15,16,19,20,21,22,24,26,27,40,41,42,43,46,49,50,53,55,56,60,62,64,65,66,69,70,71,72,77,78,79,80,83,84,85,87,88,90,91,92,93,94,95,102,106,107,108,110],\n",
    "                2:[4,6,10,13,14,17,18,23,25,29,54,73,76,86,89,97,98,104,105,111],\n",
    "                3:[2,9,28,30,32,33,34,35,36,37,38,39,47,48,51,52,81,96,99],\n",
    "                4:[31,44,45,57,58,59,61,63,67,68,74,75,82,100,101,103,109,112]\n",
    "        }\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            f_gs[k] = ['c'+str(i) for i in f_gs[k]]\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "        \n",
    "    elif prepro == 'binary' and thresh > 0:\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        return (X_train_hat > thresh).astype(int), (X_test_hat > thresh).astype(int), f_gs\n",
    "    else:\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        optimal_thresholds = []\n",
    "        for class_idx in range(X_train_hat.shape[1]):\n",
    "            y_true_class = X_train.iloc[:, class_idx]\n",
    "            y_probs_class = X_train_hat.iloc[:, class_idx]\n",
    "            optimal_thresholds.append(find_optimal_threshold(y_true_class, y_probs_class))\n",
    "        optimal_thresholds = np.array(optimal_thresholds)\n",
    "        \n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    \n",
    "def process_y(y_train, y_train_hat, y_test, y_test_hat, prepro):\n",
    "    if prepro == \"probs\":\n",
    "        return softmax(y_train_hat, axis=1), softmax(y_test_hat, axis=1)\n",
    "    elif prepro == \"classes\":\n",
    "        return pd.DataFrame(y_train_hat.idxmax(axis=1).astype(int)), pd.DataFrame(y_test_hat.idxmax(axis=1).astype(int))\n",
    "    else:\n",
    "        return y_train_hat, y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c1307d0-864a-4d43-9705-cc210e1759fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {}\n",
    "args_dict['task_type'] = 'regression'\n",
    "args_dict['model_name'] = 'FIGSRegressor'\n",
    "args_dict['X_type'] = 'binary'\n",
    "args_dict['thresh'] = 0.45\n",
    "args_dict['Y_type'] = 'logits'\n",
    "args_dict['max_rules'] = 90\n",
    "args_dict['max_trees'] = 30\n",
    "args_dict['max_depth'] = 4\n",
    "args_dict['device'] = 'cuda:0'\n",
    "args_dict['num_clusters'] = 5\n",
    "args_dict['num_bootstraps'] = 2\n",
    "\n",
    "args = ARGS(args_dict)\n",
    "r = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27343364-26b7-475b-9efb-89fecd62dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat = load_csvs(f'/home/mattyshen/DistillationEdit/data/cub_tabular/seed0_Joint0.01SigmoidModel__Seed1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f0b126f-4fb3-4993-9f44-c1b5f260079f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36497ffe-f5c1-4c13-881c-76be5c7a0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FIGSClassifier(max_rules = args.max_rules, max_trees = args.max_trees, max_depth = args.max_depth)\n",
    "r, model = fit_model(model, X_train, y_train, None, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4937a2fd-3638-451f-b66e-aa50090aa470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702540106951871"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model.predict(X_train), axis = 2), axis = 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6dbf6d81-8d53-4735-a4fe-9c712c622a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691059716948568"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model.predict(X_test), axis = 2), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f5c13f7-c668-4a7e-8cec-e590a41aab19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5270969968933379"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model.predict((X_test_hat > 0.45).astype(int)), axis = 2), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adddc5f6-7d16-41bf-9311-d352aeae2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGS classifier model\n",
    "model2 = FIGSClassifier(max_rules = args.max_rules, max_trees = args.max_trees, max_depth = args.max_depth)\n",
    "r, model2 = fit_model(model2, (X_train_hat > 0.45).astype(int), y_train_hat.idxmax(axis =1).astype(int).to_numpy().reshape(-1, 1), None, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ce5bd4c-c31b-4e0e-af25-30d9377892f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6915106951871658"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model2.predict((X_train_hat > 0.45).astype(int)), axis = 2), axis = 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d66b1222-d782-4d73-96d7-ed5a8556a758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086296168450121"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model2.predict((X_test_hat > 0.45).astype(int)), axis = 2), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d1c512d-f64d-456b-9d56-1547464e23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIGS classifier model\n",
    "model3 = FIGSClassifier(max_rules = args.max_rules, max_trees = args.max_trees, max_depth = args.max_depth)\n",
    "r, model3 = fit_model(model3, (X_train_hat > 0.45).astype(int), y_train, None, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c66eb618-fbb5-454f-ab5b-c95fcb5f3736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344919786096256"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model3.predict((X_train_hat > 0.45).astype(int)), axis = 2), axis = 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d300696-4d0f-43d0-b34b-1d882f82d4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7026234035208837"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model3.predict((X_test_hat > 0.45).astype(int)), axis = 2), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0a2ba38-f919-47c3-9ba1-6e81a893f0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393382352941176"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model3.predict((X_train_hat > 0.45).astype(int)), axis = 2), axis = 1), y_train_hat.idxmax(axis = 1).astype(int).to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "537ac5f2-c08d-4236-bf1c-b5c99b24ea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148084225060407"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(np.sum(model3.predict((X_test_hat > 0.45).astype(int)), axis = 2), axis = 1), y_test_hat.idxmax(axis = 1).astype(int).to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673459b-98ba-417a-a188-47f87c9d7b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
