{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6384ecca-7f1c-4e61-8cef-416c6edf9d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/aiohttp/helpers.py:107: DeprecationWarning: \"@coroutine\" decorator is deprecated since Python 3.8, use \"async def\" instead\n",
      "  def noop(*args, **kwargs):  # type: ignore\n",
      "2025-01-22 20:48:07.586189: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-22 20:48:08.600605: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/botocore/httpsession.py:34: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\n",
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import joblib\n",
    "import imodels\n",
    "import inspect\n",
    "import os.path\n",
    "import imodelsx.cache_save_utils\n",
    "import sys\n",
    "import torch\n",
    "#path_to_repo = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "#os.chdir(path_to_repo)\n",
    "#os.chdir('/home/mattyshen/interpretableDistillation')\n",
    "sys.path.append('..')\n",
    "\n",
    "import idistill.model\n",
    "import idistill.data\n",
    "from idistill.ftd import FTDistillRegressorCV\n",
    "from idistill.whitebox_figs import FIGSRegressor, FIGSClassifier\n",
    "from idistill.subset_predictors import L0L2RegressorCV\n",
    "\n",
    "sys.path.append('/home/mattyshen/iCBM')\n",
    "\n",
    "from CUB.template_model import End2EndModel, Inception3, MLP\n",
    "\n",
    "class ARGS:\n",
    "    def __init__(self, a_dict):\n",
    "        for k in a_dict.keys():\n",
    "            exec(f'self.{k} = a_dict[\"{k}\"]')\n",
    "            \n",
    "def fit_model(model, X_train, y_train, feature_names, r):\n",
    "    # fit the model\n",
    "    fit_parameters = inspect.signature(model.fit).parameters.keys()\n",
    "    if \"feature_names\" in fit_parameters and feature_names is not None:\n",
    "        model.fit(X_train, y_train, feature_names=feature_names)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    return r, model\n",
    "\n",
    "def evaluate_model(model, X_train, X_val, y_train, y_val, comp, seed, r):\n",
    "    \"\"\"Evaluate model performance on each split\"\"\"\n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy_score,\n",
    "        }\n",
    "    for split_name, (X_, y_) in zip(\n",
    "        [\"trainval\", \"test\"], [(X_train, y_train), (X_val, y_val)]\n",
    "    ):\n",
    "        y_pred_ = model.predict(X_)\n",
    "        if len(y_pred_.shape) > 1 and y_pred_.shape[1] > 1:\n",
    "            #handle regressors\n",
    "            y_pred_ = np.argmax(y_pred_, axis=1)\n",
    "        for i, (metric_name, metric_fn) in enumerate(metrics.items()):\n",
    "            print(metric_fn(y_, y_pred_))\n",
    "            r[f\"{comp}_seed{seed}_{metric_name}_{split_name}\"] = metric_fn(y_, y_pred_)\n",
    "\n",
    "    return r\n",
    "\n",
    "def load_csvs(path):\n",
    "\n",
    "    X_train = pd.read_csv(f'{path}/X_trainval.csv', index_col=0)\n",
    "    X_train_hat = pd.read_csv(f'{path}/X_trainval_hat.csv', index_col=0)\n",
    "    X_test = pd.read_csv(f'{path}/X_test.csv', index_col=0)\n",
    "    X_test_hat = pd.read_csv(f'{path}/X_test_hat.csv', index_col=0)\n",
    "    y_train = pd.read_csv(f'{path}/y_trainval.csv', index_col=0)\n",
    "    y_train_hat = pd.read_csv(f'{path}/y_trainval_hat.csv', index_col=0)\n",
    "    y_test = pd.read_csv(f'{path}/y_test.csv', index_col=0)\n",
    "    y_test_hat = pd.read_csv(f'{path}/y_test_hat.csv', index_col=0)\n",
    "\n",
    "    return X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat\n",
    "\n",
    "def find_optimal_threshold(y_true, y_probs):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "def find_thresh(linkage_matrix, min_clusters=10, max_clusters=15, step=0.1, count = 0):\n",
    "    if count > 3:\n",
    "        print(max_clusters)\n",
    "        return find_thresh(linkage_matrix, min_clusters=min_clusters, max_clusters=(max_clusters-5*4)-1, step=step, count = 0)\n",
    "    threshold = 4.9\n",
    "    while threshold < 10:\n",
    "        clusters = fcluster(linkage_matrix, t=threshold, criterion='distance')\n",
    "        num_clusters = len(set(clusters))\n",
    "        if min_clusters <= num_clusters <= max_clusters:\n",
    "            return threshold, num_clusters\n",
    "        threshold += step\n",
    "    print('find_thresh recursive call beginning')\n",
    "    return find_thresh(linkage_matrix, min_clusters=min_clusters, max_clusters=max_clusters+5, step=0.1, count = count+1)\n",
    "    #return None, 0\n",
    "\n",
    "def cluster_concepts(X, num_clusters):\n",
    "    distance_matrix = 1 - X_train_hat.corr().abs()\n",
    "    linkage_matrix = linkage(squareform(distance_matrix), method='ward')\n",
    "    \n",
    "    threshold, _ = find_thresh(linkage_matrix, min_clusters=num_clusters-5, max_clusters=num_clusters, step=0.1)\n",
    "        \n",
    "    clusters = fcluster(linkage_matrix, t=threshold, criterion='distance')\n",
    "    \n",
    "    feature_groups = {}\n",
    "    for i, cluster_id in enumerate(clusters):\n",
    "        feature_groups.setdefault(cluster_id, []).append(distance_matrix.columns[i])\n",
    "    \n",
    "    return feature_groups\n",
    "\n",
    "def process_X(X_train, X_train_hat, X_test, X_test_hat, prepro, num_clusters, thresh=0):\n",
    "    if prepro == \"probs\":\n",
    "        return X_train_hat, X_test_hat, None\n",
    "    elif prepro == 'cluster':\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    elif prepro == 'global':\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        opt_thresh = find_optimal_threshold(X_train.values.reshape(-1, ), X_train_hat.values.reshape(-1, ))\n",
    "        \n",
    "        return (X_train_hat > opt_thresh).astype(int), (X_test_hat > opt_thresh).astype(int), f_gs\n",
    "    elif prepro == 'gpt1':\n",
    "        f_gs = {1:['c'+str(i) for i in range(1, 5)]+['c'+str(i) for i in range(53, 55)]+['c'+str(i) for i in range(100, 104)],\n",
    "                2:['c'+str(i) for i in range(5, 11)]+['c'+str(i) for i in range(110, 113)]+['c78'],\n",
    "                3:['c'+str(i) for i in range(11, 17)]+['c'+str(i) for i in range(26, 32)]+['c'+str(i) for i in range(85, 88)]+['c'+str(i) for i in range(65, 71)]+['c'+str(i) for i in range(104, 110)],\n",
    "                4:['c'+str(i) for i in range(17, 24)]+['c'+str(i) for i in range(40, 51)]+['c'+str(i) for i in range(24, 26)]+['c'+str(i) for i in range(71, 78)]+['c'+str(i) for i in range(60, 65)],\n",
    "                5:['c'+str(i) for i in range(32, 38)]+['c'+str(i) for i in range(88, 91)],\n",
    "                6:['c38', 'c39', 'c51','c52']+['c'+str(i) for i in range(55, 60)],\n",
    "                7:['c'+str(i) for i in range(97, 100)],\n",
    "                8:['c'+str(i) for i in range(91, 97)]+['c'+str(i) for i in range(79, 85)]\n",
    "        }\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    elif prepro == 'gpt2':\n",
    "        f_gs = {1:['c'+str(i) for i in range(1, 5)]+['c'+str(i) for i in range(53, 55)]+['c32']+['c'+str(i) for i in range(78, 85)],\n",
    "                2:['c'+str(i) for i in range(5, 11)]+['c'+str(i) for i in range(110, 113)]+['c'+str(i) for i in range(33, 38)]+['c'+str(i) for i in range(88, 91)],\n",
    "                3:['c'+str(i) for i in range(91, 97)]+['c'+str(i) for i in range(11, 17)]+['c'+str(i) for i in range(26, 32)]+['c'+str(i) for i in range(85, 88)]+['c'+str(i) for i in range(17, 24)]+['c'+str(i) for i in range(60, 65)],\n",
    "                4:['c'+str(i) for i in range(40, 51)]+['c24', 'c25']+['c'+str(i) for i in range(104, 110)]+['c'+str(i) for i in range(55, 60)]+['c'+str(i) for i in range(65, 78)],\n",
    "                5:['c38', 'c39', 'c51','c52'],\n",
    "                6:['c'+str(i) for i in range(100, 104)]+['c'+str(i) for i in range(97, 100)]\n",
    "        }\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    elif prepro == 'gpt3':\n",
    "        f_gs = {1:['c'+str(i) for i in range(1, 5)]+['c53', 'c54']+['c'+str(i) for i in range(100, 104)],\n",
    "                2:['c78', 'c32']+['c'+str(i) for i in range(5, 11)]+['c'+str(i) for i in range(110, 113)]+['c'+str(i) for i in range(88, 91)]+['c'+str(i) for i in range(33, 38)],\n",
    "                3:['c'+str(i) for i in range(91, 97)]+['c'+str(i) for i in range(11, 24)]+['c'+str(i) for i in range(26, 32)]+['c'+str(i) for i in range(85, 88)]+['c'+str(i) for i in range(55, 78)]+['c'+str(i) for i in range(104, 110)],\n",
    "                4:['c'+str(i) for i in range(40, 51)]+['c24', 'c25', 'c38', 'c39', 'c51', 'c52'],\n",
    "                5:['c'+str(i) for i in range(79, 85)],\n",
    "                6:['c'+str(i) for i in range(97, 100)]\n",
    "        }\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    \n",
    "    elif prepro == 'gpt4':\n",
    "        f_gs = {1:[1,3,5,7,8,11,12,15,16,19,20,21,22,24,26,27,40,41,42,43,46,49,50,53,55,56,60,62,64,65,66,69,70,71,72,77,78,79,80,83,84,85,87,88,90,91,92,93,94,95,102,106,107,108,110],\n",
    "                2:[4,6,10,13,14,17,18,23,25,29,54,73,76,86,89,97,98,104,105,111],\n",
    "                3:[2,9,28,30,32,33,34,35,36,37,38,39,47,48,51,52,81,96,99],\n",
    "                4:[31,44,45,57,58,59,61,63,67,68,74,75,82,100,101,103,109,112]\n",
    "        }\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            f_gs[k] = ['c'+str(i) for i in f_gs[k]]\n",
    "        \n",
    "        optimal_thresholds = np.zeros(X_train.shape[1])\n",
    "        \n",
    "        for k in f_gs.keys():\n",
    "            idxs = [int(s[1:]) - 1 for s in f_gs[k]]\n",
    "            optimal_thresholds[idxs] = find_optimal_threshold(X_train[f_gs[k]].values.reshape(-1, ), X_train_hat[f_gs[k]].values.reshape(-1, ))\n",
    "\n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "        \n",
    "    elif prepro == 'binary' and thresh > 0:\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        return (X_train_hat > thresh).astype(int), (X_test_hat > thresh).astype(int), f_gs\n",
    "    else:\n",
    "        f_gs = cluster_concepts(X_train_hat, num_clusters)\n",
    "        optimal_thresholds = []\n",
    "        for class_idx in range(X_train_hat.shape[1]):\n",
    "            y_true_class = X_train.iloc[:, class_idx]\n",
    "            y_probs_class = X_train_hat.iloc[:, class_idx]\n",
    "            optimal_thresholds.append(find_optimal_threshold(y_true_class, y_probs_class))\n",
    "        optimal_thresholds = np.array(optimal_thresholds)\n",
    "        \n",
    "        return (X_train_hat > optimal_thresholds).astype(int), (X_test_hat > optimal_thresholds).astype(int), f_gs\n",
    "    \n",
    "def process_y(y_train, y_train_hat, y_test, y_test_hat, prepro):\n",
    "    if prepro == \"probs\":\n",
    "        return softmax(y_train_hat, axis=1), softmax(y_test_hat, axis=1)\n",
    "    elif prepro == \"classes\":\n",
    "        return pd.DataFrame(y_train_hat.idxmax(axis=1).astype(int)), pd.DataFrame(y_test_hat.idxmax(axis=1).astype(int))\n",
    "    else:\n",
    "        return y_train_hat, y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a720c3-4376-47b9-9528-c60c906f5c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 20, 19, 18]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gs = {1:[1,3,5,7,8,11,12,15,16,19,20,21,22,24,26,27,40,41,42,43,46,49,50,53,55,56,60,62,64,65,66,69,70,71,72,77,78,79,80,83,84,85,87,88,90,91,92,93,94,95,102,106,107,108,110],\n",
    "                2:[4,6,10,13,14,17,18,23,25,29,54,73,76,86,89,97,98,104,105,111],\n",
    "                3:[2,9,28,30,32,33,34,35,36,37,38,39,47,48,51,52,81,96,99],\n",
    "                4:[31,44,45,57,58,59,61,63,67,68,74,75,82,100,101,103,109,112]\n",
    "        }\n",
    "\n",
    "[len(f_gs[i])for i in f_gs.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1235f3c5-f957-4522-85a0-25153d3ff816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interactions(model):\n",
    "    \"\"\"\n",
    "    Extracts all feature interactions from the FIGS model by parsing through each additive tree.\n",
    "\n",
    "    Parameters:\n",
    "        model: A FIGS model containing an attribute `trees_`.\n",
    "               Each tree is comprised of hierarchically linked `Node` objects.\n",
    "\n",
    "    Returns:\n",
    "        interactions: A list of sets, where each set contains the features involved in an interaction.\n",
    "    \"\"\"\n",
    "    interactions = []\n",
    "\n",
    "    def traverse_tree(node, current_features, current_depth):\n",
    "        \"\"\"\n",
    "        Recursively traverse a tree to collect feature interactions.\n",
    "\n",
    "        Parameters:\n",
    "            node: The current `Node` object in the tree.\n",
    "            current_features: A set of features encountered so far in the current path.\n",
    "        \"\"\"\n",
    "        if node.left is None and node.right is None:\n",
    "            cur_interactions.append((current_features, np.var(np.abs(node.value))))\n",
    "            return\n",
    "\n",
    "        # Add the current feature to the set of features for this path\n",
    "\n",
    "        # If the node has children, traverse them\n",
    "        if node.left is not None:\n",
    "            current_features_l = current_features.copy()\n",
    "            current_features_l.append('c' + str(node.feature+1))\n",
    "            traverse_tree(node.left, current_features_l.copy(), current_depth=current_depth+1)\n",
    "        if node.right is not None:\n",
    "            current_features_r = current_features.copy()\n",
    "            current_features_r.append('!c' + str(node.feature+1))\n",
    "            traverse_tree(node.right, current_features_r.copy(), current_depth=current_depth+1)\n",
    "\n",
    "    # Loop through each tree in the model\n",
    "    # traverse_tree(model.trees_[0], set(), current_depth=0)\n",
    "    # return interactions\n",
    "    for tree in model.trees_:\n",
    "        # Start traversal for each tree\n",
    "        cur_interactions = []\n",
    "        traverse_tree(tree, [], current_depth=0)\n",
    "        interactions.append(cur_interactions)\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1307d0-864a-4d43-9705-cc210e1759fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {}\n",
    "args_dict['task_type'] = 'regression'\n",
    "args_dict['model_name'] = 'FIGSRegressor'\n",
    "args_dict['X_type'] = 'binary'\n",
    "args_dict['thresh'] = 0.45\n",
    "args_dict['Y_type'] = 'logits'\n",
    "args_dict['max_rules'] = 100\n",
    "args_dict['max_trees'] = 20\n",
    "args_dict['max_depth'] = 4\n",
    "args_dict['device'] = 'cuda:0'\n",
    "args_dict['num_clusters'] = 5\n",
    "args_dict['num_bootstraps'] = 2\n",
    "\n",
    "args = ARGS(args_dict)\n",
    "r = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27343364-26b7-475b-9efb-89fecd62dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat = load_csvs(f'/home/mattyshen/DistillationEdit/data/cub_tabular/seed0_Joint0.01SigmoidModel__Seed1')\n",
    "X_train_model, X_test_model, clusters = process_X(X_train, X_train_hat, X_test, X_test_hat, args.X_type, args.num_clusters, args.thresh)\n",
    "y_train_model, y_test_model = process_y(y_train, y_train_hat, y_test, y_test_hat, args.Y_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36497ffe-f5c1-4c13-881c-76be5c7a0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FIGSRegressor(max_rules = args.max_rules, max_trees = args.max_trees, max_depth = args.max_depth)\n",
    "r, model = fit_model(model, X_train_model, y_train_model, None, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bff761c-4a9b-4119-b0ac-5ce080b64eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666551605108733"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(model.predict(X_test_model), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f084acf4-b327-4070-9589-d179e5cdf536",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_interactions = extract_interactions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93c8cf4-2c99-4e59-a704-7d7444e7daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [ x for xs in cur_interactions for x in xs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c3e6a22-769f-47af-9581-ba5bc55fccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_intervention = model.predict(X_test_model, by_tree = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd564513-21d4-42e1-a204-79c82e5a05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_argmax_max(variances, index):\n",
    "    maxes = np.partition(variances, -2, axis=1)[:, -index]\n",
    "    argmaxes = np.argsort(variances, axis=1)[:, -index]\n",
    "    return maxes, argmaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c383ade-57b0-4c6e-ab3f-6699e2605d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36688228 0.36688228 0.36688228 ... 0.5657923  0.5657923  0.5657923 ] [2 2 2 ... 1 1 1]\n",
      "[0.12255553 0.12255553 0.12255553 ... 0.12255553 0.12255553 0.12255553] [0 0 0 ... 0 0 0]\n",
      "[0.12192598 0.06141263 0.04694282 ... 0.05235382 0.05235382 0.05235382] [6 3 1 ... 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "def extract_adaptive_intervention(model, X, number_of_top_paths, tol = 0.0001):\n",
    "    test_pred_intervention = model.predict(X, by_tree = True)\n",
    "\n",
    "    concepts_to_edit = [[] for _ in range(X.shape[0])]\n",
    "    variances = np.var(np.abs(test_pred_intervention), axis = 1)\n",
    "\n",
    "    for idx in range(number_of_top_paths):\n",
    "        maxes, argmaxes = get_argmax_max(variances, idx+1)\n",
    "        for i, (tree_idx, var) in enumerate(zip(argmaxes, maxes)):\n",
    "            for paths in cur_interactions[tree_idx]:\n",
    "                if abs(paths[1] - var) < tol:\n",
    "                    concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in paths[0]]\n",
    "                    concepts_to_edit[i].append(concept_indexes)\n",
    "                    \n",
    "    concepts_to_edit = [sum(element, []) for element in concepts_to_edit]\n",
    "    concepts_to_edit = [list(set(c)) for c in concepts_to_edit]\n",
    "    \n",
    "    return concepts_to_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2e7d648-d6ec-4d5c-8133-02f8ac718c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_edit = [sum(element, []) for element in concepts_to_edit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee0e0bcc-11fb-4f68-bd1e-7b44eaf48ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_edit = [list(set(c)) for c in concepts_to_edit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f3ac4b-90a2-48e0-b40a-a2e506d0786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(concepts_to_edit)):\n",
    "    X_test_model.iloc[i, concepts_to_edit[i]] = X_test.iloc[i, concepts_to_edit[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a4eb105-2ee6-49b6-a5f7-26989942da8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8077321366931308"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(model.predict(X_test_model), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7be223f-91c2-43b8-a2d2-0a2c0b5b85ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mhist([\u001b[38;5;28mlen\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m concepts_to_edit])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist([len(i) for i in concepts_to_edit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab49913-381f-4655-be9a-3f1522c82ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HVI + non HVI\n",
    "\n",
    "X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat = load_csvs(f'/home/mattyshen/DistillationEdit/data/cub_tabular/seed0_Joint0.01SigmoidModel__Seed1')\n",
    "X_train_model, X_test_model, clusters = process_X(X_train, X_train_hat, X_test, X_test_hat, args.X_type, args.num_clusters, args.thresh)\n",
    "y_train_model, y_test_model = process_y(y_train, y_train_hat, y_test, y_test_hat, args.Y_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7a8ae-f687-4a2f-9891-775b83f39062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interactions(model):\n",
    "    \n",
    "    interactions = []\n",
    "\n",
    "    def traverse_tree(node, current_features, current_depth):\n",
    "        \n",
    "        if node.left is None and node.right is None:\n",
    "            cur_interactions.append((current_features, np.var(np.abs(node.value))))\n",
    "            return\n",
    "        if node.left is not None:\n",
    "            current_features_l = current_features.copy()\n",
    "            current_features_l.append('c' + str(node.feature+1))\n",
    "            traverse_tree(node.left, current_features_l.copy(), current_depth=current_depth+1)\n",
    "        if node.right is not None:\n",
    "            current_features_r = current_features.copy()\n",
    "            current_features_r.append('!c' + str(node.feature+1))\n",
    "            traverse_tree(node.right, current_features_r.copy(), current_depth=current_depth+1)\n",
    "            \n",
    "    for tree in model.trees_:\n",
    "        cur_interactions = []\n",
    "        traverse_tree(tree, [], current_depth=0)\n",
    "        interactions.append(cur_interactions)\n",
    "        \n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43882746-4985-457f-9c83-1f4c89626c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f539efa-6395-41e5-95df-fbd316099cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_interactions = extract_interactions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38602674-b630-400e-8abe-d1e6c6e6466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_edit = [[] for _ in range(X_test_model.shape[0])]\n",
    "variances = np.var(np.abs(test_preds), axis = 1)\n",
    "number_of_top_paths = 1\n",
    "\n",
    "for idx in range(number_of_top_paths):\n",
    "    maxes, argmaxes = get_argmax_max(variances, idx+1)\n",
    "    print(maxes, argmaxes)\n",
    "    for i, (tree_idx, var) in enumerate(zip(argmaxes, maxes)):\n",
    "        for j, paths in enumerate(cur_interactions[tree_idx]):\n",
    "            if abs(paths[1] - var) < 0.0001:\n",
    "                concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in paths[0]]\n",
    "                concepts_to_edit[i].append(concept_indexes)\n",
    "                \n",
    "                best_unactive = cur_interactions[tree_idx][0]\n",
    "                for k, paths in enumerate(cur_interactions[tree_idx]):\n",
    "                    if k != j and best_unactive[1] < paths[1]:\n",
    "                        best_unactive = paths\n",
    "                concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in best_unactive[0]]\n",
    "                concepts_to_edit[i].append(concept_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7c3f5-db2b-4097-8345-f16274ab0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_edit = [sum(element, []) for element in concepts_to_edit]\n",
    "concepts_to_edit = [list(set(c)) for c in concepts_to_edit]\n",
    "\n",
    "for i in range(len(concepts_to_edit)):\n",
    "    X_test_model.iloc[i, concepts_to_edit[i]] = X_test.iloc[i, concepts_to_edit[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6674c80-3297-4b93-a5b1-4636c3d5dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(np.sum(model.predict(X_test_model), axis = 2), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb6ab2-0a94-4434-8a46-84b7826523dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_interactions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b0ba8-72fb-4620-a672-6c91e707aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top k predictions\n",
    "\n",
    "X_train, X_train_hat, X_test, X_test_hat, y_train, y_train_hat, y_test, y_test_hat = load_csvs(f'/home/mattyshen/DistillationEdit/data/cub_tabular/seed0_Joint0.01SigmoidModel__Seed1')\n",
    "X_train_model, X_test_model, clusters = process_X(X_train, X_train_hat, X_test, X_test_hat, args.X_type, args.num_clusters, args.thresh)\n",
    "y_train_model, y_test_model = process_y(y_train, y_train_hat, y_test, y_test_hat, args.Y_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531640d-7c4a-4403-ab9a-9e86252525b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3723975-e203-43ad-bab3-f95b1d614508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interactions(model):\n",
    "    \"\"\"\n",
    "    Extracts all feature interactions from the FIGS model by parsing through each additive tree.\n",
    "\n",
    "    Parameters:\n",
    "        model: A FIGS model containing an attribute `trees_`.\n",
    "               Each tree is comprised of hierarchically linked `Node` objects.\n",
    "\n",
    "    Returns:\n",
    "        interactions: A list of sets, where each set contains the features involved in an interaction.\n",
    "    \"\"\"\n",
    "    interactions = []\n",
    "\n",
    "    def traverse_tree(node, current_features, current_depth):\n",
    "        \"\"\"\n",
    "        Recursively traverse a tree to collect feature interactions.\n",
    "\n",
    "        Parameters:\n",
    "            node: The current `Node` object in the tree.\n",
    "            current_features: A set of features encountered so far in the current path.\n",
    "        \"\"\"\n",
    "        if node.left is None and node.right is None:\n",
    "            cur_interactions.append((current_features, node.value))\n",
    "            return\n",
    "\n",
    "        # Add the current feature to the set of features for this path\n",
    "\n",
    "        # If the node has children, traverse them\n",
    "        if node.left is not None:\n",
    "            current_features_l = current_features.copy()\n",
    "            current_features_l.append('c' + str(node.feature+1))\n",
    "            traverse_tree(node.left, current_features_l.copy(), current_depth=current_depth+1)\n",
    "        if node.right is not None:\n",
    "            current_features_r = current_features.copy()\n",
    "            current_features_r.append('!c' + str(node.feature+1))\n",
    "            traverse_tree(node.right, current_features_r.copy(), current_depth=current_depth+1)\n",
    "\n",
    "    # Loop through each tree in the model\n",
    "    # traverse_tree(model.trees_[0], set(), current_depth=0)\n",
    "    # return interactions\n",
    "    for tree in model.trees_:\n",
    "        # Start traversal for each tree\n",
    "        cur_interactions = []\n",
    "        traverse_tree(tree, [], current_depth=0)\n",
    "        interactions.append(cur_interactions)\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72021262-4aa0-4e39-8e72-bdecb8c3f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_interactions = extract_interactions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15f948-c84d-4369-b4c8-b10d049822c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes, argmaxes = get_argmax_max(np.sum(test_preds, axis = 2), idx+1)\n",
    "argmaxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ececc-39db-4375-9830-ec9acc67fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_top_paths = 1\n",
    "concepts_to_edit = [[] for _ in range(X_test_model.shape[0])]\n",
    "\n",
    "for idx in range(number_of_top_paths):\n",
    "    maxes, argmaxes = get_argmax_max(np.sum(test_preds, axis = 2), idx+1)\n",
    "    #maxes, argmaxes = get_argmax_max(np.sum(test_preds, axis = 2), idx+1)\n",
    "    for i, class_idx in enumerate(argmaxes):\n",
    "        cur_idx_max = np.argmax(test_preds[i, class_idx, :])\n",
    "        cur_max = np.max(test_preds[i, class_idx, :])\n",
    "        \n",
    "        temp = [abs(t[1][class_idx] - cur_max) < 0.0001 for t in cur_interactions[cur_idx_max]]\n",
    "        paths = cur_interactions[cur_idx_max][temp.index(1)]\n",
    "        \n",
    "        concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in paths[0]]\n",
    "        concepts_to_edit[i].append(concept_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162018d-9f92-45cf-b0a0-da2716227181",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_edit = [sum(element, []) for element in concepts_to_edit]\n",
    "\n",
    "concepts_to_edit = [list(set(c)) for c in concepts_to_edit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b226924-6661-4b1f-a2a3-9d9f8f0d1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(i) for i in concepts_to_edit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76d9da-7cd3-4a83-9100-63656b963c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(concepts_to_edit)):\n",
    "    X_test_model.iloc[i, concepts_to_edit[i]] = X_test.iloc[i, concepts_to_edit[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038e18b-59f9-4727-9f9b-bedd6328b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(np.sum(model.predict(X_test_model), axis = 2), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa37c74-1fd8-40d4-ace7-0a9c60dca3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_top_paths = 3\n",
    "for idx in range(number_of_top_paths):\n",
    "    maxes, argmaxes = get_argmax_max(variances, idx+1)\n",
    "    print(maxes, argmaxes)\n",
    "    for i, (tree_idx, var) in enumerate(zip(argmaxes, maxes)):\n",
    "        for paths in cur_interactions[tree_idx]:\n",
    "            if abs(paths[1] - var) < 0.0001:\n",
    "                concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in paths[0]]\n",
    "                concepts_to_edit[i].append(concept_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb3fc6-9249-45b3-ba22-9fc8756db6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c730fe-4eec-49a1-869d-a3e66c740d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_edit = [[] for _ in range(X_test_model.shape[0])]\n",
    "index_of_interactions = []\n",
    "variances = np.var(test_preds, axis = 1)\n",
    "number_of_top_paths = 1\n",
    "\n",
    "for idx in range(number_of_top_paths):\n",
    "    maxes, argmaxes = get_argmax_max(variances, idx+1)\n",
    "    print(maxes, argmaxes)\n",
    "    for i, (tree_idx, var) in enumerate(zip(argmaxes, maxes)):\n",
    "        for paths in cur_interactions[tree_idx]:\n",
    "            if abs(paths[1] - var) < 0.0001:\n",
    "                concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in paths[0]]\n",
    "                concepts_to_edit[i].append(concept_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3adbb0-a933-4742-a6c5-24a4ec747805",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e0b32-316f-46f1-997c-3ac6e5fa7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61b113-6deb-4b0f-8b5d-a2f14ed505e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cte in enumerate(concepts_to_edit):\n",
    "    \n",
    "    concept_indexes = [int(p[1:])-1 if p[0] != '!' else int(p[2:])-1 for p in paths[0]]\n",
    "    concepts_to_edit[i].append(concept_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581ea68-8567-418f-943f-67ee35c83252",
   "metadata": {},
   "outputs": [],
   "source": [
    "top9_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc1181-bd19-45e1-854c-38b55e8387db",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_to_edit = []\n",
    "for i in top9_concepts:\n",
    "    if i[0] == '!':\n",
    "        concepts_to_edit.append(int(i[2:])-1)\n",
    "    else:\n",
    "        concepts_to_edit.append(int(i[1:])-1)\n",
    "concepts_to_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317692c-12d3-4b25-b1f1-4bc3e7df3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_model.iloc[:, concepts_to_edit] = X_test.iloc[:, concepts_to_edit] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad50cf-6c0c-4d89-a84e-34d4b49f0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(model.predict(X_test_model), axis = 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937a2fd-3638-451f-b66e-aa50090aa470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example array\n",
    "arr = np.array([[10, 20, 15, 9],\n",
    "                [30, 40, 35, 29],\n",
    "                [50, 60, 55, 59]])\n",
    "\n",
    "# Find the second largest element along axis 1 (rows)\n",
    "second_largest = np.partition(arr, -2, axis=1)[:, -2]\n",
    "\n",
    "print(\"Array:\")\n",
    "print(arr)\n",
    "print(\"Second largest along axis 1:\")\n",
    "print(second_largest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75503ea4-ee05-4614-864d-15ad677b448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.partition(arr, -2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f782ade-f77b-4832-88ee-27903550d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.partition(arr, -2, axis=1)[:, -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e31658-f066-4c1d-9905-056952fd7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(arr, axis=1)[:, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673459b-98ba-417a-a188-47f87c9d7b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
