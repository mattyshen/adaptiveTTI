{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E402\n",
    "import math\n",
    "import warnings\n",
    "from typing import Dict, Literal\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import delu  # Deep Learning Utilities: https://github.com/Yura52/delu\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch import Tensor\n",
    "from tqdm.std import tqdm\n",
    "import json\n",
    "import sys\n",
    "\n",
    "warnings.resetwarnings()\n",
    "\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "\n",
    "from fourierDistill import *\n",
    "from featurizer import BinaryTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattyshen/anaconda3/lib/python3.9/site-packages/mdlp/discretization.py:107: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  min_split=1e-3, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "from mdlp.discretization import MDLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = sklearn.datasets.fetch_california_housing(as_frame = True)\n",
    "dataset = sklearn.datasets.load_iris(as_frame = True)\n",
    "X: np.ndarray = dataset[\"data\"]\n",
    "Y: np.ndarray = dataset[\"target\"]\n",
    "\n",
    "all_idx = np.arange(len(Y))\n",
    "train_idx, test_idx = sklearn.model_selection.train_test_split(\n",
    "    all_idx, train_size=0.8, random_state = 0\n",
    ")\n",
    "# train_idx, val_idx = sklearn.model_selection.train_test_split(\n",
    "#     trainval_idx, train_size=0.8, random_state = 0\n",
    "# )\n",
    "X_train = X.loc[train_idx]\n",
    "X_test = X.loc[test_idx]\n",
    "y_train = Y.loc[train_idx]\n",
    "y_test = Y.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inter = 3\n",
    "k_cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_bin3 = BinaryTransformer(depth = 3, bit = True)\n",
    "X_train_bin3 = bt_bin3.fit_and_transform(X.loc[train_idx, :], Y.loc[train_idx])\n",
    "X_test_bin3 = bt_bin3.transform(X.loc[test_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bin3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-interaction model fitting\n",
      "(120, 299)\n",
      "Re-fitting with LogisticRegression with L1 penalty\n"
     ]
    }
   ],
   "source": [
    "ftd_bin3 = FTDistillClassifierCV(\n",
    "                 pre_interaction=None, \n",
    "                 pre_lam1=0.01, \n",
    "                 pre_lam2=0.01,\n",
    "                 pre_max_features=None,\n",
    "                 post_interaction='l1l2', \n",
    "                 post_lam1=0.1, \n",
    "                 post_lam2=0.1,\n",
    "                 post_max_features=None,\n",
    "                 size_interactions=3)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "ftd_bin3.fit(X_train_bin3, y_train, bt_bin3.no_interaction)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftd_bin3.re_fit_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ElasticNetCV' object has no attribute 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mftd_bin3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_interaction_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ElasticNetCV' object has no attribute 'C'"
     ]
    }
   ],
   "source": [
    "ftd_bin3.post_interaction_model.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd_bin3.post_interaction_model.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ftd_bin3.predict(X_test_bin3)== y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(ftd_bin3.predict(X_train_bin3), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(ftd_bin3.predict(X_test_bin3), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MDLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d = m.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_d = m.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd_bin3.post_lam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [ftd_bin3, ftd_bit3, ftd_bit4]\n",
    "model_names = ['(bin3, true, train)', '(bit3, true, train)', '(bit4, true, train)']\n",
    "\n",
    "r2_df = pd.DataFrame()\n",
    "r2_df['Model'] = model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df['Train R2'] = [r2_score(ftd_bin3.predict(X_train_bin3), y_train),r2_score(ftd_bit3.predict(X_train_bit3), y_train), r2_score(ftd_bit4.predict(X_train_bit4), y_train)]\n",
    "r2_df['Test R2'] = [r2_score(ftd_bin3.predict(X_test_bin3), y_test),r2_score(ftd_bit3.predict(X_test_bit3), y_test), r2_score(ftd_bit4.predict(X_test_bit4), y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df['Train Time'] = train_time\n",
    "r2_df['Total Num Features'] = [len(m.regression_model.coef_) for m in model_list]\n",
    "r2_df['Num Selected Features'] = [sum(m.regression_model.coef_ != 0) for m in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_df.to_csv('r2/binarize_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[m.regression_model.reg_param for m in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftd_bit4.regression_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import l0learn\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "n_samples, n_features = 100, 20\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "true_coef = np.zeros(n_features)\n",
    "true_coef[::2] = 1  # Only every other feature is relevant\n",
    "y = np.dot(X, true_coef) + np.random.normal(size=n_samples)\n",
    "\n",
    "# Fit the model using l0learn\n",
    "fit = l0learn.fit(X, y, max_support_size=10)\n",
    "\n",
    "# Print the fitted coefficients for the best model\n",
    "print(\"Fitted coefficients:\")\n",
    "#print(fit.coef_)\n",
    "\n",
    "# # Make predictions\n",
    "# X_new = np.random.randn(10, n_features)  # New data for prediction\n",
    "# predictions = l0learn_predict(fit, X_new)\n",
    "# print(\"Predictions:\")\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.coeff(lambda_0=0.079901, gamma=0).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.coeff(lambda_0 = 0.079901, gamma = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(4) # fix the seed to get a reproducible result\n",
    "n, p, k = 500, 1000, 10\n",
    "X = np.random.normal(size=(n, p))\n",
    "B = np.zeros(p)\n",
    "B[:k] = 1\n",
    "e = np.random.normal(size=(n,))/2\n",
    "y = X@B + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = l0learn.fit(X, y, penalty=\"L0\", max_support_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model_2 = l0learn.fit(X, y, penalty=\"L0L2\", num_gamma = 5, gamma_min = 0.0001, gamma_max = 10, max_support_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model_2.coeff(lambda_0=0.0016, gamma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from l0bnb import fit_path\n",
    "from l0bnb import gen_synthetic\n",
    "\n",
    "\"\"\"\n",
    "For demonstration, we first generate a synthetic regression dataset (X,y)\n",
    "as follows: y = X*b + epsilon, where the true vector of coefficients b\n",
    "is sparse and has only 10 nonzero entries.\n",
    "We set the number of samples n=1000 and number of features p=10,000.\n",
    "\"\"\"\n",
    "X, y, b = gen_synthetic(n=1000, p=10000, supp_size=10)\n",
    "print(\"Nonzero indices in b: \", np.nonzero(b)[0])\n",
    "\n",
    "\"\"\"\n",
    "Run L0BnB to solve the problem for a sequence of lambda_0's.\n",
    "By default, the sequence of lambda_0's is automatically chosen by the toolkit.\n",
    "Use max_nonzeros=10 to stop the regularization path when it exceeds 10 nonzeros.\n",
    "Here we fix lambda_2 = 0.01 (generally, this is data-dependent).\n",
    "\"\"\"\n",
    "sols = fit_path(X, y, lambda_2 = 0.01, max_nonzeros = 10)\n",
    "\n",
    "\"\"\"\n",
    "sols is a list of solutions, each corresponding to a different lambda_0.\n",
    "Below we inspect the solution with index 4.\n",
    "The estimated coefficients vector \"b_estimated\" and the intercept term can be accessed as follows:\n",
    "\"\"\"\n",
    "b_estimated = sols[4][\"B\"] # a numpy array.\n",
    "intercept = sols[4][\"B0\"]\n",
    "\n",
    "# To check the nonzero indices in b_estimated:\n",
    "print(\"Nonzero indices in b_estimated: \", np.nonzero(b_estimated)[0])\n",
    "# The nonzero indices in b_estimated match that of b.\n",
    "\n",
    "# Predictions on the training data can be made as follows:\n",
    "y_estimated = np.dot(X, b_estimated) + intercept\n",
    "\n",
    "# For more advanced usage, check the documentation of fit_path:\n",
    "print(fit_path.__doc__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from irf import irf_utils\n",
    "from irf.ensemble import RandomForestClassifierWithWeights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
