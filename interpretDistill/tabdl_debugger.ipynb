{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4abae37-0ac7-4fd8-ae00-f26a90b640a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'featurizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeaturizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score, accuracy_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'featurizer'"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from featurizer import *\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from imodels import FIGSRegressor, FIGSClassifier\n",
    "from imodels.importance import RandomForestPlusRegressor\n",
    "\n",
    "from tabdl import *\n",
    "\n",
    "import openml\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724d30b-24cf-4461-b148-fa2ef130dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "miami_housing = openml.datasets.get_dataset(43093)\n",
    "X, y, _, _ = miami_housing.get_data(target=miami_housing.default_target_attribute, dataset_format=\"dataframe\")\n",
    "\n",
    "X = pd.DataFrame(X.values, columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf2736-1305-4478-9f07-80af5a0cfb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from featurizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cde9f6-b8c6-4ece-905d-e3e5ec8ed2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegFeaturizer()\n",
    "X_f = f.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52788127-cda2-41d9-8138-11115487f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_coupled_dict = {( \n",
    "  'dataset_name', \n",
    "  'model_name',\n",
    "  'distiller_name',\n",
    "  'featurizer_name',\n",
    "  'featurizer_frac',\n",
    "  'featurizer_overlap',\n",
    "  'depth',\n",
    "  'bit',\n",
    "  'pre_interaction',\n",
    "  'pre_max_features',\n",
    "  'post_interaction',\n",
    "  'post_max_features'\n",
    " ):\n",
    " [(dn,\n",
    "   mn,\n",
    "   din,\n",
    "   fn,\n",
    "   ff,\n",
    "   d,\n",
    "   b,\n",
    "   prei,\n",
    "   premf,\n",
    "   posti,\n",
    "   postmf\n",
    "  )\n",
    " for dn in [\"ca_housing\", \"abalone\", \"parkinsons\", \"airfoil\", \"cpu_act\", \"concrete\", \"powerplant\", \"miami_housing\", \"insurance\", \"qsar\", \"allstate\", \"mercedes\", \"transaction\"]\n",
    " for mn in [\"resnet\", \"ft_transformer\"]\n",
    " for din in [\"figs\", \"ft_distill\"]\n",
    " for fn in [\"featurizer\"]\n",
    " for ff in [0.3, 0.7]\n",
    " for d in [2, 3]\n",
    " for b in [0,1]\n",
    " for prei in [\"l0l2\", \"l1l2\"]\n",
    " for premf in [0.5]\n",
    " for posti in [\"l0l2\"]\n",
    " for postmf in [30]\n",
    " ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518e02f-dea7-4b51-b379-2a262c89ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in params_coupled_dict.keys()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0742b6-7196-4719-befd-0af5f390938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(params_coupled_dict[[i for i in params_coupled_dict.keys()][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c89aa-ed9a-45ea-b6f4-e7566f758457",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac185bb-d67a-4dd0-914b-83ee2a755696",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_continuous = X.apply(lambda col: pd.api.types.is_float_dtype(col) and len(col.unique()) > 20)\n",
    "\n",
    "# Split the DataFrame based on the determined column types\n",
    "X_cont = X.loc[:, is_continuous]\n",
    "X_cat = X.loc[:, ~is_continuous]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82159b1-eb77-4593-9dad-e1d25fde19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db8fc2-7ab4-4248-b00b-425bb7d04788",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_float_dtype(30003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f73ff-d9a9-44ac-8a90-9056aec95c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46587d07-bdc5-4758-95ef-80f7a5b88c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegFeaturizer(bit=False)\n",
    "X_t = f.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72930f41-851b-4a27-a038-373b23a1cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.feature_types, f.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eafb62-cd4e-4d2c-be34-f6fd9b34e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552aaec-bfd1-4363-9da8-04c81692104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = sklearn.datasets.load_iris(as_frame = True)\n",
    "# X: np.ndarray = dataset[\"data\"]\n",
    "# Y: np.ndarray = dataset[\"target\"]\n",
    "# task_type = 'multiclass'\n",
    "# f = ClassFeaturizer(depth=3, bit=False)\n",
    "# X = f.fit_transform(X, Y)\n",
    "# mlp = TabDLM('MLP', task_type, n_classes=3, verbose = False)\n",
    "# resnet = TabDLM('ResNet', task_type, n_classes=3, verbose = False)\n",
    "# ftt = TabDLM('FTTransformer', task_type, n_classes=3, verbose = False)\n",
    "# mlp.fit(X, Y)\n",
    "# resnet.fit(X, Y)\n",
    "# ftt.fit(X, Y)\n",
    "# accuracy_score(np.argmax(mlp.predict(X), axis = 1), Y), accuracy_score(np.argmax(resnet.predict(X), axis = 1), Y), accuracy_score(np.argmax(ftt.predict(X), axis = 1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fc6c8-fa3d-4577-ab29-0248a37900a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "\n",
    "# Generate continuous features\n",
    "continuous_features = np.random.randn(num_samples, 3)\n",
    "\n",
    "# Generate categorical features (numerical)\n",
    "categorical_feature_1 = np.random.randint(0, 3, num_samples)  # 3 categories\n",
    "categorical_feature_2 = np.random.randint(0, 5, num_samples)  # 5 categories\n",
    "\n",
    "# Combine the features into a DataFrame\n",
    "data = pd.DataFrame(continuous_features, columns=['cont_feature_1', 'cont_feature_2', 'cont_feature_3'])\n",
    "data['cat_feature_1'] = categorical_feature_1\n",
    "data['cat_feature_2'] = categorical_feature_2\n",
    "\n",
    "# Generate the target variable Y as a linear combination of features + noise\n",
    "coefficients = np.array([1.5, -2.0, 3.0, 0.5, -1.0])\n",
    "features = np.hstack([continuous_features, categorical_feature_1.reshape(-1, 1), categorical_feature_2.reshape(-1, 1)])\n",
    "noise = np.random.randn(num_samples) * 0.1  # Add some noise\n",
    "\n",
    "Y = features.dot(coefficients) + noise\n",
    "data['Y'] = Y\n",
    "\n",
    "X = data.drop(columns = ['Y'])\n",
    "Y = data['Y']\n",
    "\n",
    "f = RegFeaturizer(depth=3, bit=False)\n",
    "task_type = 'regression'\n",
    "X = f.fit_transform(X, Y)\n",
    "mlp = TabDLM('MLP', task_type, n_classes=3, verbose = False)\n",
    "resnet = TabDLM('ResNet', task_type, n_classes=3, verbose = False)\n",
    "ftt = TabDLM('FTTransformer', task_type, n_classes=3, verbose = False)\n",
    "mlp.fit(X, Y)\n",
    "resnet.fit(X, Y)\n",
    "ftt.fit(X, Y)\n",
    "r2_score(mlp.predict(X), Y), r2_score(resnet.predict(X), Y), r2_score(ftt.predict(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7da045-2582-4dda-b24c-038d1da0cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.fetch_california_housing(as_frame = True)\n",
    "X: np.ndarray = dataset[\"data\"]\n",
    "Y: np.ndarray = dataset[\"target\"]\n",
    "task_type = 'regression'\n",
    "f = RegFeaturizer(depth=3, bit=False)\n",
    "#X = f.fit_transform(X, Y)\n",
    "mlp = TabDLM('MLP', task_type, verbose = False)\n",
    "resnet = TabDLM('ResNet', task_type, verbose = False)\n",
    "ftt = TabDLM('FTTransformer', task_type, verbose = False)\n",
    "mlp.fit(X, Y)\n",
    "resnet.fit(X, Y)\n",
    "ftt.fit(X, Y)\n",
    "r2_score(mlp.predict(X), Y), r2_score(resnet.predict(X), Y), r2_score(ftt.predict(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11f505-c616-425e-8f43-21beb8af9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.fetch_california_housing(as_frame = True)\n",
    "X: np.ndarray = dataset[\"data\"]\n",
    "Y: np.ndarray = dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c56f22a-3733-45aa-ace1-db2fb371a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a7674-0faf-4c04-99ea-58c537d671ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size =0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df5091-5b69-4d39-8976-96eaa4976ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256ed1c-bf2e-4aea-b8bc-da3e6e422a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(5)\n",
    "type(pd.Series(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48be62e-0e42-4eed-ab1b-943236ceabf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
