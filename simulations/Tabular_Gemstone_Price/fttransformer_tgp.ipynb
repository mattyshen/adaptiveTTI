{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/home/mattyshen/interpretableDistillation') #/simulations/Tabular_Gemstone_Price')\n",
    "\n",
    "from interpretDistill.fourierDistill import FTDistill, FTDistillCV\n",
    "from interpretDistill.binaryTransformer import BinaryTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from interpretDistill.FTutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/mattyshen/interpretableDistillation/simulations/Tabular_Gemstone_Price/data/train.csv').drop(columns =['id'])\n",
    "#df_test = pd.read_csv('/home/mattyshen/interpretableDistillation/simulations/Tabular_Gemstone_Price/data/test.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Docs: https://yura52.github.io/zero/0.0.4/reference/api/zero.improve_reproducibility.html\n",
    "zero.improve_reproducibility(seed=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T07:12:17.511779Z",
     "iopub.status.busy": "2022-02-02T07:12:17.511443Z",
     "iopub.status.idle": "2022-02-02T07:12:17.516764Z",
     "shell.execute_reply": "2022-02-02T07:12:17.515764Z",
     "shell.execute_reply.started": "2022-02-02T07:12:17.511742Z"
    }
   },
   "source": [
    "### Split train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "X['train'], X['test'], y['train'], y['test'] = sklearn.model_selection.train_test_split(\n",
    "    df_train.drop(columns = ['price']), df_train['price'], train_size=0.8\n",
    ")\n",
    "X['train'], X['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
    "    X['train'], y['train'], train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BinaryTransformer(depth = 2, bit = False)\n",
    "X_b['train'] = bt.fit_and_transform(X['train'], y['train'])\n",
    "X_b['val'] = bt.transform(X['val'])\n",
    "X_b['test'] = bt.transform(X['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['train'].isna().to_numpy().sum(), X['val'].isna().to_numpy().sum(), X['test'].isna().to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['train'].shape, X['val'].shape, X['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['train'].shape, y['val'].shape, y['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = 1\n",
    "mlp = MLP(\n",
    "    d_in=X['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=384,\n",
    "    dropout=0.1,\n",
    ")\n",
    "resnet = ResNet(\n",
    "    d_in=X['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=192,\n",
    "    d_hidden=None,\n",
    "    d_hidden_multiplier=2.0,\n",
    "    dropout1=0.15,\n",
    "    dropout2=0.15,\n",
    ")\n",
    "mlp_b = MLP(\n",
    "    d_in=X_b['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=384,\n",
    "    dropout=0.1,\n",
    ")\n",
    "resnet_b = ResNet(\n",
    "    d_in=X_b['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=192,\n",
    "    d_hidden=None,\n",
    "    d_hidden_multiplier=2.0,\n",
    "    dropout1=0.15,\n",
    "    dropout2=0.15,\n",
    ")\n",
    "# fttransformer = FTTransformer(\n",
    "#     n_cont_features=0,\n",
    "#     cat_cardinalities=[1]*X['train'].shape[1],\n",
    "#     d_out=d_out,\n",
    "#     n_blocks=3,\n",
    "#     d_block=192,\n",
    "#     attention_n_heads=8,\n",
    "#     attention_dropout=0.2,\n",
    "#     ffn_d_hidden=None,\n",
    "#     ffn_d_hidden_multiplier=4 / 3,\n",
    "#     ffn_dropout=0.1,\n",
    "#     residual_dropout=0.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Define DataLoader for training and validation sets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "models = [mlp, resnet]\n",
    "optimizers = []\n",
    "\n",
    "best_val_loss = [float('inf'), float('inf')]\n",
    "best_model_path = 'best_model.pth'\n",
    "for epoch in range(num_epochs):\n",
    "    for model_idx, model in enumerate(models):\n",
    "        optimizer = optimizers[model_idx]\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item() * inputs.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Model {model_idx+1}, Validation Loss: {val_loss}')\n",
    "\n",
    "        # Save the model if the validation loss has decreased\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"Saving model with best validation loss\")\n",
    "\n",
    "# Load the best model\n",
    "best_model = Model()\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = fttransformer(torch.tensor(X['train'].values, dtype = torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_pred_mlp.detach().numpy().reshape(-1, ) - y['train'].to_numpy())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    ")\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(x_num, x_cat=None):\n",
    "    if isinstance(model, rtdl.FTTransformer):\n",
    "        return model(x_num.float(), x_cat)\n",
    "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
    "        assert x_cat is None\n",
    "        return model(x_num)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'Looks like you are using a custom model: {type(model)}.'\n",
    "            ' Then you have to implement this branch first.'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in zero.iter_batches(torch.cat((X_num[part],X_cat[part]), 1) ,1024):\n",
    "#         print(apply_model(batch))\n",
    "        prediction.append(apply_model(batch[:,:58], batch[:, -4:].to(torch.int64)))\n",
    "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
    "    target = y[part].cpu().numpy()\n",
    "\n",
    "    if task_type == 'binclass':\n",
    "        prediction = np.round(scipy.special.expit(prediction))\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    elif task_type == 'multiclass':\n",
    "        prediction = prediction.argmax(1)\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    else:\n",
    "        assert task_type == 'regression'\n",
    "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
    "\n",
    "progress = zero.ProgressTracker(patience=100)\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 4 # can increase the epoch size \n",
    "report_frequency = len(X['train']) // batch_size // 5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_num_batch = X_num['train'][batch_idx]\n",
    "        x_cat_batch = X_cat['train'][batch_idx].to(torch.int64)\n",
    "        y_batch = y['train'][batch_idx]\n",
    "        loss = loss_fn(apply_model(x_num_batch, x_cat_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % report_frequency == 0:\n",
    "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_params.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model using GPU to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    print('using device: cuda')\n",
    "else:\n",
    "    print('using device: cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../input/model-params/model_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU and torch.cuda.is_available():\n",
    "    test_num = test_num.float().cuda()\n",
    "    test_cat = test_cat.to(torch.int64).cuda()\n",
    "    dtype1 = torch.cuda.FloatTensor\n",
    "    dtype2 = torch.cuda.IntTensor\n",
    "    model.cuda()\n",
    "else:\n",
    "    test_num = test_num.float()\n",
    "    test_cat = test_cat.to(torch.int64)\n",
    "    dtype1 = torch.FloatTensor\n",
    "    dtype2 = torch.cuda.IntTensor\n",
    "\n",
    "test_num = Variable(test_num).type(dtype1)\n",
    "test_cat = Variable(test_cat).type(dtype2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(test_num, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame()\n",
    "Submission['id'] = df_test['id']\n",
    "Submission['site_eui'] = (predict.cpu().detach().numpy() * y_std) + y_mean\n",
    "Submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "* https://github.com/yandex-research/rtdl/blob/main/examples/rtdl.ipynb\n",
    "* https://arxiv.org/abs/2106.11959\n",
    "* https://yandex-research.github.io/rtdl/stable/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
