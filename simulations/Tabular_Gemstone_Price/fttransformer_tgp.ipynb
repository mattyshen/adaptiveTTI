{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "from rtdl_revisiting_models import MLP, ResNet, FTTransformer\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/home/mattyshen/interpretableDistillation') #/simulations/Tabular_Gemstone_Price')\n",
    "\n",
    "from interpretDistill.fourierDistill import FTDistill, FTDistillCV\n",
    "from interpretDistill.binaryTransformer import BinaryTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from interpretDistill.FTutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/mattyshen/interpretableDistillation/simulations/Tabular_Gemstone_Price/data/train.csv').drop(columns =['id'])\n",
    "#df_test = pd.read_csv('/home/mattyshen/interpretableDistillation/simulations/Tabular_Gemstone_Price/data/test.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.55</td>\n",
       "      <td>13619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.03</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.12</td>\n",
       "      <td>5.05</td>\n",
       "      <td>13387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.71</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.61</td>\n",
       "      <td>4.77</td>\n",
       "      <td>14453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193568</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>61.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193569</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>60.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.77</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193570</th>\n",
       "      <td>0.73</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193571</th>\n",
       "      <td>0.34</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.81</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193572</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>60.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193573 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        carat        cut color clarity  depth  table     x     y     z  price\n",
       "0        1.52    Premium     F     VS2   62.2   58.0  7.27  7.33  4.55  13619\n",
       "1        2.03  Very Good     J     SI2   62.0   58.0  8.06  8.12  5.05  13387\n",
       "2        0.70      Ideal     G     VS1   61.2   57.0  5.69  5.73  3.50   2772\n",
       "3        0.32      Ideal     G     VS1   61.6   56.0  4.38  4.41  2.71    666\n",
       "4        1.70    Premium     G     VS2   62.6   59.0  7.65  7.61  4.77  14453\n",
       "...       ...        ...   ...     ...    ...    ...   ...   ...   ...    ...\n",
       "193568   0.31      Ideal     D    VVS2   61.1   56.0  4.35  4.39  2.67   1130\n",
       "193569   0.70    Premium     G    VVS2   60.3   58.0  5.75  5.77  3.47   2874\n",
       "193570   0.73  Very Good     F     SI1   63.1   57.0  5.72  5.75  3.62   3036\n",
       "193571   0.34  Very Good     D     SI1   62.9   55.0  4.45  4.49  2.81    681\n",
       "193572   0.71       Good     E     SI2   60.8   64.0  5.73  5.71  3.48   2258\n",
       "\n",
       "[193573 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123456"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Docs: https://yura52.github.io/zero/0.0.4/reference/api/zero.improve_reproducibility.html\n",
    "zero.improve_reproducibility(seed=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T07:12:17.511779Z",
     "iopub.status.busy": "2022-02-02T07:12:17.511443Z",
     "iopub.status.idle": "2022-02-02T07:12:17.516764Z",
     "shell.execute_reply": "2022-02-02T07:12:17.515764Z",
     "shell.execute_reply.started": "2022-02-02T07:12:17.511742Z"
    }
   },
   "source": [
    "### Split train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "X['train'], X['test'], y['train'], y['test'] = sklearn.model_selection.train_test_split(\n",
    "    df_train.drop(columns = ['price']), df_train['price'], train_size=0.8\n",
    ")\n",
    "X['train'], X['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
    "    X['train'], y['train'], train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BinaryTransformer(depth = 2, bit = False)\n",
    "X_b['train'] = bt.fit_and_transform(X['train'], y['train'])\n",
    "X_b['val'] = bt.transform(X['val'])\n",
    "X_b['test'] = bt.transform(X['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['train'].isna().to_numpy().sum(), X['val'].isna().to_numpy().sum(), X['test'].isna().to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123886, 48), (30972, 48), (38715, 48))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['train'].shape, X['val'].shape, X['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123886,), (30972,), (38715,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['train'].shape, y['val'].shape, y['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'regression'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = 1\n",
    "mlp = MLP(\n",
    "    d_in=X['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=384,\n",
    "    dropout=0.1,\n",
    ")\n",
    "resnet = ResNet(\n",
    "    d_in=X['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=192,\n",
    "    d_hidden=None,\n",
    "    d_hidden_multiplier=2.0,\n",
    "    dropout1=0.15,\n",
    "    dropout2=0.15,\n",
    ")\n",
    "mlp_b = MLP(\n",
    "    d_in=X_b['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=384,\n",
    "    dropout=0.1,\n",
    ")\n",
    "resnet_b = ResNet(\n",
    "    d_in=X_b['train'].shape[1],\n",
    "    d_out=d_out,\n",
    "    n_blocks=2,\n",
    "    d_block=192,\n",
    "    d_hidden=None,\n",
    "    d_hidden_multiplier=2.0,\n",
    "    dropout1=0.15,\n",
    "    dropout2=0.15,\n",
    ")\n",
    "# fttransformer = FTTransformer(\n",
    "#     n_cont_features=0,\n",
    "#     cat_cardinalities=[1]*X['train'].shape[1],\n",
    "#     d_out=d_out,\n",
    "#     n_blocks=3,\n",
    "#     d_block=192,\n",
    "#     attention_n_heads=8,\n",
    "#     attention_dropout=0.2,\n",
    "#     ffn_d_hidden=None,\n",
    "#     ffn_d_hidden_multiplier=4 / 3,\n",
    "#     ffn_dropout=0.1,\n",
    "#     residual_dropout=0.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "# Define DataLoader for training and validation sets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "models = [mlp, resnet]\n",
    "optimizers = []\n",
    "\n",
    "best_val_loss = [float('inf'), float('inf')]\n",
    "best_model_path = 'best_model.pth'\n",
    "for epoch in range(num_epochs):\n",
    "    for model_idx, model in enumerate(models):\n",
    "        optimizer = optimizers[model_idx]\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item() * inputs.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Model {model_idx+1}, Validation Loss: {val_loss}')\n",
    "\n",
    "        # Save the model if the validation loss has decreased\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"Saving model with best validation loss\")\n",
    "\n",
    "# Load the best model\n",
    "best_model = Model()\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x_cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred_mlp \u001b[38;5;241m=\u001b[39m \u001b[43mfttransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x_cat'"
     ]
    }
   ],
   "source": [
    "y_pred_mlp = fttransformer(torch.tensor(X['train'].values, dtype = torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_pred_mlp.detach().numpy().reshape(-1, ) - y['train'].to_numpy())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    ")\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(x_num, x_cat=None):\n",
    "    if isinstance(model, rtdl.FTTransformer):\n",
    "        return model(x_num.float(), x_cat)\n",
    "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
    "        assert x_cat is None\n",
    "        return model(x_num)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'Looks like you are using a custom model: {type(model)}.'\n",
    "            ' Then you have to implement this branch first.'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in zero.iter_batches(torch.cat((X_num[part],X_cat[part]), 1) ,1024):\n",
    "#         print(apply_model(batch))\n",
    "        prediction.append(apply_model(batch[:,:58], batch[:, -4:].to(torch.int64)))\n",
    "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
    "    target = y[part].cpu().numpy()\n",
    "\n",
    "    if task_type == 'binclass':\n",
    "        prediction = np.round(scipy.special.expit(prediction))\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    elif task_type == 'multiclass':\n",
    "        prediction = prediction.argmax(1)\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    else:\n",
    "        assert task_type == 'regression'\n",
    "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
    "\n",
    "progress = zero.ProgressTracker(patience=100)\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 4 # can increase the epoch size \n",
    "report_frequency = len(X['train']) // batch_size // 5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_num_batch = X_num['train'][batch_idx]\n",
    "        x_cat_batch = X_cat['train'][batch_idx].to(torch.int64)\n",
    "        y_batch = y['train'][batch_idx]\n",
    "        loss = loss_fn(apply_model(x_num_batch, x_cat_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % report_frequency == 0:\n",
    "            print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_params.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model using GPU to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    print('using device: cuda')\n",
    "else:\n",
    "    print('using device: cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../input/model-params/model_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU and torch.cuda.is_available():\n",
    "    test_num = test_num.float().cuda()\n",
    "    test_cat = test_cat.to(torch.int64).cuda()\n",
    "    dtype1 = torch.cuda.FloatTensor\n",
    "    dtype2 = torch.cuda.IntTensor\n",
    "    model.cuda()\n",
    "else:\n",
    "    test_num = test_num.float()\n",
    "    test_cat = test_cat.to(torch.int64)\n",
    "    dtype1 = torch.FloatTensor\n",
    "    dtype2 = torch.cuda.IntTensor\n",
    "\n",
    "test_num = Variable(test_num).type(dtype1)\n",
    "test_cat = Variable(test_cat).type(dtype2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predict = model(test_num, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame()\n",
    "Submission['id'] = df_test['id']\n",
    "Submission['site_eui'] = (predict.cpu().detach().numpy() * y_std) + y_mean\n",
    "Submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "* https://github.com/yandex-research/rtdl/blob/main/examples/rtdl.ipynb\n",
    "* https://arxiv.org/abs/2106.11959\n",
    "* https://yandex-research.github.io/rtdl/stable/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
